TITLE: MatchService API Documentation
DESCRIPTION: Comprehensive API documentation for the MatchService, detailing all its members and inherited methods. This entry outlines the structure and available operations for interacting with the MatchService.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/match_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
.. automodule:: google.cloud.aiplatform_v1beta1.services.match_service
    :members:
    :inherited-members:
```

----------------------------------------

TITLE: DeploymentResourcePoolService API Reference
DESCRIPTION: This section details the methods available for interacting with the DeploymentResourcePoolService. It covers the service's functionality, including creating, getting, listing, and deleting deployment resource pools, as well as managing their operations. The documentation includes method signatures, parameter descriptions, return types, and potential error conditions.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/deployment_resource_pool_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
DeploymentResourcePoolService:
  __init__(client_options=None, credentials=None, client_config=None)
    Initializes the DeploymentResourcePoolService client.
    Parameters:
      client_options: Client options for the service.
      credentials: Credentials for authentication.
      client_config: Client configuration.

  create_deployment_resource_pool(request: google.cloud.aiplatform_v1beta1.types.CreateDeploymentResourcePoolRequest) -> google.cloud.aiplatform_v1beta1.types.DeploymentResourcePool
    Creates a DeploymentResourcePool.
    Parameters:
      request: The request object for creating a deployment resource pool.
        - parent: Required. The resource name of the Location to create the DeploymentResourcePool in.
        - deployment_resource_pool: Required. The DeploymentResourcePool to create.
    Returns:
      The created DeploymentResourcePool.

  get_deployment_resource_pool(request: google.cloud.aiplatform_v1beta1.types.GetDeploymentResourcePoolRequest) -> google.cloud.aiplatform_v1beta1.types.DeploymentResourcePool
    Gets a DeploymentResourcePool.
    Parameters:
      request: The request object for getting a deployment resource pool.
        - name: Required. The name of the DeploymentResourcePool resource.
    Returns:
      The DeploymentResourcePool resource.

  list_deployment_resource_pools(request: google.cloud.aiplatform_v1beta1.types.ListDeploymentResourcePoolsRequest) -> google.cloud.aiplatform_v1beta1.types.ListDeploymentResourcePoolsResponse
    Lists DeploymentResourcePools.
    Parameters:
      request: The request object for listing deployment resource pools.
        - parent: Required. The resource name of the Location to list DeploymentResourcePools.
        - filter: The standard list filter.
        - page_size: The standard list page size.
        - page_token: The standard list page token.
    Returns:
      A list of DeploymentResourcePool resources.

  delete_deployment_resource_pool(request: google.cloud.aiplatform_v1beta1.types.DeleteDeploymentResourcePoolRequest) -> google.cloud.aiplatform_v1beta1.types.Operation
    Deletes a DeploymentResourcePool.
    Parameters:
      request: The request object for deleting a deployment resource pool.
        - name: Required. The name of the DeploymentResourcePool to delete.
    Returns:
      An Operation object representing the long-running operation.

  get_operation(request: google.cloud.aiplatform_v1beta1.types.GetOperationRequest) -> google.cloud.aiplatform_v1beta1.types.Operation
    Gets an operation.
    Parameters:
      request: The request object for getting an operation.
        - name: Required. The name of the operation resource.
    Returns:
      The Operation resource.

  list_operations(request: google.cloud.aiplatform_v1beta1.types.ListOperationsRequest) -> google.cloud.aiplatform_v1beta1.types.ListOperationsResponse
    Lists operations.
    Parameters:
      request: The request object for listing operations.
        - name: Required. The name of the operation collection.
        - filter: The standard list filter.
        - page_size: The standard list page size.
        - page_token: The standard list page token.
    Returns:
      A list of Operation resources.

  cancel_operation(request: google.cloud.aiplatform_v1beta1.types.CancelOperationRequest) -> google.protobuf.empty_pb2.Empty
    Cancels an operation.
    Parameters:
      request: The request object for cancelling an operation.
        - name: Required. The name of the operation resource.
    Returns:
      An empty response.

  delete_operation(request: google.cloud.aiplatform_v1beta1.types.DeleteOperationRequest) -> google.protobuf.empty_pb2.Empty
    Deletes an operation.
    Parameters:
      request: The request object for deleting an operation.
        - name: Required. The name of the operation resource.
    Returns:
      An empty response.

  wait_operation(request: google.cloud.aiplatform_v1beta1.types.WaitOperationRequest) -> google.cloud.aiplatform_v1beta1.types.Operation
    Waits for an operation to complete.
    Parameters:
      request: The request object for waiting on an operation.
        - name: Required. The name of the operation resource.
        - timeout: The maximum time to wait for the operation to complete.
    Returns:
      The Operation resource.

  -- Pagers --

  list_deployment_resource_pools(request: google.cloud.aiplatform_v1beta1.types.ListDeploymentResourcePoolsRequest) -> Iterator[google.cloud.aiplatform_v1beta1.types.DeploymentResourcePool]
    Iterates over DeploymentResourcePools.
    Parameters:
      request: The request object for listing deployment resource pools.
    Yields:
      DeploymentResourcePool resources.

  list_operations(request: google.cloud.aiplatform_v1beta1.types.ListOperationsRequest) -> Iterator[google.cloud.aiplatform_v1beta1.types.Operation]
    Iterates over operations.
    Parameters:
      request: The request object for listing operations.
    Yields:
      Operation resources.

```

----------------------------------------

TITLE: GenAiCacheService API Reference
DESCRIPTION: Provides the API definition for the GenAiCacheService, including its methods and their parameters. This service is part of the google.cloud.aiplatform_v1 library.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/gen_ai_cache_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
GenAiCacheService:
  __init__(client_options=None, credentials=None, client_info=None)
    Initializes the GenAiCacheService client.
    Parameters:
      client_options (google.api_core.client_options.ClientOptions): Client options for the service.
      credentials (google.auth.credentials.Credentials): The credentials to use for the service.
      client_info (google.api_core.client_info.ClientInfo): Client information for the service.

  close():
    Closes the client and releases any resources.

  list_cached_contents(request: google.cloud.aiplatform_v1.types.ListCachedContentsRequest = None, *, retry: google.api_core.retry.Retry = GAPIC_RETRY_DEFAULT, timeout: float = None, metadata: Sequence[tuple[str, str]] = None) -> google.cloud.aiplatform_v1.types.ListCachedContentsResponse:
    Lists CachedContents.
    Parameters:
      request (google.cloud.aiplatform_v1.types.ListCachedContentsRequest): The request object.
      retry (google.api_core.retry.Retry): An optional retry object.
      timeout (float): An optional timeout value.
      metadata (Sequence[tuple[str, str]]): Optional metadata.
    Returns:
      google.cloud.aiplatform_v1.types.ListCachedContentsResponse: The response from the ListCachedContents API.

  get_cached_content(request: google.cloud.aiplatform_v1.types.GetCachedContentRequest = None, *, retry: google.api_core.retry.Retry = GAPIC_RETRY_DEFAULT, timeout: float = None, metadata: Sequence[tuple[str, str]] = None) -> google.cloud.aiplatform_v1.types.CachedContent:
    Gets a CachedContent.
    Parameters:
      request (google.cloud.aiplatform_v1.types.GetCachedContentRequest): The request object.
      retry (google.api_core.retry.Retry): An optional retry object.
      timeout (float): An optional timeout value.
      metadata (Sequence[tuple[str, str]]): Optional metadata.
    Returns:
      google.cloud.aiplatform_v1.types.CachedContent: The CachedContent object.

  create_cached_content(request: google.cloud.aiplatform_v1.types.CreateCachedContentRequest = None, *, retry: google.api_core.retry.Retry = GAPIC_RETRY_DEFAULT, timeout: float = None, metadata: Sequence[tuple[str, str]] = None) -> google.cloud.aiplatform_v1.types.CachedContent:
    Creates a CachedContent.
    Parameters:
      request (google.cloud.aiplatform_v1.types.CreateCachedContentRequest): The request object.
      retry (google.api_core.retry.Retry): An optional retry object.
      timeout (float): An optional timeout value.
      metadata (Sequence[tuple[str, str]]): Optional metadata.
    Returns:
      google.cloud.aiplatform_v1.types.CachedContent: The created CachedContent object.

  update_cached_content(request: google.cloud.aiplatform_v1.types.UpdateCachedContentRequest = None, *, retry: google.api_core.retry.Retry = GAPIC_RETRY_DEFAULT, timeout: float = None, metadata: Sequence[tuple[str, str]] = None) -> google.cloud.aiplatform_v1.types.CachedContent:
    Updates a CachedContent.
    Parameters:
      request (google.cloud.aiplatform_v1.types.UpdateCachedContentRequest): The request object.
      retry (google.api_core.retry.Retry): An optional retry object.
      timeout (float): An optional timeout value.
      metadata (Sequence[tuple[str, str]]): Optional metadata.
    Returns:
      google.cloud.aiplatform_v1.types.CachedContent: The updated CachedContent object.

  delete_cached_content(request: google.cloud.aiplatform_v1.types.DeleteCachedContentRequest = None, *, retry: google.api_core.retry.Retry = GAPIC_RETRY_DEFAULT, timeout: float = None, metadata: Sequence[tuple[str, str]] = None):
    Deletes a CachedContent.
    Parameters:
      request (google.cloud.aiplatform_v1.types.DeleteCachedContentRequest): The request object.
      retry (google.api_core.retry.Retry): An optional retry object.
      timeout (float): An optional timeout value.
      metadata (Sequence[tuple[str, str]]): Optional metadata.
    Returns:
      None

```

----------------------------------------

TITLE: Google Cloud AI Platform V1beta1 API Overview
DESCRIPTION: This entry provides a high-level overview of the Google Cloud AI Platform V1beta1 API, specifically detailing services related to schema predict instances. Due to the limited information provided, specific methods, parameters, or return values cannot be detailed.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/instance_v1beta1/services_.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
API: Google Cloud AI Platform V1beta1

Scope: Services for Schema Predict Instance

Description: This API enables interaction with Google Cloud's AI Platform for prediction tasks, particularly those involving schema-defined instances. It outlines the general capabilities for deploying and managing machine learning models for inference.

Note: This is a general description. Specific API endpoints, methods, request/response schemas, and usage examples are not provided in the input text.
```

----------------------------------------

TITLE: IndexEndpointService API Reference
DESCRIPTION: Provides detailed API documentation for the IndexEndpointService, including its methods, parameters, return values, and usage patterns. This section covers the core functionalities for managing index endpoints.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/index_endpoint_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1beta1.services.index_endpoint_service
  - Exposes methods for interacting with the Index Endpoint Service.
  - Includes functionalities for creating, deleting, updating, and retrieving index endpoints.
  - Supports operations like deploying models to endpoints and managing associated resources.
  - Parameters and return types are defined by the service's protobuf definitions.

google.cloud.aiplatform_v1beta1.services.index_endpoint_service.pagers
  - Contains pager classes for handling paginated responses from the Index Endpoint Service.
  - Facilitates efficient iteration over large datasets returned by API calls.
  - Pagers typically wrap list methods and manage token-based pagination internally.
```

----------------------------------------

TITLE: MigrationService Pagers API Reference
DESCRIPTION: Provides API documentation for the pagers associated with the MigrationService module. Pagers are used to handle large result sets returned by API methods, enabling efficient iteration over data.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/migration_service.rst#_snippet_1

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1.services.migration_service.pagers

This module contains pager classes for the MigrationService API.

:members:
:inherited-members:

This section details the pager classes, their attributes, and methods for iterating through paginated API responses from the MigrationService. Specific pager classes and their usage are generated by the documentation tool.
```

----------------------------------------

TITLE: TensorboardService API Reference
DESCRIPTION: Provides comprehensive API documentation for the TensorboardService, including methods for managing Tensorboard resources. This entry aggregates all related methods and their details as generated by the Python client library's documentation system.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/tensorboard_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
TensorboardService:
  __init__(client_options=None, credentials=None, client_config=None)
    Initializes the TensorboardService client.
    Parameters:
      client_options (google.api_core.client_options.ClientOptions): Client options for the service.
      credentials (google.auth.credentials.Credentials): Credentials for the service.
      client_config (dict): Client configuration dictionary.

  create_tensorboard(request: google.cloud.aiplatform_v1.types.CreateTensorboardRequest = None, parent: str = None, tensorboard: google.cloud.aiplatform_v1.types.Tensorboard = None) -> google.cloud.aiplatform_v1.types.Tensorboard
    Creates a Tensorboard.
    Parameters:
      request (google.cloud.aiplatform_v1.types.CreateTensorboardRequest): The request object.
      parent (str): Required. The parent resource name where the Tensorboard should be created.
      tensorboard (google.cloud.aiplatform_v1.types.Tensorboard): Required. The Tensorboard to create.
    Returns: The created Tensorboard.

  get_tensorboard(name: str = None, request: google.cloud.aiplatform_v1.types.GetTensorboardRequest = None) -> google.cloud.aiplatform_v1.types.Tensorboard
    Gets a Tensorboard.
    Parameters:
      name (str): Required. The name of the Tensorboard resource.
      request (google.cloud.aiplatform_v1.types.GetTensorboardRequest): The request object.
    Returns: The Tensorboard resource.

  update_tensorboard(tensorboard: google.cloud.aiplatform_v1.types.Tensorboard = None, update_mask: google.protobuf.field_mask_pb2.FieldMask = None, request: google.cloud.aiplatform_v1.types.UpdateTensorboardRequest = None) -> google.cloud.aiplatform_v1.types.Tensorboard
    Updates a Tensorboard.
    Parameters:
      tensorboard (google.cloud.aiplatform_v1.types.Tensorboard): Required. The Tensorboard to update.
      update_mask (google.protobuf.field_mask_pb2.FieldMask): The update mask to specify which fields to update.
      request (google.cloud.aiplatform_v1.types.UpdateTensorboardRequest): The request object.
    Returns: The updated Tensorboard.

  delete_tensorboard(name: str = None, request: google.cloud.aiplatform_v1.types.DeleteTensorboardRequest = None) -> google.api_core.operation.Operation
    Deletes a Tensorboard.
    Parameters:
      name (str): Required. The name of the Tensorboard resource to delete.
      request (google.cloud.aiplatform_v1.types.DeleteTensorboardRequest): The request object.
    Returns: An Operation object representing the long-running operation.

  list_tensorboards(parent: str = None, filter: str = None, page_size: int = None, page_token: str = None, request: google.cloud.aiplatform_v1.types.ListTensorboardsRequest = None) -> google.cloud.aiplatform_v1.services.tensorboard_service.pagers.ListTensorboardsPager
    Lists Tensorboards.
    Parameters:
      parent (str): Required. The parent resource name.
      filter (str): The standard list filter.
      page_size (int): The maximum number of resources to return.
      page_token (str): The page token.
      request (google.cloud.aiplatform_v1.types.ListTensorboardsRequest): The request object.
    Returns: A Pager object for iterating through Tensorboards.

  create_tensorboard_experiment(request: google.cloud.aiplatform_v1.types.CreateTensorboardExperimentRequest = None, parent: str = None, tensorboard_experiment: google.cloud.aiplatform_v1.types.TensorboardExperiment = None) -> google.cloud.aiplatform_v1.types.TensorboardExperiment
    Creates a TensorboardExperiment.
    Parameters:
      request (google.cloud.aiplatform_v1.types.CreateTensorboardExperimentRequest): The request object.
      parent (str): Required. The parent Tensorboard name.
      tensorboard_experiment (google.cloud.aiplatform_v1.types.TensorboardExperiment): Required. The TensorboardExperiment to create.
    Returns: The created TensorboardExperiment.

  get_tensorboard_experiment(name: str = None, request: google.cloud.aiplatform_v1.types.GetTensorboardExperimentRequest = None) -> google.cloud.aiplatform_v1.types.TensorboardExperiment
    Gets a TensorboardExperiment.
    Parameters:
      name (str): Required. The name of the TensorboardExperiment resource.
      request (google.cloud.aiplatform_v1.types.GetTensorboardExperimentRequest): The request object.
    Returns: The TensorboardExperiment resource.

  update_tensorboard_experiment(tensorboard_experiment: google.cloud.aiplatform_v1.types.TensorboardExperiment = None, update_mask: google.protobuf.field_mask_pb2.FieldMask = None, request: google.cloud.aiplatform_v1.types.UpdateTensorboardExperimentRequest = None) -> google.cloud.aiplatform_v1.types.TensorboardExperiment
    Updates a TensorboardExperiment.
    Parameters:
      tensorboard_experiment (google.cloud.aiplatform_v1.types.TensorboardExperiment): Required. The TensorboardExperiment to update.
      update_mask (google.protobuf.field_mask_pb2.FieldMask): The update mask to specify which fields to update.
      request (google.cloud.aiplatform_v1.types.UpdateTensorboardExperimentRequest): The request object.
    Returns: The updated TensorboardExperiment.

  delete_tensorboard_experiment(name: str = None, request: google.cloud.aiplatform_v1.types.DeleteTensorboardExperimentRequest = None) -> google.api_core.operation.Operation
    Deletes a TensorboardExperiment.
    Parameters:
      name (str): Required. The name of the TensorboardExperiment resource to delete.
      request (google.cloud.aiplatform_v1.types.DeleteTensorboardExperimentRequest): The request object.
    Returns: An Operation object representing the long-running operation.

  list_tensorboard_experiments(parent: str = None, filter: str = None, page_size: int = None, page_token: str = None, request: google.cloud.aiplatform_v1.types.ListTensorboardExperimentsRequest = None) -> google.cloud.aiplatform_v1.services.tensorboard_service.pagers.ListTensorboardExperimentsPager
    Lists TensorboardExperiments.
    Parameters:
      parent (str): Required. The parent Tensorboard name.
      filter (str): The standard list filter.
      page_size (int): The maximum number of resources to return.
      page_token (str): The page token.
      request (google.cloud.aiplatform_v1.types.ListTensorboardExperimentsRequest): The request object.
    Returns: A Pager object for iterating through TensorboardExperiments.

  create_tensorboard_run(request: google.cloud.aiplatform_v1.types.CreateTensorboardRunRequest = None, parent: str = None, tensorboard_run: google.cloud.aiplatform_v1.types.TensorboardRun = None) -> google.cloud.aiplatform_v1.types.TensorboardRun
    Creates a TensorboardRun.
    Parameters:
      request (google.cloud.aiplatform_v1.types.CreateTensorboardRunRequest): The request object.
      parent (str): Required. The parent TensorboardExperiment name.
      tensorboard_run (google.cloud.aiplatform_v1.types.TensorboardRun): Required. The TensorboardRun to create.
    Returns: The created TensorboardRun.

  get_tensorboard_run(name: str = None, request: google.cloud.aiplatform_v1.types.GetTensorboardRunRequest = None) -> google.cloud.aiplatform_v1.types.TensorboardRun
    Gets a TensorboardRun.
    Parameters:
      name (str): Required. The name of the TensorboardRun resource.
      request (google.cloud.aiplatform_v1.types.GetTensorboardRunRequest): The request object.
    Returns: The TensorboardRun resource.

  update_tensorboard_run(tensorboard_run: google.cloud.aiplatform_v1.types.TensorboardRun = None, update_mask: google.protobuf.field_mask_pb2.FieldMask = None, request: google.cloud.aiplatform_v1.types.UpdateTensorboardRunRequest = None) -> google.cloud.aiplatform_v1.types.TensorboardRun
    Updates a TensorboardRun.
    Parameters:
      tensorboard_run (google.cloud.aiplatform_v1.types.TensorboardRun): Required. The TensorboardRun to update.
      update_mask (google.protobuf.field_mask_pb2.FieldMask): The update mask to specify which fields to update.
      request (google.cloud.aiplatform_v1.types.UpdateTensorboardRunRequest): The request object.
    Returns: The updated TensorboardRun.

  delete_tensorboard_run(name: str = None, request: google.cloud.aiplatform_v1.types.DeleteTensorboardRunRequest = None) -> google.api_core.operation.Operation
    Deletes a TensorboardRun.
    Parameters:
      name (str): Required. The name of the TensorboardRun resource to delete.
      request (google.cloud.aiplatform_v1.types.DeleteTensorboardRunRequest): The request object.
    Returns: An Operation object representing the long-running operation.

  list_tensorboard_runs(parent: str = None, filter: str = None, page_size: int = None, page_token: str = None, request: google.cloud.aiplatform_v1.types.ListTensorboardRunsRequest = None) -> google.cloud.aiplatform_v1.services.tensorboard_service.pagers.ListTensorboardRunsPager
    Lists TensorboardRuns.
    Parameters:
      parent (str): Required. The parent TensorboardExperiment name.
      filter (str): The standard list filter.
      page_size (int): The maximum number of resources to return.
      page_token (str): The page token.
      request (google.cloud.aiplatform_v1.types.ListTensorboardRunsRequest): The request object.
    Returns: A Pager object for iterating through TensorboardRuns.

  read_tensorboard_timeseries_data(request: google.cloud.aiplatform_v1.types.ReadTensorboardTimeseriesDataRequest = None, tensorboard_timeseries: str = None, start_time: google.protobuf.timestamp_pb2.Timestamp = None, end_time: google.protobuf.timestamp_pb2.Timestamp = None, max_run_count: int = None, max_step_count: int = None) -> google.cloud.aiplatform_v1.services.tensorboard_service.pagers.ReadTensorboardTimeseriesDataPager
    Reads TensorboardTimeseries data.
    Parameters:
      request (google.cloud.aiplatform_v1.types.ReadTensorboardTimeseriesDataRequest): The request object.
      tensorboard_timeseries (str): Required. The name of the TensorboardTimeseries to read data from.
      start_time (google.protobuf.timestamp_pb2.Timestamp): The start time for the data to read.
      end_time (google.protobuf.timestamp_pb2.Timestamp): The end time for the data to read.
      max_run_count (int): The maximum number of runs to return data for.
      max_step_count (int): The maximum number of steps to return data for.
    Returns: A Pager object for iterating through TensorboardTimeseriesData.

  write_tensorboard_experiment_data(request: google.cloud.aiplatform_v1.types.WriteTensorboardExperimentDataRequest = None, parent: str = None, write_entries: list[google.cloud.aiplatform_v1.types.WriteTensorboardExperimentDataRequest.TensorboardExperimentDataEntry] = None) -> google.cloud.aiplatform_v1.types.WriteTensorboardExperimentDataResponse
    Writes TensorboardExperiment data.
    Parameters:
      request (google.cloud.aiplatform_v1.types.WriteTensorboardExperimentDataRequest): The request object.
      parent (str): Required. The name of the TensorboardExperiment to write data to.
      write_entries (list[google.cloud.aiplatform_v1.types.WriteTensorboardExperimentDataRequest.TensorboardExperimentDataEntry]): The data entries to write.
    Returns: The response from writing the data.

  write_tensorboard_run_data(request: google.cloud.aiplatform_v1.types.WriteTensorboardRunDataRequest = None, parent: str = None, write_entries: list[google.cloud.aiplatform_v1.types.WriteTensorboardRunDataRequest.TensorboardRunDataEntry] = None) -> google.cloud.aiplatform_v1.types.WriteTensorboardRunDataResponse
    Writes TensorboardRun data.
    Parameters:
      request (google.cloud.aiplatform_v1.types.WriteTensorboardRunDataRequest): The request object.
      parent (str): Required. The name of the TensorboardRun to write data to.
      write_entries (list[google.cloud.aiplatform_v1.types.WriteTensorboardRunDataRequest.TensorboardRunDataEntry]): The data entries to write.
    Returns: The response from writing the data.

  export_tensorboard_data(request: google.cloud.aiplatform_v1.types.ExportTensorboardDataRequest = None, name: str = None) -> google.api_core.operation.Operation
    Exports Tensorboard data.
    Parameters:
      request (google.cloud.aiplatform_v1.types.ExportTensorboardDataRequest): The request object.
      name (str): Required. The name of the Tensorboard to export data from.
    Returns: An Operation object representing the long-running operation.

  get_tensorboard_timeseries(name: str = None, request: google.cloud.aiplatform_v1.types.GetTensorboardTimeseriesRequest = None) -> google.cloud.aiplatform_v1.types.TensorboardTimeseries
    Gets a TensorboardTimeseries.
    Parameters:
      name (str): Required. The name of the TensorboardTimeseries resource.
      request (google.cloud.aiplatform_v1.types.GetTensorboardTimeseriesRequest): The request object.
    Returns: The TensorboardTimeseries resource.

  list_tensorboard_timeseries(parent: str = None, filter: str = None, page_size: int = None, page_token: str = None, order_by: str = None, request: google.cloud.aiplatform_v1.types.ListTensorboardTimeseriesRequest = None) -> google.cloud.aiplatform_v1.services.tensorboard_service.pagers.ListTensorboardTimeseriesPager
    Lists TensorboardTimeseries.
    Parameters:
      parent (str): Required. The parent TensorboardRun name.
      filter (str): The standard list filter.
      page_size (int): The maximum number of resources to return.
      page_token (str): The page token.
      order_by (str): The order for the results.
      request (google.cloud.aiplatform_v1.types.ListTensorboardTimeseriesRequest): The request object.
    Returns: A Pager object for iterating through TensorboardTimeseries.

  batch_create_tensorboard_timeseries(request: google.cloud.aiplatform_v1.types.BatchCreateTensorboardTimeseriesRequest = None, parent: str = None, tensorboard_timeseries: list[google.cloud.aiplatform_v1.types.TensorboardTimeseries] = None) -> google.cloud.aiplatform_v1.types.BatchCreateTensorboardTimeseriesResponse
    Batch creates TensorboardTimeseries.
    Parameters:
      request (google.cloud.aiplatform_v1.types.BatchCreateTensorboardTimeseriesRequest): The request object.
      parent (str): Required. The parent TensorboardRun name.
      tensorboard_timeseries (list[google.cloud.aiplatform_v1.types.TensorboardTimeseries]): Required. The TensorboardTimeseries to create.
    Returns: The response from batch creating the timeseries.

  batch_read_tensorboard_timeseries_data(request: google.cloud.aiplatform_v1.types.BatchReadTensorboardTimeseriesDataRequest = None, time_series: list[str] = None, start_time: google.protobuf.timestamp_pb2.Timestamp = None, end_time: google.protobuf.timestamp_pb2.Timestamp = None, max_run_count: int = None, max_step_count: int = None) -> google.cloud.aiplatform_v1.services.tensorboard_service.pagers.BatchReadTensorboardTimeseriesDataPager
    Batch reads TensorboardTimeseries data.
    Parameters:
      request (google.cloud.aiplatform_v1.types.BatchReadTensorboardTimeseriesDataRequest): The request object.
      time_series (list[str]): Required. The names of the TensorboardTimeseries to read data from.
      start_time (google.protobuf.timestamp_pb2.Timestamp): The start time for the data to read.
      end_time (google.protobuf.timestamp_pb2.Timestamp): The end time for the data to read.
      max_run_count (int): The maximum number of runs to return data for.
      max_step_count (int): The maximum number of steps to return data for.
    Returns: A Pager object for iterating through BatchReadTensorboardTimeseriesData.

```

----------------------------------------

TITLE: PipelineService API Reference
DESCRIPTION: Provides comprehensive API documentation for the PipelineService, including all public methods and inherited members. This entry details the service's functionality, parameters, return types, and usage patterns as defined by the google-cloud-aiplatform library.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/pipeline_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1.services.pipeline_service
  (Details on methods, parameters, and return values are generated from the module's members.)

  Example structure (actual details depend on library introspection):
  PipelineService:
    __init__(...) 
      Initializes the PipelineService client.
    create_pipeline_job(request: CreatePipelineJobRequest) -> PipelineJob
      Creates a pipeline job.
      Parameters:
        request: The request object for creating a pipeline job.
      Returns:
        The created PipelineJob resource.
    get_pipeline_job(request: GetPipelineJobRequest) -> PipelineJob
      Gets a pipeline job.
      Parameters:
        request: The request object for getting a pipeline job.
      Returns:
        The PipelineJob resource.
    list_pipeline_jobs(request: ListPipelineJobsRequest) -> ListPipelineJobsResponse
      Lists pipeline jobs.
      Parameters:
        request: The request object for listing pipeline jobs.
      Returns:
        A response containing a list of PipelineJob resources.
    ...
```

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1.services.pipeline_service.pagers
  (Details on pager classes and their methods are generated from the module's members.)

  Example structure (actual details depend on library introspection):
  PipelineJobListPager:
    __init__(...) 
      Initializes the pager.
    __iter__() -> Iterator[PipelineJob]
      Iterates over PipelineJob resources.
    next_page_token: str
      The token to retrieve the next page of results.
    ...
```

----------------------------------------

TITLE: FeatureOnlineStoreAdminService API Reference
DESCRIPTION: Provides administrative access to Feature Stores online. This entry details the service's Python module and its associated pager classes, which are used for handling paginated responses from API calls.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/feature_online_store_admin_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1beta1.services.feature_online_store_admin_service
  - Manages online feature store resources.
  - Includes methods for creating, deleting, updating, and retrieving feature store configurations.

google.cloud.aiplatform_v1beta1.services.feature_online_store_admin_service.pagers
  - Contains pager classes for handling paginated results from the FeatureOnlineStoreAdminService.
  - Enables efficient iteration over large datasets returned by API methods.
```

----------------------------------------

TITLE: Google Cloud AI Platform v1 API Types Overview
DESCRIPTION: This section outlines the structure and members of the Google Cloud AI Platform v1 API types module. It serves as a reference point for understanding the data structures used by the API.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/types_.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Module: google.cloud.aiplatform_v1.types

Description: Contains the data types and structures used by the Google Cloud AI Platform v1 API.

Members:
  - Lists all public attributes and methods within the module.

Inheritance:
  - Shows the inheritance hierarchy for the types defined in the module.

Note: Specific type definitions, their parameters, and return values are detailed in separate API documentation entries or client library references.
```

----------------------------------------

TITLE: NotebookService API Reference
DESCRIPTION: Provides detailed information on the methods available for interacting with the AI Platform Notebooks API. This includes operations for managing notebook instances, environments, and related resources. The service client and its pagers are documented here.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/notebook_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1.services.notebook_service

Provides the client for the NotebookService.

Methods:
  create_notebook_instance(parent: str
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

LANGUAGE: undefined
CODE:
```
undefined
```

----------------------------------------

TITLE: Google Cloud AI Platform Endpoint Service API
DESCRIPTION: Provides access to the Endpoint Service API for managing endpoints in Google Cloud AI Platform. This includes methods for creating, deleting, updating, and listing endpoints, as well as managing their associated resources. The API is designed for programmatic interaction with AI Platform services.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/endpoint_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1.services.endpoint_service
  - Provides methods for interacting with the Endpoint Service API.
  - Includes functionality for managing AI Platform endpoints.

google.cloud.aiplatform_v1.services.endpoint_service.pagers
  - Contains pager classes for handling paginated responses from the Endpoint Service API.
  - Facilitates efficient retrieval of large result sets.
```

----------------------------------------

TITLE: MigrationService API Reference
DESCRIPTION: Provides API documentation for the MigrationService module. This includes all public members and inherited members, detailing the service's functionality and methods for managing migrations within Google Cloud AI Platform.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/migration_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1.services.migration_service

This module provides the client for the MigrationService API.

:members:
:inherited-members:

This section details the methods, parameters, and return types for interacting with the MigrationService. Specific methods and their signatures are generated by the documentation tool based on the module's content.
```

----------------------------------------

TITLE: SpecialistPoolService and Pagers API Documentation
DESCRIPTION: This entry consolidates the API documentation for the SpecialistPoolService and its pagers. It outlines the structure for generating documentation for all public members and inherited members of these modules.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/specialist_pool_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
.. automodule:: google.cloud.aiplatform_v1.services.specialist_pool_service
    :members:
    :inherited-members:

.. automodule:: google.cloud.aiplatform_v1.services.specialist_pool_service.pagers
    :members:
    :inherited-members:
```

----------------------------------------

TITLE: Reasoning Engine Service API Reference
DESCRIPTION: Provides access to the Reasoning Engine Service API, enabling interaction with reasoning engine functionalities. Includes methods for managing reasoning engines and their operations, along with pagers for handling large result sets.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/reasoning_engine_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1.services.reasoning_engine_service
  Provides client for Reasoning Engine Service API.

  Methods:
    create_reasoning_engine(request: google.cloud.aiplatform_v1.types.CreateReasoningEngineRequest) -> google.longrunning.operations_pb2.Operation
      Creates a ReasoningEngine.

    get_reasoning_engine(request: google.cloud.aiplatform_v1.types.GetReasoningEngineRequest) -> google.cloud.aiplatform_v1.types.ReasoningEngine
      Gets a ReasoningEngine.

    list_reasoning_engines(request: google.cloud.aiplatform_v1.types.ListReasoningEnginesRequest) -> google.cloud.aiplatform_v1.types.ListReasoningEnginesResponse
      Lists ReasoningEngines.

    update_reasoning_engine(request: google.cloud.aiplatform_v1.types.UpdateReasoningEngineRequest) -> google.longrunning.operations_pb2.Operation
      Updates a ReasoningEngine.

    delete_reasoning_engine(request: google.cloud.aiplatform_v1.types.DeleteReasoningEngineRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a ReasoningEngine.

    deploy_reasoning_engine(request: google.cloud.aiplatform_v1.types.DeployReasoningEngineRequest) -> google.longrunning.operations_pb2.Operation
      Deploys a ReasoningEngine.

    undeploy_reasoning_engine(request: google.cloud.aiplatform_v1.types.UndeployReasoningEngineRequest) -> google.longrunning.operations_pb2.Operation
      Undeploys a ReasoningEngine.

    run_reasoning_engine(request: google.cloud.aiplatform_v1.types.RunReasoningEngineRequest) -> google.cloud.aiplatform_v1.types.RunReasoningEngineResponse
      Runs a ReasoningEngine.

    list_reasoning_engine_versions(request: google.cloud.aiplatform_v1.types.ListReasoningEngineVersionsRequest) -> google.cloud.aiplatform_v1.types.ListReasoningEngineVersionsResponse
      Lists ReasoningEngineVersions.

    get_reasoning_engine_version(request: google.cloud.aiplatform_v1.types.GetReasoningEngineVersionRequest) -> google.cloud.aiplatform_v1.types.ReasoningEngineVersion
      Gets a ReasoningEngineVersion.

    create_reasoning_engine_version(request: google.cloud.aiplatform_v1.types.CreateReasoningEngineVersionRequest) -> google.longrunning.operations_pb2.Operation
      Creates a ReasoningEngineVersion.

    update_reasoning_engine_version(request: google.cloud.aiplatform_v1.types.UpdateReasoningEngineVersionRequest) -> google.longrunning.operations_pb2.Operation
      Updates a ReasoningEngineVersion.

    delete_reasoning_engine_version(request: google.cloud.aiplatform_v1.types.DeleteReasoningEngineVersionRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a ReasoningEngineVersion.

    get_evaluation(request: google.cloud.aiplatform_v1.types.GetEvaluationRequest) -> google.cloud.aiplatform_v1.types.Evaluation
      Gets an Evaluation.

    list_evaluations(request: google.cloud.aiplatform_v1.types.ListEvaluationsRequest) -> google.cloud.aiplatform_v1.types.ListEvaluationsResponse
      Lists Evaluations.

    create_evaluation(request: google.cloud.aiplatform_v1.types.CreateEvaluationRequest) -> google.longrunning.operations_pb2.Operation
      Creates an Evaluation.

    delete_evaluation(request: google.cloud.aiplatform_v1.types.DeleteEvaluationRequest) -> google.longrunning.operations_pb2.Operation
      Deletes an Evaluation.

    get_model_evaluation(request: google.cloud.aiplatform_v1.types.GetModelEvaluationRequest) -> google.cloud.aiplatform_v1.types.ModelEvaluation
      Gets a ModelEvaluation.

    list_model_evaluations(request: google.cloud.aiplatform_v1.types.ListModelEvaluationsRequest) -> google.cloud.aiplatform_v1.types.ListModelEvaluationsResponse
      Lists ModelEvaluations.

    get_model_evaluation_slice(request: google.cloud.aiplatform_v1.types.GetModelEvaluationSliceRequest) -> google.cloud.aiplatform_v1.types.ModelEvaluationSlice
      Gets a ModelEvaluationSlice.

    list_model_evaluation_slices(request: google.cloud.aiplatform_v1.types.ListModelEvaluationSlicesRequest) -> google.cloud.aiplatform_v1.types.ListModelEvaluationSlicesResponse
      Lists ModelEvaluationSlices.

    get_vertex_ai_model_monitoring_job(request: google.cloud.aiplatform_v1.types.GetVertexAiModelMonitoringJobRequest) -> google.cloud.aiplatform_v1.types.VertexAiModelMonitoringJob
      Gets a VertexAiModelMonitoringJob.

    list_vertex_ai_model_monitoring_jobs(request: google.cloud.aiplatform_v1.types.ListVertexAiModelMonitoringJobsRequest) -> google.cloud.aiplatform_v1.types.ListVertexAiModelMonitoringJobsResponse
      Lists VertexAiModelMonitoringJobs.

    create_vertex_ai_model_monitoring_job(request: google.cloud.aiplatform_v1.types.CreateVertexAiModelMonitoringJobRequest) -> google.longrunning.operations_pb2.Operation
      Creates a VertexAiModelMonitoringJob.

    delete_vertex_ai_model_monitoring_job(request: google.cloud.aiplatform_v1.types.DeleteVertexAiModelMonitoringJobRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a VertexAiModelMonitoringJob.

    update_vertex_ai_model_monitoring_job(request: google.cloud.aiplatform_v1.types.UpdateVertexAiModelMonitoringJobRequest) -> google.longrunning.operations_pb2.Operation
      Updates a VertexAiModelMonitoringJob.

    batch_prediction_job(request: google.cloud.aiplatform_v1.types.BatchPredictionJob) -> google.longrunning.operations_pb2.Operation
      Creates a BatchPredictionJob.

    get_batch_prediction_job(request: google.cloud.aiplatform_v1.types.GetBatchPredictionJobRequest) -> google.cloud.aiplatform_v1.types.BatchPredictionJob
      Gets a BatchPredictionJob.

    list_batch_prediction_jobs(request: google.cloud.aiplatform_v1.types.ListBatchPredictionJobsRequest) -> google.cloud.aiplatform_v1.types.ListBatchPredictionJobsResponse
      Lists BatchPredictionJobs.

    cancel_batch_prediction_job(request: google.cloud.aiplatform_v1.types.CancelBatchPredictionJobRequest) -> google.protobuf.empty_pb2.Empty
      Cancels a BatchPredictionJob.

    delete_batch_prediction_job(request: google.cloud.aiplatform_v1.types.DeleteBatchPredictionJobRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a BatchPredictionJob.

    create_endpoint(request: google.cloud.aiplatform_v1.types.CreateEndpointRequest) -> google.longrunning.operations_pb2.Operation
      Creates an Endpoint.

    get_endpoint(request: google.cloud.aiplatform_v1.types.GetEndpointRequest) -> google.cloud.aiplatform_v1.types.Endpoint
      Gets an Endpoint.

    list_endpoints(request: google.cloud.aiplatform_v1.types.ListEndpointsRequest) -> google.cloud.aiplatform_v1.types.ListEndpointsResponse
      Lists Endpoints.

    delete_endpoint(request: google.cloud.aiplatform_v1.types.DeleteEndpointRequest) -> google.longrunning.operations_pb2.Operation
      Deletes an Endpoint.

    update_endpoint(request: google.cloud.aiplatform_v1.types.UpdateEndpointRequest) -> google.longrunning.operations_pb2.Operation
      Updates an Endpoint.

    deploy_model(request: google.cloud.aiplatform_v1.types.DeployModelRequest) -> google.longrunning.operations_pb2.Operation
      Deploys a Model to an Endpoint.

    undeploy_model(request: google.cloud.aiplatform_v1.types.UndeployModelRequest) -> google.longrunning.operations_pb2.Operation
      Undeploys a Model from an Endpoint.

    create_model(request: google.cloud.aiplatform_v1.types.CreateModelRequest) -> google.longrunning.operations_pb2.Operation
      Creates a Model.

    get_model(request: google.cloud.aiplatform_v1.types.GetModelRequest) -> google.cloud.aiplatform_v1.types.Model
      Gets a Model.

    list_models(request: google.cloud.aiplatform_v1.types.ListModelsRequest) -> google.cloud.aiplatform_v1.types.ListModelsResponse
      Lists Models.

    delete_model(request: google.cloud.aiplatform_v1.types.DeleteModelRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a Model.

    update_model(request: google.cloud.aiplatform_v1.types.UpdateModelRequest) -> google.longrunning.operations_pb2.Operation
      Updates a Model.

    upload_model(request: google.cloud.aiplatform_v1.types.UploadModelRequest) -> google.longrunning.operations_pb2.Operation
      Uploads a Model.

    import_model_evaluation(request: google.cloud.aiplatform_v1.types.ImportModelEvaluationRequest) -> google.longrunning.operations_pb2.Operation
      Imports a ModelEvaluation.

    export_model(request: google.cloud.aiplatform_v1.types.ExportModelRequest) -> google.longrunning.operations_pb2.Operation
      Exports a Model.

    get_pipeline_job(request: google.cloud.aiplatform_v1.types.GetPipelineJobRequest) -> google.cloud.aiplatform_v1.types.PipelineJob
      Gets a PipelineJob.

    list_pipeline_jobs(request: google.cloud.aiplatform_v1.types.ListPipelineJobsRequest) -> google.cloud.aiplatform_v1.types.ListPipelineJobsResponse
      Lists PipelineJobs.

    create_pipeline_job(request: google.cloud.aiplatform_v1.types.CreatePipelineJobRequest) -> google.longrunning.operations_pb2.Operation
      Creates a PipelineJob.

    delete_pipeline_job(request: google.cloud.aiplatform_v1.types.DeletePipelineJobRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a PipelineJob.

    cancel_pipeline_job(request: google.cloud.aiplatform_v1.types.CancelPipelineJobRequest) -> google.protobuf.empty_pb2.Empty
      Cancels a PipelineJob.

    run_pipeline_job(request: google.cloud.aiplatform_v1.types.RunPipelineJobRequest) -> google.longrunning.operations_pb2.Operation
      Runs a PipelineJob.

    get_training_pipeline(request: google.cloud.aiplatform_v1.types.GetTrainingPipelineRequest) -> google.cloud.aiplatform_v1.types.TrainingPipeline
      Gets a TrainingPipeline.

    list_training_pipelines(request: google.cloud.aiplatform_v1.types.ListTrainingPipelinesRequest) -> google.cloud.aiplatform_v1.types.ListTrainingPipelinesResponse
      Lists TrainingPipelines.

    create_training_pipeline(request: google.cloud.aiplatform_v1.types.CreateTrainingPipelineRequest) -> google.longrunning.operations_pb2.Operation
      Creates a TrainingPipeline.

    delete_training_pipeline(request: google.cloud.aiplatform_v1.types.DeleteTrainingPipelineRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a TrainingPipeline.

    get_custom_job(request: google.cloud.aiplatform_v1.types.GetCustomJobRequest) -> google.cloud.aiplatform_v1.types.CustomJob
      Gets a CustomJob.

    list_custom_jobs(request: google.cloud.aiplatform_v1.types.ListCustomJobsRequest) -> google.cloud.aiplatform_v1.types.ListCustomJobsResponse
      Lists CustomJobs.

    create_custom_job(request: google.cloud.aiplatform_v1.types.CreateCustomJobRequest) -> google.longrunning.operations_pb2.Operation
      Creates a CustomJob.

    delete_custom_job(request: google.cloud.aiplatform_v1.types.DeleteCustomJobRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a CustomJob.

    cancel_custom_job(request: google.cloud.aiplatform_v1.types.CancelCustomJobRequest) -> google.protobuf.empty_pb2.Empty
      Cancels a CustomJob.

    get_hyperparameter_tuning_job(request: google.cloud.aiplatform_v1.types.GetHyperparameterTuningJobRequest) -> google.cloud.aiplatform_v1.types.HyperparameterTuningJob
      Gets a HyperparameterTuningJob.

    list_hyperparameter_tuning_jobs(request: google.cloud.aiplatform_v1.types.ListHyperparameterTuningJobsRequest) -> google.cloud.aiplatform_v1.types.ListHyperparameterTuningJobsResponse
      Lists HyperparameterTuningJobs.

    create_hyperparameter_tuning_job(request: google.cloud.aiplatform_v1.types.CreateHyperparameterTuningJobRequest) -> google.longrunning.operations_pb2.Operation
      Creates a HyperparameterTuningJob.

    delete_hyperparameter_tuning_job(request: google.cloud.aiplatform_v1.types.DeleteHyperparameterTuningJobRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a HyperparameterTuningJob.

    cancel_hyperparameter_tuning_job(request: google.cloud.aiplatform_v1.types.CancelHyperparameterTuningJobRequest) -> google.protobuf.empty_pb2.Empty
      Cancels a HyperparameterTuningJob.

    get_metadata_store(request: google.cloud.aiplatform_v1.types.GetMetadataStoreRequest) -> google.cloud.aiplatform_v1.types.MetadataStore
      Gets a MetadataStore.

    list_metadata_stores(request: google.cloud.aiplatform_v1.types.ListMetadataStoresRequest) -> google.cloud.aiplatform_v1.types.ListMetadataStoresResponse
      Lists MetadataStores.

    create_metadata_store(request: google.cloud.aiplatform_v1.types.CreateMetadataStoreRequest) -> google.longrunning.operations_pb2.Operation
      Creates a MetadataStore.

    delete_metadata_store(request: google.cloud.aiplatform_v1.types.DeleteMetadataStoreRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a MetadataStore.

    get_metadata_schema(request: google.cloud.aiplatform_v1.types.GetMetadataSchemaRequest) -> google.cloud.aiplatform_v1.types.MetadataSchema
      Gets a MetadataSchema.

    list_metadata_schemas(request: google.cloud.aiplatform_v1.types.ListMetadataSchemasRequest) -> google.cloud.aiplatform_v1.types.ListMetadataSchemasResponse
      Lists MetadataSchemas.

    create_metadata_schema(request: google.cloud.aiplatform_v1.types.CreateMetadataSchemaRequest) -> google.cloud.aiplatform_v1.types.MetadataSchema
      Creates a MetadataSchema.

    get_lineage_run(request: google.cloud.aiplatform_v1.types.GetLineageRunRequest) -> google.cloud.aiplatform_v1.types.LineageRun
      Gets a LineageRun.

    list_lineage_runs(request: google.cloud.aiplatform_v1.types.ListLineageRunsRequest) -> google.cloud.aiplatform_v1.types.ListLineageRunsResponse
      Lists LineageRuns.

    create_lineage_run(request: google.cloud.aiplatform_v1.types.CreateLineageRunRequest) -> google.cloud.aiplatform_v1.types.LineageRun
      Creates a LineageRun.

    update_lineage_run(request: google.cloud.aiplatform_v1.types.UpdateLineageRunRequest) -> google.cloud.aiplatform_v1.types.LineageRun
      Updates a LineageRun.

    delete_lineage_run(request: google.cloud.aiplatform_v1.types.DeleteLineageRunRequest) -> google.protobuf.empty_pb2.Empty
      Deletes a LineageRun.

    add_context_to_lineage_run(request: google.cloud.aiplatform_v1.types.AddContextToLineageRunRequest) -> google.protobuf.empty_pb2.Empty
      Adds a Context to a LineageRun.

    remove_context_from_lineage_run(request: google.cloud.aiplatform_v1.types.RemoveContextFromLineageRunRequest) -> google.protobuf.empty_pb2.Empty
      Removes a Context from a LineageRun.

    get_artifact(request: google.cloud.aiplatform_v1.types.GetArtifactRequest) -> google.cloud.aiplatform_v1.types.Artifact
      Gets an Artifact.

    list_artifacts(request: google.cloud.aiplatform_v1.types.ListArtifactsRequest) -> google.cloud.aiplatform_v1.types.ListArtifactsResponse
      Lists Artifacts.

    create_artifact(request: google.cloud.aiplatform_v1.types.CreateArtifactRequest) -> google.cloud.aiplatform_v1.types.Artifact
      Creates an Artifact.

    update_artifact(request: google.cloud.aiplatform_v1.types.UpdateArtifactRequest) -> google.cloud.aiplatform_v1.types.Artifact
      Updates an Artifact.

    delete_artifact(request: google.cloud.aiplatform_v1.types.DeleteArtifactRequest) -> google.protobuf.empty_pb2.Empty
      Deletes an Artifact.

    link_artifacts(request: google.cloud.aiplatform_v1.types.LinkArtifactsRequest) -> google.protobuf.empty_pb2.Empty
      Links Artifacts.

    unlink_artifacts(request: google.cloud.aiplatform_v1.types.UnlinkArtifactsRequest) -> google.protobuf.empty_pb2.Empty
      Unlinks Artifacts.

    get_context(request: google.cloud.aiplatform_v1.types.GetContextRequest) -> google.cloud.aiplatform_v1.types.Context
      Gets a Context.

    list_contexts(request: google.cloud.aiplatform_v1.types.ListContextsRequest) -> google.cloud.aiplatform_v1.types.ListContextsResponse
      Lists Contexts.

    create_context(request: google.cloud.aiplatform_v1.types.CreateContextRequest) -> google.cloud.aiplatform_v1.types.Context
      Creates a Context.

    update_context(request: google.cloud.aiplatform_v1.types.UpdateContextRequest) -> google.cloud.aiplatform_v1.types.Context
      Updates a Context.

    delete_context(request: google.cloud.aiplatform_v1.types.DeleteContextRequest) -> google.protobuf.empty_pb2.Empty
      Deletes a Context.

    add_context_to_artifact(request: google.cloud.aiplatform_v1.types.AddContextToArtifactRequest) -> google.protobuf.empty_pb2.Empty
      Adds a Context to an Artifact.

    remove_context_from_artifact(request: google.cloud.aiplatform_v1.types.RemoveContextFromArtifactRequest) -> google.protobuf.empty_pb2.Empty
      Removes a Context from an Artifact.

    add_artifact_to_context(request: google.cloud.aiplatform_v1.types.AddArtifactToContextRequest) -> google.protobuf.empty_pb2.Empty
      Adds an Artifact to a Context.

    remove_artifact_from_context(request: google.cloud.aiplatform_v1.types.RemoveArtifactFromContextRequest) -> google.protobuf.empty_pb2.Empty
      Removes an Artifact from a Context.

    get_execution(request: google.cloud.aiplatform_v1.types.GetExecutionRequest) -> google.cloud.aiplatform_v1.types.Execution
      Gets an Execution.

    list_executions(request: google.cloud.aiplatform_v1.types.ListExecutionsRequest) -> google.cloud.aiplatform_v1.types.ListExecutionsResponse
      Lists Executions.

    create_execution(request: google.cloud.aiplatform_v1.types.CreateExecutionRequest) -> google.cloud.aiplatform_v1.types.Execution
      Creates an Execution.

    update_execution(request: google.cloud.aiplatform_v1.types.UpdateExecutionRequest) -> google.cloud.aiplatform_v1.types.Execution
      Updates an Execution.

    delete_execution(request: google.cloud.aiplatform_v1.types.DeleteExecutionRequest) -> google.protobuf.empty_pb2.Empty
      Deletes an Execution.

    add_execution_to_context(request: google.cloud.aiplatform_v1.types.AddExecutionToContextRequest) -> google.protobuf.empty_pb2.Empty
      Adds an Execution to a Context.

    remove_execution_from_context(request: google.cloud.aiplatform_v1.types.RemoveExecutionFromContextRequest) -> google.protobuf.empty_pb2.Empty
      Removes an Execution from a Context.

    add_execution_to_artifact(request: google.cloud.aiplatform_v1.types.AddExecutionToArtifactRequest) -> google.protobuf.empty_pb2.Empty
      Adds an Execution to an Artifact.

    remove_execution_from_artifact(request: google.cloud.aiplatform_v1.types.RemoveExecutionFromArtifactRequest) -> google.protobuf.empty_pb2.Empty
      Removes an Execution from an Artifact.

    add_artifact_to_execution(request: google.cloud.aiplatform_v1.types.AddArtifactToExecutionRequest) -> google.protobuf.empty_pb2.Empty
      Adds an Artifact to an Execution.

    remove_artifact_from_execution(request: google.cloud.aiplatform_v1.types.RemoveArtifactFromExecutionRequest) -> google.protobuf.empty_pb2.Empty
      Removes an Artifact from an Execution.

    add_execution_to_execution(request: google.cloud.aiplatform_v1.types.AddExecutionToExecutionRequest) -> google.protobuf.empty_pb2.Empty
      Adds an Execution to an Execution.

    remove_execution_from_execution(request: google.cloud.aiplatform_v1.types.RemoveExecutionFromExecutionRequest) -> google.protobuf.empty_pb2.Empty
      Removes an Execution from an Execution.

    get_feature_store(request: google.cloud.aiplatform_v1.types.GetFeatureStoreRequest) -> google.cloud.aiplatform_v1.types.FeatureStore
      Gets a FeatureStore.

    list_feature_stores(request: google.cloud.aiplatform_v1.types.ListFeatureStoresRequest) -> google.cloud.aiplatform_v1.types.ListFeatureStoresResponse
      Lists FeatureStores.

    create_feature_store(request: google.cloud.aiplatform_v1.types.CreateFeatureStoreRequest) -> google.longrunning.operations_pb2.Operation
      Creates a FeatureStore.

    delete_feature_store(request: google.cloud.aiplatform_v1.types.DeleteFeatureStoreRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a FeatureStore.

    update_feature_store(request: google.cloud.aiplatform_v1.types.UpdateFeatureStoreRequest) -> google.longrunning.operations_pb2.Operation
      Updates a FeatureStore.

    get_feature_group(request: google.cloud.aiplatform_v1.types.GetFeatureGroupRequest) -> google.cloud.aiplatform_v1.types.FeatureGroup
      Gets a FeatureGroup.

    list_feature_groups(request: google.cloud.aiplatform_v1.types.ListFeatureGroupsRequest) -> google.cloud.aiplatform_v1.types.ListFeatureGroupsResponse
      Lists FeatureGroups.

    create_feature_group(request: google.cloud.aiplatform_v1.types.CreateFeatureGroupRequest) -> google.longrunning.operations_pb2.Operation
      Creates a FeatureGroup.

    delete_feature_group(request: google.cloud.aiplatform_v1.types.DeleteFeatureGroupRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a FeatureGroup.

    update_feature_group(request: google.cloud.aiplatform_v1.types.UpdateFeatureGroupRequest) -> google.longrunning.operations_pb2.Operation
      Updates a FeatureGroup.

    get_feature(request: google.cloud.aiplatform_v1.types.GetFeatureRequest) -> google.cloud.aiplatform_v1.types.Feature
      Gets a Feature.

    list_features(request: google.cloud.aiplatform_v1.types.ListFeaturesRequest) -> google.cloud.aiplatform_v1.types.ListFeaturesResponse
      Lists Features.

    create_feature(request: google.cloud.aiplatform_v1.types.CreateFeatureRequest) -> google.longrunning.operations_pb2.Operation
      Creates a Feature.

    delete_feature(request: google.cloud.aiplatform_v1.types.DeleteFeatureRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a Feature.

    update_feature(request: google.cloud.aiplatform_v1.types.UpdateFeatureRequest) -> google.longrunning.operations_pb2.Operation
      Updates a Feature.

    ingest_feature_data(request: google.cloud.aiplatform_v1.types.IngestFeatureDataRequest) -> google.longrunning.operations_pb2.Operation
      Ingests Feature data.

    import_feature_values(request: google.cloud.aiplatform_v1.types.ImportFeatureValuesRequest) -> google.longrunning.operations_pb2.Operation
      Imports Feature values.

    batch_read_feature_values(request: google.cloud.aiplatform_v1.types.BatchReadFeatureValuesRequest) -> google.longrunning.operations_pb2.Operation
      Reads Feature values in batch.

    read_feature_values(request: google.cloud.aiplatform_v1.types.ReadFeatureValuesRequest) -> google.cloud.aiplatform_v1.types.ReadFeatureValuesResponse
      Reads Feature values.

    list_feature_value_appends(request: google.cloud.aiplatform_v1.types.ListFeatureValueAppendsRequest) -> google.cloud.aiplatform_v1.types.ListFeatureValueAppendsResponse
      Lists FeatureValueAppends.

    create_feature_value_append(request: google.cloud.aiplatform_v1.types.CreateFeatureValueAppendRequest) -> google.longrunning.operations_pb2.Operation
      Creates a FeatureValueAppend.

    delete_feature_value_append(request: google.cloud.aiplatform_v1.types.DeleteFeatureValueAppendRequest) -> google.longrunning.operations_pb2.Operation
      Deletes a FeatureValueAppend.

    get_feature_registry_service_config(request: google.cloud.aiplatform_v1.types.GetFeatureRegistryServiceConfigRequest) -> google.cloud.aiplatform_v1.types.FeatureRegistryServiceConfig
      Gets FeatureRegistryServiceConfig.

    update_feature_registry_service_config(request: google.cloud.aiplatform_v1.types.UpdateFeatureRegistryServiceConfigRequest) -> google.cloud.aiplatform_v1.types.FeatureRegistryServiceConfig
      Updates FeatureRegistryServiceConfig.

    get_data_item(request: google.cloud.aiplatform_v1.types.GetDataItemRequest) -> google.cloud.aiplatform_v1.types.DataItem
      Gets a DataItem.

    list_data_items(request: google.cloud.aiplatform_v1.types.ListDataItemsRequest) -> google.cloud.aiplatform_v1.types.ListDataItemsResponse

```

----------------------------------------

TITLE: Google Cloud Aiplatform v1 API Types Reference
DESCRIPTION: This entry serves as a reference for the types available in the Google Cloud AI Platform v1 API. It outlines the structure and members of the types module, facilitating integration and development with the AI Platform service.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/types.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Google Cloud Aiplatform v1 API Types:

This documentation block details the types available for the Google Cloud AI Platform v1 API. It is generated from the `google.cloud.aiplatform_v1.types` module.

Key Features:
- Lists all members (classes, functions, constants) within the types module.
- Indicates inheritance relationships between types.

Usage:
Developers can import and utilize these types to interact with the AI Platform API, defining request and response structures.

Example (Conceptual):
```python
from google.cloud.aiplatform_v1.types import TrainingPipeline

# Instantiate a TrainingPipeline object
pipeline = TrainingPipeline(
    display_name='my-training-pipeline',
    # ... other parameters
)
```

Note: Specific parameter details, return types, and method signatures for each type are typically found in the full API reference documentation or SDK source code.
```

----------------------------------------

TITLE: VizierService Module Documentation
DESCRIPTION: This entry represents the documentation for the VizierService module. It indicates that all members and inherited members of this module should be documented, pointing to the API surface provided by the service.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/vizier_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
.. automodule:: google.cloud.aiplatform_v1beta1.services.vizier_service
    :members:
    :inherited-members:
```

----------------------------------------

TITLE: Google Cloud Client Library for Python
DESCRIPTION: References the official Google Cloud Client Library for Python, which is used by the samples. Provides links to the library's documentation for detailed API usage, source code browsing, and issue reporting.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/scripts/readme-gen/templates/README.tmpl.rst#_snippet_1

LANGUAGE: APIDOC
CODE:
```
Google Cloud Client Library for Python:
  Documentation: https://googlecloudplatform.github.io/google-cloud-python/
  Source Code: https://github.com/GoogleCloudPlatform/google-cloud-python
  Report Issues: https://github.com/GoogleCloudPlatform/google-cloud-python/issues
```

----------------------------------------

TITLE: TensorboardService API Reference
DESCRIPTION: Provides details on the methods available for interacting with the TensorboardService, including operations for managing Tensorboards, Experiments, and Runs. This section also covers pagers used for handling list operations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/tensorboard_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
TensorboardService:
  Description: Manages Tensorboards, Experiments, and Runs for ML experiment tracking.

  Methods:
    create_tensorboard(request: google.cloud.aiplatform_v1beta1.types.CreateTensorboardRequest) -> google.cloud.aiplatform_v1beta1.types.Tensorboard
      Creates a Tensorboard.
      Parameters:
        request: The request object for creating a Tensorboard.
      Returns: The created Tensorboard resource.

    get_tensorboard(request: google.cloud.aiplatform_v1beta1.types.GetTensorboardRequest) -> google.cloud.aiplatform_v1beta1.types.Tensorboard
      Gets a Tensorboard.
      Parameters:
        request: The request object for getting a Tensorboard.
      Returns: The requested Tensorboard resource.

    update_tensorboard(request: google.cloud.aiplatform_v1beta1.types.UpdateTensorboardRequest) -> google.cloud.aiplatform_v1beta1.types.Tensorboard
      Updates a Tensorboard.
      Parameters:
        request: The request object for updating a Tensorboard.
      Returns: The updated Tensorboard resource.

    delete_tensorboard(request: google.cloud.aiplatform_v1beta1.types.DeleteTensorboardRequest) -> google.protobuf.empty_pb2.Empty
      Deletes a Tensorboard.
      Parameters:
        request: The request object for deleting a Tensorboard.
      Returns: An empty response.

    list_tensorboards(request: google.cloud.aiplatform_v1beta1.types.ListTensorboardsRequest) -> google.cloud.aiplatform_v1beta1.types.ListTensorboardsResponse
      Lists Tensorboards.
      Parameters:
        request: The request object for listing Tensorboards.
      Returns: A list of Tensorboard resources.

    create_experiment(request: google.cloud.aiplatform_v1beta1.types.CreateExperimentRequest) -> google.cloud.aiplatform_v1beta1.types.Experiment
      Creates an Experiment.
      Parameters:
        request: The request object for creating an Experiment.
      Returns: The created Experiment resource.

    get_experiment(request: google.cloud.aiplatform_v1beta1.types.GetExperimentRequest) -> google.cloud.aiplatform_v1beta1.types.Experiment
      Gets an Experiment.
      Parameters:
        request: The request object for getting an Experiment.
      Returns: The requested Experiment resource.

    update_experiment(request: google.cloud.aiplatform_v1beta1.types.UpdateExperimentRequest) -> google.cloud.aiplatform_v1beta1.types.Experiment
      Updates an Experiment.
      Parameters:
        request: The request object for updating an Experiment.
      Returns: The updated Experiment resource.

    delete_experiment(request: google.cloud.aiplatform_v1beta1.types.DeleteExperimentRequest) -> google.protobuf.empty_pb2.Empty
      Deletes an Experiment.
      Parameters:
        request: The request object for deleting an Experiment.
      Returns: An empty response.

    list_experiments(request: google.cloud.aiplatform_v1beta1.types.ListExperimentsRequest) -> google.cloud.aiplatform_v1beta1.types.ListExperimentsResponse
      Lists Experiments.
      Parameters:
        request: The request object for listing Experiments.
      Returns: A list of Experiment resources.

    create_run(request: google.cloud.aiplatform_v1beta1.types.CreateRunRequest) -> google.cloud.aiplatform_v1beta1.types.Run
      Creates a Run.
      Parameters:
        request: The request object for creating a Run.
      Returns: The created Run resource.

    get_run(request: google.cloud.aiplatform_v1beta1.types.GetRunRequest) -> google.cloud.aiplatform_v1beta1.types.Run
      Gets a Run.
      Parameters:
        request: The request object for getting a Run.
      Returns: The requested Run resource.

    update_run(request: google.cloud.aiplatform_v1beta1.types.UpdateRunRequest) -> google.cloud.aiplatform_v1beta1.types.Run
      Updates a Run.
      Parameters:
        request: The request object for updating a Run.
      Returns: The updated Run resource.

    delete_run(request: google.cloud.aiplatform_v1beta1.types.DeleteRunRequest) -> google.protobuf.empty_pb2.Empty
      Deletes a Run.
      Parameters:
        request: The request object for deleting a Run.
      Returns: An empty response.

    list_runs(request: google.cloud.aiplatform_v1beta1.types.ListRunsRequest) -> google.cloud.aiplatform_v1beta1.types.ListRunsResponse
      Lists Runs.
      Parameters:
        request: The request object for listing Runs.
      Returns: A list of Run resources.

  Pager Classes:
    TensorboardServiceAsyncClient:
      Asynchronous client for TensorboardService.

    TensorboardServiceClient:
      Synchronous client for TensorboardService.

    ListTensorboardsPager:
      Pager for ListTensorboards.

    ListExperimentsPager:
      Pager for ListExperiments.

    ListRunsPager:
      Pager for ListRuns.

  Example Usage (Conceptual):
    from google.cloud.aiplatform_v1beta1.services import tensorboard_service

    client = tensorboard_service.TensorboardServiceClient()
    # Example: Create a Tensorboard
    # tensorboard = client.create_tensorboard(request={'parent': 'projects/.../locations/...', 'tensorboard': {'display_name': 'my-tensorboard'}})
    # print(f'Created Tensorboard: {tensorboard.name}')

    # Example: List Experiments
    # for experiment in client.list_experiments(request={'parent': 'projects/.../locations/.../tensorboards/...'}):
    #     print(f'Experiment: {experiment.display_name}')

```

----------------------------------------

TITLE: Reasoning Engine Service Client
DESCRIPTION: Provides access to the Reasoning Engine Service API. This includes methods for managing and interacting with reasoning engines, which are used for complex AI reasoning tasks. It also includes pagers for handling large result sets.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/reasoning_engine_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1beta1.services.reasoning_engine_service
  - Provides the main client for interacting with the Reasoning Engine Service.
  - Methods typically include operations like creating, listing, and managing reasoning engines.
  - Dependencies: google-cloud-aiplatform library.
  - Usage: Instantiate the client and call its methods.

google.cloud.aiplatform_v1beta1.services.reasoning_engine_service.pagers
  - Contains pager classes for methods that return lists of resources.
  - Facilitates efficient iteration over potentially large collections of results.
  - Example: A `ListReasoningEngines` method might return a pager object that handles fetching subsequent pages automatically.
```

----------------------------------------

TITLE: Vertex AI Rag Service API
DESCRIPTION: Provides access to the Vertex AI Retrieval Augmented Generation (RAG) service. This entry outlines the available methods for interacting with RAG functionalities, including data ingestion, retrieval, and generation.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/vertex_rag_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
VertexRagService:
  __init__(client_options=None, credentials_path=None)
    Initializes the Vertex AI Rag Service client.
    Parameters:
      client_options (dict, optional): Client options for the service.
      credentials_path (str, optional): Path to service account credentials.

  // Methods for managing RAG data and operations would be listed here.
  // Example: CreateRagCollection, GetRagCollection, AddDocument, QueryRagCollection, etc.
  // Specific method signatures, parameters, return types, and error conditions are detailed in the full API reference.
```

----------------------------------------

TITLE: FeaturestoreOnlineServingService API Reference
DESCRIPTION: This section details the FeaturestoreOnlineServingService API, which allows for the retrieval of feature values for online predictions. It covers the methods available for interacting with the online serving endpoint of the Featurestore.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/featurestore_online_serving_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
FeaturestoreOnlineServingService:
  Description: Manages online serving for Featurestore data.
  Methods:
    - read_feature_values(entity_type: str, entity_id: str, feature_selector: FeatureSelector, data_format: str = 'PROTO') -> ReadFeatureValuesResponse
      Reads feature values for a given entity.
      Parameters:
        entity_type: The entity type to read features from.
        entity_id: The ID of the entity.
        feature_selector: Specifies which features to retrieve.
        data_format: The desired format for the returned data (e.g., 'PROTO', 'JSON').
      Returns: A ReadFeatureValuesResponse object containing the requested feature values.

    - stream_feature_values(entity_type: str, entity_ids: list[str], feature_selector: FeatureSelector, data_format: str = 'PROTO') -> StreamFeatureValuesResponse
      Streams feature values for multiple entities.
      Parameters:
        entity_type: The entity type to read features from.
        entity_ids: A list of entity IDs.
        feature_selector: Specifies which features to retrieve.
        data_format: The desired format for the returned data.
      Returns: A StreamFeatureValuesResponse object containing the streamed feature values.

  FeatureSelector:
    Description: Defines the selection criteria for features.
    Fields:
      - id: The ID of the feature.
      - name: The name of the feature.
      - selected_features: A list of specific features to select.

  ReadFeatureValuesResponse:
    Description: Response object for reading feature values.
    Fields:
      - feature_values: A list of FeatureValues objects.

  StreamFeatureValuesResponse:
    Description: Response object for streaming feature values.
    Fields:
      - feature_values: A list of FeatureValues objects.

  FeatureValues:
    Description: Represents a set of feature values for an entity.
    Fields:
      - feature_values: A map of feature names to their values.
      - entity_id: The ID of the entity.

  Error Conditions:
    - INVALID_ARGUMENT: If input parameters are invalid.
    - NOT_FOUND: If the entity or feature is not found.
    - UNAUTHENTICATED: If the request is not authenticated.
    - UNAUTHORIZED: If the caller lacks permission.
```

----------------------------------------

TITLE: IndexEndpointService and Pagers
DESCRIPTION: This section documents the IndexEndpointService, which provides methods for managing index endpoints, and its associated pagers, used for iterating through paginated results. It covers the service's core functionalities and how to interact with its responses.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/index_endpoint_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1.services.index_endpoint_service
  This module provides the client for the IndexEndpointService, enabling operations such as creating, deleting, updating, and querying index endpoints.
  It includes methods for managing the lifecycle and configuration of AI Platform index endpoints.

  google.cloud.aiplatform_v1.services.index_endpoint_service.pagers
  This module contains pager classes used to handle paginated responses from the IndexEndpointService. These pagers simplify the process of iterating over large result sets returned by API calls.
```

----------------------------------------

TITLE: Build HTML Documentation
DESCRIPTION: Builds the project's HTML documentation. This command is used to generate the user-facing documentation, typically after making changes that affect API or behavior.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_11

LANGUAGE: bash
CODE:
```
nox -s docs
```

----------------------------------------

TITLE: Google Cloud AI Platform V1 Predict Params API Types
DESCRIPTION: This section details the types and schemas available for configuring prediction parameters in the Google Cloud AI Platform V1 API. It outlines the structure and expected data formats for various prediction-related settings.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/params_v1/types.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Types for Google Cloud Aiplatform V1 Schema Predict Params v1 API

This module provides type definitions for the Google Cloud AI Platform V1 Schema Predict Params. These types are used to define the structure and expected values for parameters when making predictions using the AI Platform V1 API.

Key functionalities include:
- Defining input and output schemas for prediction requests.
- Specifying parameters for model configuration and execution.
- Ensuring type safety and data validation for prediction inputs.

Example Usage:
While specific code examples are not provided in this overview, these types would typically be used within client libraries or SDKs to construct prediction requests, ensuring that all required parameters are correctly formatted according to the API specification.

Related Concepts:
- Model deployment
- Prediction requests
- Schema validation
- Google Cloud AI Platform V1 API
```

----------------------------------------

TITLE: FeatureRegistryService API
DESCRIPTION: Provides access to the FeatureRegistryService client for managing feature registry resources. This includes methods for creating, retrieving, updating, and deleting feature groups and features.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/feature_registry_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1beta1.services.feature_registry_service

This module provides the client for the FeatureRegistryService API.

Key functionalities include:
- Managing Feature Groups: Create, Get, List, Delete Feature Groups.
- Managing Features: Create, Get, List, Update, Delete Features within Feature Groups.
- Batch operations for features.

Example Usage:
```python
from google.cloud.aiplatform_v1beta1.services import feature_registry_service

# TODO: Initialize client with appropriate credentials and project details
# client = feature_registry_service.FeatureRegistryServiceClient()

# Example: List Feature Groups
# request = {}
# page_result = client.list_feature_groups(request=request)
# for page in page_result:
#     print(page)
```

Refer to the specific method documentation for detailed parameter descriptions, return types, and error handling.
```

----------------------------------------

TITLE: Google Cloud AI Platform V1 Predict Params API Types
DESCRIPTION: This section details the types and schemas available for configuring prediction parameters in the Google Cloud AI Platform V1 API. It outlines the structure and expected data formats for various prediction-related settings.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/params_v1/types_.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Types for Google Cloud Aiplatform V1 Schema Predict Params v1 API

This module provides type definitions for the Google Cloud AI Platform V1 Schema Predict Params. These types are used to define the structure and expected values for parameters when making predictions using the AI Platform V1 API.

Key functionalities include:
- Defining input and output schemas for prediction requests.
- Specifying parameters for model configuration and execution.
- Ensuring type safety and data validation for prediction inputs.

Example Usage:
While specific code examples are not provided in this overview, these types would typically be used within client libraries or SDKs to construct prediction requests, ensuring that all required parameters are correctly formatted according to the API specification.

Related Concepts:
- Model deployment
- Prediction requests
- Schema validation
- Google Cloud AI Platform V1 API
```

----------------------------------------

TITLE: Google Cloud AI Platform V1 Training Job Types API
DESCRIPTION: This API documentation details the Python types available for defining Google Cloud AI Platform V1 Training Job schemas. It covers the structure, members, and inheritance of these types, essential for programmatic interaction with AI Platform training job configurations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/definition_v1/types_.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Module: google.cloud.aiplatform.v1.schema.trainingjob.definition_v1.types

Description: Provides Python classes and types for defining the schema of training jobs within Google Cloud AI Platform V1.

Members:
  - :members:
  - :show-inheritance:

Purpose: To offer a structured and programmatic way to represent and interact with training job configurations, including parameters, datasets, and model artifacts.
```

----------------------------------------

TITLE: Google Cloud AI Platform V1 Training Job Types API
DESCRIPTION: This API documentation details the Python types available for defining Google Cloud AI Platform V1 Training Job schemas. It covers the structure, members, and inheritance of these types, essential for programmatic interaction with AI Platform training job configurations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/definition_v1/types.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Module: google.cloud.aiplatform.v1.schema.trainingjob.definition_v1.types

Description: Provides Python classes and types for defining the schema of training jobs within Google Cloud AI Platform V1.

Members:
  - :members:
  - :show-inheritance:

Purpose: To offer a structured and programmatic way to represent and interact with training job configurations, including parameters, datasets, and model artifacts.
```

----------------------------------------

TITLE: FeatureRegistryService Pagers
DESCRIPTION: Contains pager classes for handling paginated responses from the FeatureRegistryService API, allowing for efficient iteration over large result sets.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/feature_registry_service.rst#_snippet_1

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1beta1.services.feature_registry_service.pagers

This module contains pager classes used for iterating over paginated API responses from the FeatureRegistryService.

Commonly includes pagers for:
- ListFeatureGroups
- ListFeatures

These pagers abstract away the complexity of making multiple API calls to fetch all results.

Example Usage:
```python
# Assuming 'client' is an initialized FeatureRegistryServiceClient
# from google.cloud.aiplatform_v1beta1.services import feature_registry_service
# client = feature_registry_service.FeatureRegistryServiceClient()

# request = {}
# page_iterator = client.list_feature_groups(request=request)
# for feature_group in page_iterator:
#     print(feature_group.name)
```

Each pager class typically implements an iterator protocol to yield individual resources from the paginated response.
```

----------------------------------------

TITLE: Get Serving Container Specification
DESCRIPTION: Retrieves the serving container specification for the locally built model. This can be useful for inspecting the configuration of the container before deployment.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/README.md#_snippet_3

LANGUAGE: python
CODE:
```
local_model.get_serving_container_spec()

```

----------------------------------------

TITLE: Google Cloud AI Platform V1beta1 Predict Instance Schema Types
DESCRIPTION: This entry describes the schema types for prediction instances within the Google Cloud AI Platform V1beta1 API. It outlines the structure and expected data formats for inputs used in prediction requests, enabling developers to correctly format their data for model inference.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform/instance_v1beta1.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
GoogleCloudAIPlatformV1beta1PredictInstanceSchema:
  description: Defines the structure for prediction instances in the AI Platform V1beta1 API.
  parameters:
    # Specific parameter types and descriptions would be detailed here if provided in the source text.
    # Example structure:
    # instance: The input data for the prediction request.
    #   type: object
    #   description: A dictionary or JSON object representing the features for prediction.
    #   properties:
    #     feature1: The value for feature 1.
    #       type: string
    #     feature2: The value for feature 2.
    #       type: number
    #     feature3: The value for feature 3.
    #       type: array
    #       items:
    #         type: integer
    # prediction_result: The output from the model prediction.
    #   type: object
    #   description: The result of the model's prediction.
    #   properties:
    #     predicted_label: The predicted class label.
    #       type: string
    #     predicted_score: The confidence score for the prediction.
    #       type: number
  usage:
    # Example of how to structure a prediction instance payload.
    # Example:
    # {
    #   "instance": {
    #     "feature1": "example_value",
    #     "feature2": 123.45,
    #     "feature3": [1, 2, 3]
    #   }
    # }
  related_methods:
    # - Method for submitting prediction requests (e.g., projects.locations.endpoints.predict)
    # - Methods for deploying models and managing endpoints.
```

----------------------------------------

TITLE: AI Platform Schedule Service API
DESCRIPTION: Provides access to the Schedule Service API for managing schedules in Google Cloud AI Platform. Includes methods for creating, retrieving, updating, and deleting schedules, as well as listing schedules with pagination support.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/schedule_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1.services.schedule_service

This module provides the client for the Schedule Service.

Key functionalities include:
- Creating, updating, and deleting schedules.
- Retrieving details of a specific schedule.
- Listing schedules with filtering and pagination.

Dependencies:
- google-cloud-aiplatform library

Related Modules:
- google.cloud.aiplatform_v1.services.schedule_service.pagers: Contains pager classes for handling paginated responses from list operations.
```

----------------------------------------

TITLE: VertexRagDataService API Reference
DESCRIPTION: Provides methods for interacting with the Vertex AI RAG Data Service. This includes operations for creating, retrieving, updating, and deleting RAG data resources, as well as listing and managing associated entities. The service handles data ingestion, indexing, and retrieval configurations for RAG pipelines.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/vertex_rag_data_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
VertexRagDataService:
  __init__(client_options=None, credentials=None, client_config=None)
    Initializes the Vertex AI RAG Data Service client.
    Parameters:
      client_options (google.api_core.client_options.ClientOptions): Optional client options.
      credentials (google.auth.credentials.Credentials): Optional credentials.
      client_config (dict): Optional client configuration.

  create_rag_collection(request: google.cloud.aiplatform_v1beta1.types.CreateRagCollectionRequest) -> google.cloud.aiplatform_v1beta1.types.RagCollection
    Creates a new RAG collection.
    Parameters:
      request (CreateRagCollectionRequest): The request object containing the RAG collection details.
    Returns:
      RagCollection: The created RAG collection resource.

  get_rag_collection(request: google.cloud.aiplatform_v1beta1.types.GetRagCollectionRequest) -> google.cloud.aiplatform_v1beta1.types.RagCollection
    Retrieves a RAG collection.
    Parameters:
      request (GetRagCollectionRequest): The request object containing the RAG collection ID.
    Returns:
      RagCollection: The requested RAG collection resource.

  update_rag_collection(request: google.cloud.aiplatform_v1beta1.types.UpdateRagCollectionRequest) -> google.cloud.aiplatform_v1beta1.types.RagCollection
    Updates a RAG collection.
    Parameters:
      request (UpdateRagCollectionRequest): The request object containing the RAG collection ID and update mask.
    Returns:
      RagCollection: The updated RAG collection resource.

  delete_rag_collection(request: google.cloud.aiplatform_v1beta1.types.DeleteRagCollectionRequest) -> google.api_core.operation.Operation
    Deletes a RAG collection.
    Parameters:
      request (DeleteRagCollectionRequest): The request object containing the RAG collection ID.
    Returns:
      Operation: An operation object representing the long-running deletion process.

  list_rag_collections(request: google.cloud.aiplatform_v1beta1.types.ListRagCollectionsRequest) -> google.api_core.page_iterator.PageIterator
    Lists RAG collections.
    Parameters:
      request (ListRagCollectionsRequest): The request object for listing collections.
    Returns:
      PageIterator: An iterator for RAG collection resources.

  create_rag_document(request: google.cloud.aiplatform_v1beta1.types.CreateRagDocumentRequest) -> google.cloud.aiplatform_v1beta1.types.RagDocument
    Creates a RAG document within a RAG collection.
    Parameters:
      request (CreateRagDocumentRequest): The request object containing the RAG document details.
    Returns:
      RagDocument: The created RAG document resource.

  get_rag_document(request: google.cloud.aiplatform_v1beta1.types.GetRagDocumentRequest) -> google.cloud.aiplatform_v1beta1.types.RagDocument
    Retrieves a RAG document.
    Parameters:
      request (GetRagDocumentRequest): The request object containing the RAG document ID.
    Returns:
      RagDocument: The requested RAG document resource.

  update_rag_document(request: google.cloud.aiplatform_v1beta1.types.UpdateRagDocumentRequest) -> google.cloud.aiplatform_v1beta1.types.RagDocument
    Updates a RAG document.
    Parameters:
      request (UpdateRagDocumentRequest): The request object containing the RAG document ID and update mask.
    Returns:
      RagDocument: The updated RAG document resource.

  delete_rag_document(request: google.cloud.aiplatform_v1beta1.types.DeleteRagDocumentRequest) -> google.api_core.operation.Operation
    Deletes a RAG document.
    Parameters:
      request (DeleteRagDocumentRequest): The request object containing the RAG document ID.
    Returns:
      Operation: An operation object representing the long-running deletion process.

  list_rag_documents(request: google.cloud.aiplatform_v1beta1.types.ListRagDocumentsRequest) -> google.api_core.page_iterator.PageIterator
    Lists RAG documents within a RAG collection.
    Parameters:
      request (ListRagDocumentsRequest): The request object for listing documents.
    Returns:
      PageIterator: An iterator for RAG document resources.

  search_rag_documents(request: google.cloud.aiplatform_v1beta1.types.SearchRagDocumentsRequest) -> google.cloud.aiplatform_v1beta1.types.SearchRagDocumentsResponse
    Searches for RAG documents based on a query.
    Parameters:
      request (SearchRagDocumentsRequest): The request object containing the search query and filters.
    Returns:
      SearchRagDocumentsResponse: The response containing search results.

  add_rag_document_chunk(request: google.cloud.aiplatform_v1beta1.types.AddRagDocumentChunkRequest) -> google.cloud.aiplatform_v1beta1.types.AddRagDocumentChunkResponse
    Adds a chunk to a RAG document.
    Parameters:
      request (AddRagDocumentChunkRequest): The request object containing the document ID and chunk data.
    Returns:
      AddRagDocumentChunkResponse: The response indicating success or failure.

  remove_rag_document_chunk(request: google.cloud.aiplatform_v1beta1.types.RemoveRagDocumentChunkRequest) -> google.cloud.aiplatform_v1beta1.types.RemoveRagDocumentChunkResponse
    Removes a chunk from a RAG document.
    Parameters:
      request (RemoveRagDocumentChunkRequest): The request object containing the document ID and chunk ID.
    Returns:
      RemoveRagDocumentChunkResponse: The response indicating success or failure.

  get_rag_document_chunk(request: google.cloud.aiplatform_v1beta1.types.GetRagDocumentChunkRequest) -> google.cloud.aiplatform_v1beta1.types.RagDocumentChunk
    Retrieves a specific RAG document chunk.
    Parameters:
      request (GetRagDocumentChunkRequest): The request object containing the chunk ID.
    Returns:
      RagDocumentChunk: The requested RAG document chunk.

  list_rag_document_chunks(request: google.cloud.aiplatform_v1beta1.types.ListRagDocumentChunksRequest) -> google.api_core.page_iterator.PageIterator
    Lists all chunks for a given RAG document.
    Parameters:
      request (ListRagDocumentChunksRequest): The request object for listing chunks.
    Returns:
      PageIterator: An iterator for RAG document chunk resources.

  update_rag_document_chunk(request: google.cloud.aiplatform_v1beta1.types.UpdateRagDocumentChunkRequest) -> google.cloud.aiplatform_v1beta1.types.RagDocumentChunk
    Updates a RAG document chunk.
    Parameters:
      request (UpdateRagDocumentChunkRequest): The request object containing the chunk ID and update mask.
    Returns:
      RagDocumentChunk: The updated RAG document chunk.

  delete_rag_document_chunk(request: google.cloud.aiplatform_v1beta1.types.DeleteRagDocumentChunkRequest) -> google.api_core.operation.Operation
    Deletes a RAG document chunk.
    Parameters:
      request (DeleteRagDocumentChunkRequest): The request object containing the chunk ID.
    Returns:
      Operation: An operation object representing the long-running deletion process.

  get_vertex_rag_data_service_client(client_options=None, credentials=None, client_config=None) -> VertexRagDataServiceClient
    Factory method to create a VertexRagDataServiceClient.
    Parameters:
      client_options (google.api_core.client_options.ClientOptions): Optional client options.
      credentials (google.auth.credentials.Credentials): Optional credentials.
      client_config (dict): Optional client configuration.
    Returns:
      VertexRagDataServiceClient: An instance of the client.

  close() -> None
    Closes the client connection.

```

----------------------------------------

TITLE: Train AutoML Tabular Model
DESCRIPTION: Provides an example of training an AutoML tabular model using the Vertex AI SDK. It covers dataset preparation, job configuration, and running the training process with specified parameters.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_12

LANGUAGE: Python
CODE:
```
import google.cloud.aiplatform as aiplatform

# Assuming dataset is a pre-created Vertex AI TabularDataset object
# dataset = aiplatform.TabularDataset('projects/my-project/location/us-central1/datasets/{DATASET_ID}')

job = aiplatform.AutoMLTabularTrainingJob(
  display_name="train-automl",
  optimization_prediction_type="regression",
  optimization_objective="minimize-rmse",
)

model = job.run(
    dataset=dataset,
    target_column="target_column_name",
    training_fraction_split=0.6,
    validation_fraction_split=0.2,
    test_fraction_split=0.2,
    budget_milli_node_hours=1000,
    model_display_name="my-automl-model",
    disable_early_stopping=False,
)
```

----------------------------------------

TITLE: FeaturestoreService Pagers
DESCRIPTION: Documentation for the pagers associated with the FeaturestoreService. Pagers are used to handle large result sets returned by API methods, enabling efficient iteration over data.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/featurestore_service.rst#_snippet_1

LANGUAGE: python
CODE:
```
.. automodule:: google.cloud.aiplatform_v1beta1.services.featurestore_service.pagers
    :members:
    :inherited-members:
```

----------------------------------------

TITLE: Google Cloud AI Platform V1 TrainingJob Definition Types
DESCRIPTION: This entry documents the types available within the google.cloud.aiplatform.v1.schema.trainingjob.definition_v1.types module. It covers the various data structures and classes used to define training jobs in the Google Cloud AI Platform V1 API. The documentation includes all public and undocumented members, along with inheritance information.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform/definition_v1.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Module: google.cloud.aiplatform.v1.schema.trainingjob.definition_v1.types

Description: Defines the schema types for Training Jobs in Google Cloud AI Platform V1.

Members:
  - All public members (:members:)
  - Undocumented members (:undoc-members:)
  - Inheritance information (:show-inheritance:)

Note: This entry represents the API schema types. Specific method signatures, parameters, and return values would be detailed within the actual API client libraries or OpenAPI specifications, which are not directly provided in the input text.
```

----------------------------------------

TITLE: MetadataService Pagers Module - Python
DESCRIPTION: This snippet documents the pagers module for the MetadataService client. Pagers are used to handle paginated responses from API calls, simplifying iteration over large result sets.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/metadata_service.rst#_snippet_1

LANGUAGE: python
CODE:
```
google.cloud.aiplatform_v1beta1.services.metadata_service.pagers
```

----------------------------------------

TITLE: Google Cloud AI Platform V1 Predict Params Types
DESCRIPTION: This section details the types available within the google.cloud.aiplatform.v1.schema.predict.params_v1.types module. It lists members, undocumented members, and shows inheritance for comprehensive API type information.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform/params_v1.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Module: google.cloud.aiplatform.v1.schema.predict.params_v1.types

Description: This module contains the schema types for prediction parameters used in Google Cloud AI Platform V1.

Members:
  - Lists all public members of the module.
Undocumented Members:
  - Lists all members without docstrings.
Show Inheritance:
  - Indicates that inheritance hierarchies for classes within the module are displayed.

Note: Specific type definitions, their parameters, and return values are not detailed in this high-level module description. Refer to the module's source code or specific API documentation for detailed type structures.
```

----------------------------------------

TITLE: Get Predictions from Endpoint
DESCRIPTION: Sends prediction requests to a deployed model on a Vertex AI endpoint. Requires input instances in the expected format.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_24

LANGUAGE: python
CODE:
```
endpoint.predict(instances=[[6.7, 3.1, 4.7, 1.5], [4.6, 3.1, 1.5, 0.2]])
```

----------------------------------------

TITLE: Get Predictions from Vertex AI Endpoint
DESCRIPTION: Sends prediction requests to a deployed Vertex AI Endpoint. Requires a list of instances (data points) to get predictions for. The format of instances depends on the deployed model.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_22

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

# Assume endpoint is already initialized
# endpoint = aiplatform.Endpoint('projects/my-project/locations/us-central1/endpoints/{ENDPOINT_ID}')

predictions = endpoint.predict(instances=[[6.7, 3.1, 4.7, 1.5], [4.6, 3.1, 1.5, 0.2]])
```

----------------------------------------

TITLE: Get Vertex AI Model
DESCRIPTION: Retrieves a Vertex AI Model object using its resource name. This allows interaction with an existing model, such as deploying it or getting its evaluations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_12

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

model = aiplatform.Model('/projects/my-project/locations/us-central1/models/{MODEL_ID}')
```

----------------------------------------

TITLE: Google Cloud AI Platform V1 Predict Instance Types
DESCRIPTION: This section details the types available for the Google Cloud Vertex AI Platform V1 Schema Predict Instance API. It outlines the structure and expected data formats for prediction instances, crucial for integrating with Vertex AI prediction services.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform/instance_v1.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform.v1.schema.predict.instance_v1.types

This module contains type definitions for the Google Cloud Vertex AI Platform V1 Schema Predict Instance API.

It is typically used to define the structure of input data for prediction requests.

Example Usage:

.. code-block:: python

    from google.cloud.aiplatform.v1.schema.predict.instance_v1 import types

    # Assuming a specific prediction instance type like TextClassificationPredictionInstance
    # The actual types would be defined within the module and imported.
    # For demonstration, let's assume a hypothetical structure:
    # instance = types.TextClassificationPredictionInstance(
    #     content='This is a sample text.',
    #     mime_type='text/plain'
    # )

    # The actual available types depend on the specific API schema definition.
    # This directive indicates that the module provides these types.


```

----------------------------------------

TITLE: MetadataService Pagers Module
DESCRIPTION: Documentation for the MetadataService pagers module. Pagers are used to handle large result sets returned by API methods, allowing for efficient iteration over resources. This module contains classes that facilitate fetching lists of metadata resources page by page.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/metadata_service.rst#_snippet_1

LANGUAGE: python
CODE:
```
from google.cloud.aiplatform_v1.services.metadata_service.pagers import list_metadata_stores_pager

# Example usage (conceptual):
# for page in list_metadata_stores_pager.ListMetadataStoresPager(client=metadata_service.MetadataServiceClient(), request={'parent': 'projects/my-project/locations/us-central1'}):
#     for metadata_store in page.metadata_stores:
#         print(metadata_store.name)
```

----------------------------------------

TITLE: Chat with Generative Models
DESCRIPTION: Illustrates how to create and manage chat sessions with generative models, including multimodal chat. It shows starting a chat, sending messages with text and images, and receiving responses.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_4

LANGUAGE: python
CODE:
```
from vertexai.generative_models import GenerativeModel, Image

vision_model = GenerativeModel("gemini-ultra-vision")
vision_chat = vision_model.start_chat()
image = Image.load_from_file("image.jpg")
print(vision_chat.send_message(["I like this image.", image]))
print(vision_chat.send_message("What things do I like?."))
```

----------------------------------------

TITLE: TrainingJob Definition Types
DESCRIPTION: This section details the types available for defining training jobs within the Google Cloud AI Platform V1beta1 Schema. It covers various parameters and structures necessary for configuring and executing machine learning training tasks.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform/definition_v1beta1.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform.v1beta1.schema.trainingjob.definition_v1beta1.types

This module provides data structures and types for defining Google Cloud AI Platform training jobs.

Key types include:

- **TrainingJob**: Represents a complete training job configuration.
  - **displayName**: (str) The user-friendly name of the TrainingJob.
  - **model_name**: (str) The name of the model to be trained.
  - **training_task**: (TrainingTask) Configuration for the actual training task.
  - **compute_resources**: (ComputeResources) Specifies the compute resources for the training job.
  - **service_account**: (str) The service account to use for the training job.
  - **network_tags**: (list[str]) Network tags to apply to the training job.
  - **labels**: (dict[str, str]) User-defined metadata for the training job.

- **TrainingTask**: Defines the specifics of the training process.
  - **training_fraction_split**: (float) Fraction of data to use for training.
  - **validation_fraction_split**: (float) Fraction of data to use for validation.
  - **test_fraction_split**: (float) Fraction of data to use for testing.
  - **training_data_uri**: (str) URI pointing to the training dataset.
  - **validation_data_uri**: (str) URI pointing to the validation dataset.
  - **test_data_uri**: (str) URI pointing to the test dataset.
  - **hyperparameter_tuning_jobs**: (list[HyperparameterTuningJob]) List of hyperparameter tuning jobs.

- **ComputeResources**: Specifies the hardware and software resources for training.
  - **machine_type**: (str) The type of machine to use (e.g., 'n1-standard-4').
  - **accelerator_type**: (AcceleratorType) The type of accelerator (e.g., 'NVIDIA_TESLA_K80').
  - **accelerator_count**: (int) The number of accelerators to use.
  - **disk_size_gb**: (int) The size of the boot disk in GB.
  - **disk_type**: (DiskType) The type of the boot disk (e.g., 'PD_SSD').

- **AcceleratorType**: Enum for supported accelerator types.
  - **ACCELERATOR_TYPE_UNSPECIFIED**: 0
  - **NVIDIA_TESLA_K80**: 1
  - **NVIDIA_TESLA_P100**: 2
  - **NVIDIA_TESLA_V100**: 3
  - **NVIDIA_TESLA_T4**: 4
  - **NVIDIA_TESLA_A100**: 12

- **DiskType**: Enum for supported disk types.
  - **DISK_TYPE_UNSPECIFIED**: 0
  - **PD_SSD**: 1
  - **PD_SATA**: 2

Usage Example:

.. code-block:: python

  from google.cloud.aiplatform.v1beta1.schema.trainingjob import definition_v1beta1

  training_job = definition_v1beta1.TrainingJob(
      display_name='my-custom-training-job',
      training_task=definition_v1beta1.TrainingTask(
          training_data_uri='gs://my-bucket/training-data.csv'
      ),
      compute_resources=definition_v1beta1.ComputeResources(
          machine_type='n1-standard-4',
          accelerator_type='NVIDIA_TESLA_T4',
          accelerator_count=1
      )
  )

This module is generated by Sphinx and reflects the API structure for training job definitions.
```

----------------------------------------

TITLE: VertexRagService API Reference
DESCRIPTION: The VertexRagService provides an interface for interacting with Vertex AI's Retrieval Augmented Generation (RAG) features. It allows developers to manage and utilize RAG capabilities for enhancing large language model applications. Specific methods and their parameters are detailed in the underlying library documentation.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/vertex_rag_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
VertexRagService:
  Description: Manages Retrieval Augmented Generation (RAG) operations within Vertex AI.
  Module: google.cloud.aiplatform_v1.services.vertex_rag_service
  Members: All public members (methods, attributes) of the VertexRagService class are documented.
  Inherited Members: Inherited members from parent classes are also included in the documentation.
  Usage: Instantiate the service client to access its methods for RAG-related tasks.
```

----------------------------------------

TITLE: Get Explainable AI Metadata (TensorFlow 1)
DESCRIPTION: Retrieves metadata for Explainable AI from TensorFlow 1 models stored in Google Cloud Storage. Requires a builder to process the saved model.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_29

LANGUAGE: python
CODE:
```
from google.cloud.aiplatform.explain.metadata.tf.v1 import saved_model_metadata_builder

builder = saved_model_metadata_builder.SavedModelMetadataBuilder(
            'gs://python/to/my/model/dir', tags=[tf.saved_model.tag_constants.SERVING]
        )
generated_md = builder.get_metadata()
```

----------------------------------------

TITLE: GenAiCacheService Pagers Module
DESCRIPTION: This snippet documents the pager objects associated with the GenAiCacheService. Pagers are used for handling paginated responses from API calls, ensuring efficient retrieval of large datasets.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/gen_ai_cache_service.rst#_snippet_1

LANGUAGE: python
CODE:
```
.. automodule:: google.cloud.aiplatform_v1beta1.services.gen_ai_cache_service.pagers
    :members:
    :inherited-members:
```

----------------------------------------

TITLE: Define Currency Exchange Rate Tool
DESCRIPTION: A Python function that retrieves currency exchange rates using the Frankfurter API. It takes currency codes and a date as input and returns the exchange rate data.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_15

LANGUAGE: python
CODE:
```
def get_exchange_rate(
    currency_from: str = "USD",
    currency_to: str = "EUR",
    currency_date: str = "latest",
):
    """Retrieves the exchange rate between two currencies on a specified date.

    Uses the Frankfurter API (https://api.frankfurter.app/) to obtain
    exchange rate data.

    Returns:
        dict: A dictionary containing the exchange rate information.
            Example: {"amount": 1.0, "base": "USD", "date": "2023-11-24",
                "rates": {"EUR": 0.95534}}
    """
    import requests
    response = requests.get(
        f"https://api.frankfurter.app/{currency_date}",
        params={"from": currency_from, "to": currency_to},
    )
    return response.json()
```

----------------------------------------

TITLE: Set System Instructions for Gemini (Python)
DESCRIPTION: Configures system-level instructions for a Gemini model to guide its behavior and response style. This is set during model initialization.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/generative_models/README.md#_snippet_5

LANGUAGE: python
CODE:
```
from vertexai.generative_models import GenerativeModel
model = GenerativeModel(
    "gemini-1.0-pro",
    system_instruction=[
        "Talk like a pirate.",
        "Don't use rude words.",
    ],
)
print(model.generate_content("Why is sky blue?"))
```

----------------------------------------

TITLE: AI Platform V1beta1 Predict Params Schema
DESCRIPTION: This entry describes the schema for prediction parameters used in Google Cloud AI Platform's V1beta1 API. It outlines the types and structure of parameters required for making prediction requests.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/params_v1beta1/types.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Google Cloud AI Platform V1beta1 Predict Params Schema:

This schema defines the structure for parameters used in prediction requests for Google Cloud AI Platform.

Module:
  google.cloud.aiplatform.v1beta1.schema.predict.params_v1beta1.types

Purpose:
  To provide type definitions for configuring prediction requests, including model parameters and execution settings.

Key Components:
  - Parameter definitions for various prediction tasks.
  - Type validation for input parameters.
  - Structure for model-specific configurations.

Example Usage (Conceptual):
  // Assuming a Python client library interaction:
  // from google.cloud.aiplatform.v1beta1.schema.predict.params_v1beta1 import types
  // predict_params = types.PredictParams(
  //     parameters={"temperature": 0.7, "max_output_tokens": 100}
  // )

Related Concepts:
  - Vertex AI Prediction API
  - Model inference parameters
```

----------------------------------------

TITLE: Get Specific Model Evaluation
DESCRIPTION: Demonstrates how to retrieve a specific model evaluation resource for a Vertex AI Model. By default, it fetches the first evaluation if no ID is provided.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_17

LANGUAGE: Python
CODE:
```
import google.cloud.aiplatform as aiplatform

# Assuming model is a Vertex AI Model object
# model = aiplatform.Model('projects/my-project/locations/us-central1/models/{MODEL_ID}')

# returns the first evaluation with no arguments, you can also pass the evaluation ID
evaluation = model.get_model_evaluation()

eval_metrics = evaluation.metrics
```

----------------------------------------

TITLE: Create Text Dataset and Import Data
DESCRIPTION: Demonstrates creating a text dataset and then importing data into it from Google Cloud Storage. This involves two distinct steps: dataset creation and data import.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_8

LANGUAGE: python
CODE:
```
from google.cloud import aiplatform

my_dataset = aiplatform.TextDataset.create(
    display_name="my-dataset")

my_dataset.import_data(
    gcs_source=['gs://path/to/my/dataset.csv'],
```

----------------------------------------

TITLE: Get Existing Image Dataset
DESCRIPTION: Retrieves a previously created Vertex AI Image Dataset using its resource name. This allows access to existing datasets for further operations like training.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_6

LANGUAGE: Python
CODE:
```
dataset = aiplatform.ImageDataset('projects/my-project/location/us-central1/datasets/{DATASET_ID}')
```

----------------------------------------

TITLE: ModelMonitoringService API Reference
DESCRIPTION: Provides the primary interface for interacting with the Model Monitoring Service. This includes methods for managing model monitoring jobs, configurations, and related resources. The service definition implies a set of RPC methods for CRUD operations and querying monitoring data.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/model_monitoring_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ModelMonitoringService:
  __init__(client_options=None, credentials=None, client_info=None)
    Initializes the Model Monitoring Service client.

  create_model_monitoring_job(request=None, retry=None, timeout=None, metadata=None)
    Creates a ModelMonitoringJob. A ModelMonitoringJob is a batch job that monitors models deployed on Vertex AI.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.CreateModelMonitoringJobRequest object.
    Returns: A google.cloud.aiplatform_v1beta1.types.ModelMonitoringJob object.

  get_model_monitoring_job(request=None, retry=None, timeout=None, metadata=None)
    Gets a ModelMonitoringJob.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.GetModelMonitoringJobRequest object.
    Returns: A google.cloud.aiplatform_v1beta1.types.ModelMonitoringJob object.

  list_model_monitoring_jobs(request=None, retry=None, timeout=None, metadata=None)
    Lists ModelMonitoringJobs in a Location.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.ListModelMonitoringJobsRequest object.
    Returns: An iterable of google.cloud.aiplatform_v1beta1.types.ModelMonitoringJob objects.

  search_model_monitoring_jobs(request=None, retry=None, timeout=None, metadata=None)
    Searches for ModelMonitoringJobs.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.SearchModelMonitoringJobsRequest object.
    Returns: An iterable of google.cloud.aiplatform_v1beta1.types.ModelMonitoringJob objects.

  delete_model_monitoring_job(request=None, retry=None, timeout=None, metadata=None)
    Deletes a ModelMonitoringJob.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.DeleteModelMonitoringJobRequest object.
    Returns: An Operation object.

  update_model_monitoring_job(request=None, retry=None, timeout=None, metadata=None)
    Updates a ModelMonitoringJob.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.UpdateModelMonitoringJobRequest object.
    Returns: A google.cloud.aiplatform_v1beta1.types.ModelMonitoringJob object.

  pause_model_monitoring_job(request=None, retry=None, timeout=None, metadata=None)
    Pauses a ModelMonitoringJob.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.PauseModelMonitoringJobRequest object.
    Returns: An Operation object.

  resume_model_monitoring_job(request=None, retry=None, timeout=None, metadata=None)
    Resumes a ModelMonitoringJob.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.ResumeModelMonitoringJobRequest object.
    Returns: An Operation object.

  list_model_monitoring_alerts(request=None, retry=None, timeout=None, metadata=None)
    Lists ModelMonitoringAlerts.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.ListModelMonitoringAlertsRequest object.
    Returns: An iterable of google.cloud.aiplatform_v1beta1.types.ModelMonitoringAlert objects.

  get_model_monitoring_alert(request=None, retry=None, timeout=None, metadata=None)
    Gets a ModelMonitoringAlert.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.GetModelMonitoringAlertRequest object.
    Returns: A google.cloud.aiplatform_v1beta1.types.ModelMonitoringAlert object.

  list_model_monitoring_stats(request=None, retry=None, timeout=None, metadata=None)
    Lists ModelMonitoringStats.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.ListModelMonitoringStatsRequest object.
    Returns: An iterable of google.cloud.aiplatform_v1beta1.types.ModelMonitoringStats objects.

  get_model_monitoring_stats(request=None, retry=None, timeout=None, metadata=None)
    Gets a ModelMonitoringStats.
    Parameters:
      request: A google.cloud.aiplatform_v1beta1.types.GetModelMonitoringStatsRequest object.
    Returns: A google.cloud.aiplatform_v1beta1.types.ModelMonitoringStats object.

ModelMonitoringService.Pagers:
  ListModelMonitoringJobsPager:
    Iterates over pages of ModelMonitoringJobs.
  SearchModelMonitoringJobsPager:
    Iterates over pages of ModelMonitoringJobs.
  ListModelMonitoringAlertsPager:
    Iterates over pages of ModelMonitoringAlerts.
  ListModelMonitoringStatsPager:
    Iterates over pages of ModelMonitoringStats.

```

----------------------------------------

TITLE: Get Explainable AI Metadata for TF2 Models
DESCRIPTION: Shows how to obtain metadata in dictionary format from TensorFlow 2 models using `SavedModelMetadataBuilder`. This metadata is a prerequisite for enabling explainability features in Vertex AI.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_29

LANGUAGE: Python
CODE:
```
from google.cloud.aiplatform.explain.metadata.tf.v2 import saved_model_metadata_builder

builder = saved_model_metadata_builder.SavedModelMetadataBuilder('gs://python/to/my/model/dir')
generated_md = builder.get_metadata()
```

----------------------------------------

TITLE: Quick Start: Deploy Default Open Model
DESCRIPTION: Deploys a specified open model using default configurations. This is ideal for fast prototyping and initial evaluation of model outputs.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/model_garden/README.md#_snippet_1

LANGUAGE: python
CODE:
```
from vertexai import model_garden

model = model_garden.OpenModel("google/paligemma@paligemma-224-float32")
endpoint = model.deploy()
```

----------------------------------------

TITLE: AI Platform V1beta1 Predict Params Schema
DESCRIPTION: This entry describes the schema for prediction parameters used in Google Cloud AI Platform's V1beta1 API. It outlines the types and structure of parameters required for making prediction requests.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/params_v1beta1/types_.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Google Cloud AI Platform V1beta1 Predict Params Schema:

This schema defines the structure for parameters used in prediction requests for Google Cloud AI Platform.

Module:
  google.cloud.aiplatform.v1beta1.schema.predict.params_v1beta1.types

Purpose:
  To provide type definitions for configuring prediction requests, including model parameters and execution settings.

Key Components:
  - Parameter definitions for various prediction tasks.
  - Type validation for input parameters.
  - Structure for model-specific configurations.

Example Usage (Conceptual):
  // Assuming a Python client library interaction:
  // from google.cloud.aiplatform.v1beta1.schema.predict.params_v1beta1 import types
  // predict_params = types.PredictParams(
  //     parameters={"temperature": 0.7, "max_output_tokens": 100}
  // )

Related Concepts:
  - Vertex AI Prediction API
  - Model inference parameters
```

----------------------------------------

TITLE: Google Cloud AI Platform V1beta1 Predict Instance Types
DESCRIPTION: This section details the types available for defining prediction instances within the Google Cloud AI Platform V1beta1 API. It covers the structure and expected data formats for various prediction-related operations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/instance_v1beta1/types_.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Module: google.cloud.aiplatform.v1beta1.schema.predict.instance_v1beta1.types

Description: Provides type definitions for Google Cloud AI Platform V1beta1 prediction instances.

Key Features:
- Defines data structures for prediction requests and responses.
- Supports various machine learning model types and their specific input/output formats.
- Integrates with Google Cloud's AI Platform services for model deployment and inference.

Usage:
Import specific types from this module to construct prediction instances for your AI Platform jobs.

Example:
```python
from google.cloud.aiplatform.v1beta1.schema.predict.instance_v1beta1 import types

# Example of creating a prediction instance (specific structure depends on model type)
# prediction_instance = types.MyModelPredictionInstance(
#     input_data=...,
#     parameters=...
# )
```

Note: The exact types and their fields are determined by the specific model schema being used and are not fully detailed in this general API reference.
```

----------------------------------------

TITLE: Use Explanation Metadata for Deployment (Python)
DESCRIPTION: Demonstrates how to obtain explanation metadata in protobuf format and utilize it during model deployment to an endpoint or model upload. This metadata is crucial for enabling explanations in Vertex AI.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_31

LANGUAGE: Python
CODE:
```
explanation_metadata = builder.get_metadata_protobuf()

# To deploy a model to an endpoint with explanation
model.deploy(..., explanation_metadata=explanation_metadata)

# To deploy a model to a created endpoint with explanation
endpoint.deploy(..., explanation_metadata=explanation_metadata)

# To upload a model with explanation
aiplatform.Model.upload(..., explanation_metadata=explanation_metadata)
```

----------------------------------------

TITLE: Get Explainable AI Metadata for TF1 Models
DESCRIPTION: Retrieves metadata in dictionary format from TensorFlow 1 models using the `SavedModelMetadataBuilder`. This metadata is essential for configuring explanations during model deployment or upload.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_28

LANGUAGE: Python
CODE:
```
from google.cloud.aiplatform.explain.metadata.tf.v1 import saved_model_metadata_builder
import tensorflow as tf

builder = saved_model_metadata_builder.SavedModelMetadataBuilder(
            'gs://python/to/my/model/dir', tags=[tf.saved_model.tag_constants.SERVING]
        )
generated_md = builder.get_metadata()
```

----------------------------------------

TITLE: Deploy Model to Vertex AI Endpoint
DESCRIPTION: Deploys the uploaded Vertex AI model to a managed endpoint. This makes your custom model available for online predictions.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/README.md#_snippet_8

LANGUAGE: python
CODE:
```
endpoint = model.deploy(machine_type="n1-standard-4")

```

----------------------------------------

TITLE: Google Cloud AI Platform V1beta1 Predict Instance Types
DESCRIPTION: This section details the types available for defining prediction instances within the Google Cloud AI Platform V1beta1 API. It covers the structure and expected data formats for various prediction-related operations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/instance_v1beta1/types.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Module: google.cloud.aiplatform.v1beta1.schema.predict.instance_v1beta1.types

Description: Provides type definitions for Google Cloud AI Platform V1beta1 prediction instances.

Key Features:
- Defines data structures for prediction requests and responses.
- Supports various machine learning model types and their specific input/output formats.
- Integrates with Google Cloud's AI Platform services for model deployment and inference.

Usage:
Import specific types from this module to construct prediction instances for your AI Platform jobs.

Example:
```python
from google.cloud.aiplatform.v1beta1.schema.predict.instance_v1beta1 import types

# Example of creating a prediction instance (specific structure depends on model type)
# prediction_instance = types.MyModelPredictionInstance(
#     input_data=...,
#     parameters=...
# )
```

Note: The exact types and their fields are determined by the specific model schema being used and are not fully detailed in this general API reference.
```

----------------------------------------

TITLE: Push Custom Container Image
DESCRIPTION: Pushes the built custom container image to a container registry. This step is necessary before uploading the model to Vertex AI or deploying it.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/README.md#_snippet_6

LANGUAGE: python
CODE:
```
local_model.push_image()

```

----------------------------------------

TITLE: Print Local Container Logs
DESCRIPTION: Prints the logs generated by the locally running container. This is essential for debugging issues during local testing of your custom prediction routine.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/README.md#_snippet_5

LANGUAGE: python
CODE:
```
local_endpoint.print_container_logs(show_all=True)

```

----------------------------------------

TITLE: Get TensorFlow 2 Model Metadata (Python)
DESCRIPTION: Retrieves metadata from TensorFlow 2 models in dictionary format. This requires a Google Cloud Storage path to the model directory and uses the SavedModelMetadataBuilder.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_30

LANGUAGE: Python
CODE:
```
from google.cloud.aiplatform.explain.metadata.tf.v2 import saved_model_metadata_builder

builder = saved_model_metadata_builder.SavedModelMetadataBuilder('gs://python/to/my/model/dir')
generated_md = builder.get_metadata()
```

----------------------------------------

TITLE: IndexEndpointService Transport Hierarchy
DESCRIPTION: Describes the abstract base class and its concrete implementations for IndexEndpointService transports, covering gRPC and REST protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/index_endpoint_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
IndexEndpointServiceTransport:
  Abstract Base Class (ABC) for all transports.

  - IndexEndpointServiceGrpcTransport:
    - Description: Public child for synchronous gRPC transport.
    - Defined in: grpc.py

  - IndexEndpointServiceGrpcAsyncIOTransport:
    - Description: Public child for asynchronous gRPC transport.
    - Defined in: grpc_asyncio.py

  - _BaseIndexEndpointServiceRestTransport:
    - Description: Private child for base REST transport.
    - Contains inner classes like _BaseMETHOD.
    - Defined in: rest_base.py

  - IndexEndpointServiceRestTransport:
    - Description: Public child for synchronous REST transport.
    - Inherits from _BaseIndexEndpointServiceRestTransport.
    - Uses METHOD classes derived from the parent's _BaseMETHOD.
    - Defined in: rest.py
```

----------------------------------------

TITLE: Install Vertex AI SDK (Mac/Linux)
DESCRIPTION: Installs virtualenv and the Google Cloud AI Platform SDK with prediction support for Mac/Linux environments, enabling custom prediction routines.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/README.md#_snippet_0

LANGUAGE: shell
CODE:
```
pip install virtualenv
virtualenv <your-env>
source <your-env>/bin/activate
<your-env>/bin/pip install "google-cloud-aiplatform[prediction]">=1.16.0"
```

----------------------------------------

TITLE: Instantiate Vertex AI GenAI Client
DESCRIPTION: Demonstrates how to instantiate the Google Gen AI SDK client from within the Vertex AI SDK. This requires specifying the project ID and location for the Vertex AI service.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_0

LANGUAGE: Python
CODE:
```
import vertexai
from vertexai import types

# Instantiate GenAI client from Vertex SDK
# Replace with your project ID and location
client = vertexai.Client(project='my-project', location='us-central1')
```

----------------------------------------

TITLE: Install Vertex AI SDK (Windows)
DESCRIPTION: Installs virtualenv and the Google Cloud AI Platform SDK with prediction support for Windows environments, enabling custom prediction routines.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/README.md#_snippet_1

LANGUAGE: shell
CODE:
```
pip install virtualenv
virtualenv <your-env>
<your-env>\Scripts\activate
<your-env>\Scripts\pip.exe install "google-cloud-aiplatform[prediction]">=1.16.0"
```

----------------------------------------

TITLE: IndexEndpointService Transport Hierarchy
DESCRIPTION: Describes the abstract base class and its concrete implementations for IndexEndpointService transports, covering gRPC and REST protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/index_endpoint_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
IndexEndpointServiceTransport:
  Abstract Base Class (ABC) for all transports.

  - IndexEndpointServiceGrpcTransport:
    - Description: Public child for synchronous gRPC transport.
    - Defined in: grpc.py

  - IndexEndpointServiceGrpcAsyncIOTransport:
    - Description: Public child for asynchronous gRPC transport.
    - Defined in: grpc_asyncio.py

  - _BaseIndexEndpointServiceRestTransport:
    - Description: Private child for base REST transport.
    - Contains inner classes like _BaseMETHOD.
    - Defined in: rest_base.py

  - IndexEndpointServiceRestTransport:
    - Description: Public child for synchronous REST transport.
    - Inherits from _BaseIndexEndpointServiceRestTransport.
    - Uses METHOD classes derived from the parent's _BaseMETHOD.
    - Defined in: rest.py
```

----------------------------------------

TITLE: Run Sample Tests
DESCRIPTION: Executes all tests within the samples/snippets directory using a specific Python version (e.g., 3.9). This ensures that the provided code samples function correctly against a real Google Cloud Project.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_12

LANGUAGE: bash
CODE:
```
cd samples/snippets
nox -s py-3.9
```

----------------------------------------

TITLE: VizierService Pagers Documentation
DESCRIPTION: This entry details the documentation for the pagers associated with the VizierService. It specifies that all members and inherited members of the pager module should be included in the documentation, covering features like list responses and iteration.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/vizier_service.rst#_snippet_1

LANGUAGE: APIDOC
CODE:
```
.. automodule:: google.cloud.aiplatform_v1beta1.services.vizier_service.pagers
    :members:
    :inherited-members:
```

----------------------------------------

TITLE: MetadataService Module
DESCRIPTION: Documentation for the main MetadataService module. This module provides core functionalities for interacting with AI Platform metadata, including methods for creating, retrieving, updating, and deleting metadata resources. It typically includes client initialization and service-level operations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/metadata_service.rst#_snippet_0

LANGUAGE: python
CODE:
```
from google.cloud.aiplatform_v1.services import metadata_service

# Example usage (conceptual):
# client = metadata_service.MetadataServiceClient()
# response = client.list_metadata_stores(parent='projects/my-project/locations/us-central1')
# print(response)
```

----------------------------------------

TITLE: Get Specific Vertex AI Model Evaluation
DESCRIPTION: Fetches a specific model evaluation resource for a Vertex AI Model, either the first one by default or by providing an evaluation ID. It returns the evaluation object containing metrics.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_16

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

model = aiplatform.Model('projects/my-project/locations/us-central1/models/{MODEL_ID}')

# Get the first evaluation
evaluation = model.get_model_evaluation()

# Get a specific evaluation by ID
# evaluation = model.get_model_evaluation(evaluation_id='{EVALUATION_ID}')

eval_metrics = evaluation.metrics
```

----------------------------------------

TITLE: Test Container Locally with Prediction and Health Check
DESCRIPTION: Deploys the custom container to a local endpoint for testing. It allows you to send prediction requests and perform health checks against your model before pushing it to a registry or deploying to Vertex AI.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/README.md#_snippet_4

LANGUAGE: python
CODE:
```
with local_model.deploy_to_local_endpoint(
    artifact_uri="{GCS_PATH_TO_MODEL_ARTIFACTS}",
    credential_path="{PATH_TO_CREDENTIALS}",
) as local_endpoint:
    predict_response = local_endpoint.predict(
        request_file="{PATH_TO_INPUT_FILE}",
        headers={{ANY_NEEDED_HEADERS}},
    )
    
    health_check_response = local_endpoint.run_health_check()

```

----------------------------------------

TITLE: Upload Model to Vertex AI
DESCRIPTION: Uploads the custom container model to Vertex AI. This involves associating the model with your Vertex AI project, providing a display name, and specifying the artifact URI where model artifacts are stored.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/README.md#_snippet_7

LANGUAGE: python
CODE:
```
from google.cloud import aiplatform

model = aiplatform.Model.upload(
    local_model=local_model,
    display_name="{MODEL_DISPLAY_NAME}",
    artifact_uri="{GCS_PATH_TO_MODEL_ARTIFACTS}",
)

```

----------------------------------------

TITLE: Install google-api-core
DESCRIPTION: Installs google-api-core version 2.21.0. This dependency is used for testing with REST async support.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_0

LANGUAGE: python
CODE:
```
google-api-core==2.21.0 # Tests google-api-core with rest async support
```

----------------------------------------

TITLE: Create Local Custom Prediction Routine Model
DESCRIPTION: Creates a local model object representing a custom prediction routine. This involves specifying the source directory for your code, the target Docker image name, your custom predictor and handler classes, and a requirements file if needed.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/prediction/README.md#_snippet_2

LANGUAGE: python
CODE:
```
from google.cloud.aiplatform.prediction import LocalModel

# {import your predictor and handler}

local_model = LocalModel.create_cpr_model(
    "{PATH_TO_THE_SOURCE_DIR}",
    f"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE}",
    predictor={{PREDICTOR_CLASS}},
    handler={{HANDLER_CLASS}},
    requirements_path="{PATH_TO_REQUIREMENTS_TXT}",
)

```

----------------------------------------

TITLE: Basic Text Generation with Gemini (Python)
DESCRIPTION: Demonstrates basic text generation using a Gemini model. It initializes a GenerativeModel instance and calls the generate_content method with a text prompt.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/generative_models/README.md#_snippet_2

LANGUAGE: python
CODE:
```
from vertexai.generative_models import GenerativeModel
model = GenerativeModel("gemini-pro")
print(model.generate_content("Why is sky blue?"))
```

----------------------------------------

TITLE: TensorboardService Pagers
DESCRIPTION: Documentation for the pager objects used by the TensorboardService to handle paginated responses for listing resources. These pagers facilitate efficient iteration over large result sets.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/tensorboard_service.rst#_snippet_1

LANGUAGE: APIDOC
CODE:
```
ListTensorboardsPager:
  __init__(method, request, response, *, retry=google.api_core.gapic_v1.method.DEFAULT, timeout=google.api_core.gapic_v1.method.DEFAULT, metadata=None)
    Initializes the ListTensorboardsPager.
    Parameters:
      method: The method to call for fetching pages.
      request: The initial request object.
      response: The initial response object.
      retry: Retry configuration.
      timeout: Timeout configuration.
      metadata: Metadata for the request.
    Attributes:
      next_page_token (str): The token for the next page.
      tensorboards (list[google.cloud.aiplatform_v1.types.Tensorboard]): The list of Tensorboards in the current page.

ListTensorboardExperimentsPager:
  __init__(method, request, response, *, retry=google.api_core.gapic_v1.method.DEFAULT, timeout=google.api_core.gapic_v1.method.DEFAULT, metadata=None)
    Initializes the ListTensorboardExperimentsPager.
    Parameters:
      method: The method to call for fetching pages.
      request: The initial request object.
      response: The initial response object.
      retry: Retry configuration.
      timeout: Timeout configuration.
      metadata: Metadata for the request.
    Attributes:
      next_page_token (str): The token for the next page.
      tensorboard_experiments (list[google.cloud.aiplatform_v1.types.TensorboardExperiment]): The list of TensorboardExperiments in the current page.

ListTensorboardRunsPager:
  __init__(method, request, response, *, retry=google.api_core.gapic_v1.method.DEFAULT, timeout=google.api_core.gapic_v1.method.DEFAULT, metadata=None)
    Initializes the ListTensorboardRunsPager.
    Parameters:
      method: The method to call for fetching pages.
      request: The initial request object.
      response: The initial response object.
      retry: Retry configuration.
      timeout: Timeout configuration.
      metadata: Metadata for the request.
    Attributes:
      next_page_token (str): The token for the next page.
      tensorboard_runs (list[google.cloud.aiplatform_v1.types.TensorboardRun]): The list of TensorboardRuns in the current page.

ReadTensorboardTimeseriesDataPager:
  __init__(method, request, response, *, retry=google.api_core.gapic_v1.method.DEFAULT, timeout=google.api_core.gapic_v1.method.DEFAULT, metadata=None)
    Initializes the ReadTensorboardTimeseriesDataPager.
    Parameters:
      method: The method to call for fetching pages.
      request: The initial request object.
      response: The initial response object.
      retry: Retry configuration.
      timeout: Timeout configuration.
      metadata: Metadata for the request.
    Attributes:
      next_page_token (str): The token for the next page.
      timeseries_data (list[google.cloud.aiplatform_v1.types.ReadTensorboardTimeseriesDataResponse.TimeseriesData]): The list of TimeseriesData in the current page.

ListTensorboardTimeseriesPager:
  __init__(method, request, response, *, retry=google.api_core.gapic_v1.method.DEFAULT, timeout=google.api_core.gapic_v1.method.DEFAULT, metadata=None)
    Initializes the ListTensorboardTimeseriesPager.
    Parameters:
      method: The method to call for fetching pages.
      request: The initial request object.
      response: The initial response object.
      retry: Retry configuration.
      timeout: Timeout configuration.
      metadata: Metadata for the request.
    Attributes:
      next_page_token (str): The token for the next page.
      tensorboard_timeseries (list[google.cloud.aiplatform_v1.types.TensorboardTimeseries]): The list of TensorboardTimeseries in the current page.

BatchReadTensorboardTimeseriesDataPager:
  __init__(method, request, response, *, retry=google.api_core.gapic_v1.method.DEFAULT, timeout=google.api_core.gapic_v1.method.DEFAULT, metadata=None)
    Initializes the BatchReadTensorboardTimeseriesDataPager.
    Parameters:
      method: The method to call for fetching pages.
      request: The initial request object.
      response: The initial response object.
      retry: Retry configuration.
      timeout: Timeout configuration.
      metadata: Metadata for the request.
    Attributes:
      next_page_token (str): The token for the next page.
      batch_timeseries_data (list[google.cloud.aiplatform_v1.types.BatchReadTensorboardTimeseriesDataResponse.BatchTimeseriesData]): The list of BatchTimeseriesData in the current page.

```

----------------------------------------

TITLE: Clone python-docs-samples Repository (Bash)
DESCRIPTION: Clones the official Google Cloud Python samples repository from GitHub. This is the first step to obtain the sample code for AI Platform and other Google Cloud services.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/scripts/readme-gen/templates/install_deps.tmpl.rst#_snippet_0

LANGUAGE: bash
CODE:
```
git clone https://github.com/GoogleCloudPlatform/python-docs-samples.git
```

----------------------------------------

TITLE: Install proto-plus
DESCRIPTION: Installs the proto-plus library, which is a dependency for the project.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_2

LANGUAGE: python
CODE:
```
proto-plus
```

----------------------------------------

TITLE: VizierService Client Initialization
DESCRIPTION: Demonstrates how to initialize the VizierService client for interacting with Google Cloud AI Platform's Vizier service. This client is used to manage and run experiments.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/vizier_service.rst#_snippet_0

LANGUAGE: python
CODE:
```
from google.cloud.aiplatform.v1.services import vizier_service

# Initialize the client
client = vizier_service.VizierServiceClient()

# Example usage (conceptual):
# operation = client.create_study(parent='projects/PROJECT_ID/locations/LOCATION_ID', study=study_body)
# print(operation.result())
```

----------------------------------------

TITLE: MetadataService Module - Python
DESCRIPTION: This snippet documents the main MetadataService module for the AI Platform v1beta1 client. It covers the primary client interface for interacting with metadata resources.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/metadata_service.rst#_snippet_0

LANGUAGE: python
CODE:
```
google.cloud.aiplatform_v1beta1.services.metadata_service
```

----------------------------------------

TITLE: JobService Transport Hierarchy
DESCRIPTION: Describes the inheritance structure of JobService transports, detailing the abstract base class and its concrete implementations for gRPC and REST protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/job_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
JobServiceTransport:
  Abstract Base Class (ABC) for all JobService transports.

  Public Children:
    - JobServiceGrpcTransport:
        Description: Synchronous gRPC transport implementation.
        Source: grpc.py

    - JobServiceGrpcAsyncIOTransport:
        Description: Asynchronous gRPC transport implementation using asyncio.
        Source: grpc_asyncio.py

    - JobServiceRestTransport:
        Description: Synchronous REST transport implementation.
        Inherits from: _BaseJobServiceRestTransport
        Includes: Inner classes `METHOD` derived from parent's `_BaseMETHOD`.
        Source: rest.py

  Private Children:
    - _BaseJobServiceRestTransport:
        Description: Base class for REST transport, providing common functionality.
        Includes: Inner classes `_BaseMETHOD`.
        Source: rest_base.py
```

----------------------------------------

TITLE: Transport Inheritance Structure
DESCRIPTION: Describes the class hierarchy for transport implementations in the AI Platform Python client library. It details the base abstract class and its concrete derivations for gRPC and REST protocols, specifying their synchronous/asynchronous nature and implementation files.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/model_monitoring_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ModelMonitoringServiceTransport:
  - Base abstract class for all transports.

  Public Children:
  - ModelMonitoringServiceGrpcTransport:
    - For synchronous gRPC transport.
    - Defined in: grpc.py
  - ModelMonitoringServiceGrpcAsyncIOTransport:
    - For asynchronous gRPC transport.
    - Defined in: grpc_asyncio.py
  - ModelMonitoringServiceRestTransport:
    - For synchronous REST transport.
    - Inherits from _BaseModelMonitoringServiceRestTransport.
    - Contains inner classes `METHOD` derived from parent's `_BaseMETHOD`.
    - Defined in: rest.py

  Private Children:
  - _BaseModelMonitoringServiceRestTransport:
    - Base REST transport.
    - Contains inner classes `_BaseMETHOD`.
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: MetadataService Transport Hierarchy
DESCRIPTION: Details the inheritance structure for MetadataService transports, including the abstract base class and its concrete synchronous and asynchronous implementations for gRPC and REST protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/metadata_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
MetadataServiceTransport (ABC)
  - Base class for all MetadataService transports.

  MetadataServiceGrpcTransport
  - Public child of MetadataServiceTransport.
  - Implements synchronous gRPC transport.
  - Defined in: grpc.py

  MetadataServiceGrpcAsyncIOTransport
  - Public child of MetadataServiceTransport.
  - Implements asynchronous gRPC transport.
  - Defined in: grpc_asyncio.py

  _BaseMetadataServiceRestTransport
  - Private child of MetadataServiceTransport.
  - Base class for REST transport.
  - Contains inner classes like _BaseMETHOD.
  - Defined in: rest_base.py

  MetadataServiceRestTransport
  - Public child of _BaseMetadataServiceRestTransport.
  - Implements synchronous REST transport.
  - Contains inner classes METHOD derived from _BaseMETHOD.
  - Defined in: rest.py
```

----------------------------------------

TITLE: JobService Transport Hierarchy
DESCRIPTION: Describes the inheritance structure of JobService transports, detailing the abstract base class and its concrete implementations for gRPC and REST protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/job_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
JobServiceTransport:
  Abstract Base Class (ABC) for all JobService transports.

  Public Children:
    - JobServiceGrpcTransport:
        Description: Synchronous gRPC transport implementation.
        Source: grpc.py

    - JobServiceGrpcAsyncIOTransport:
        Description: Asynchronous gRPC transport implementation using asyncio.
        Source: grpc_asyncio.py

    - JobServiceRestTransport:
        Description: Synchronous REST transport implementation.
        Inherits from: _BaseJobServiceRestTransport
        Includes: Inner classes `METHOD` derived from parent's `_BaseMETHOD`.
        Source: rest.py

  Private Children:
    - _BaseJobServiceRestTransport:
        Description: Base class for REST transport, providing common functionality.
        Includes: Inner classes `_BaseMETHOD`.
        Source: rest_base.py
```

----------------------------------------

TITLE: FeaturestoreService Module
DESCRIPTION: Documentation for the main FeaturestoreService module in the AI Platform client library. This module provides access to methods for managing feature stores, entity types, and feature values.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/featurestore_service.rst#_snippet_0

LANGUAGE: python
CODE:
```
.. automodule:: google.cloud.aiplatform_v1beta1.services.featurestore_service
    :members:
    :inherited-members:
```

----------------------------------------

TITLE: Create and Import Text Dataset
DESCRIPTION: Demonstrates creating a Vertex AI Text Dataset and then importing data into it from GCS. It specifies the import schema URI for multi-label classification.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_5

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

my_dataset = aiplatform.TextDataset.create(
    display_name="my-dataset")

my_dataset.import_data(
    gcs_source=['gs://path/to/my/dataset.csv'],
    import_schema_uri=aiplatform.schema.dataset.ioformat.text.multi_label_classification
)
```

----------------------------------------

TITLE: Migration Service Module
DESCRIPTION: Documents the main Migration Service module, including all its public members and inherited attributes. This directive indicates that the service's core functionalities are exposed through this module.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/migration_service.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
.. automodule:: google.cloud.aiplatform_v1beta1.services.migration_service
    :members:
    :inherited-members:
```

----------------------------------------

TITLE: Create Vertex AI Endpoint
DESCRIPTION: Creates a new Vertex AI endpoint resource. Endpoints are used to host deployed models for online predictions.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_22

LANGUAGE: python
CODE:
```
endpoint = aiplatform.Endpoint.create(display_name='my-endpoint')
```

----------------------------------------

TITLE: Basic Text Generation
DESCRIPTION: Demonstrates how to perform basic text generation using the Gemini-Pro model. It involves importing the GenerativeModel class and calling the generate_content method with a text prompt.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_2

LANGUAGE: python
CODE:
```
from vertexai.generative_models import GenerativeModel

model = GenerativeModel("gemini-pro")
print(model.generate_content("Why is sky blue?"))
```

----------------------------------------

TITLE: MetadataService Transport Hierarchy
DESCRIPTION: Details the inheritance structure for MetadataService transports, including the abstract base class and its concrete synchronous and asynchronous implementations for gRPC and REST protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/metadata_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
MetadataServiceTransport (ABC)
  - Base class for all MetadataService transports.

  MetadataServiceGrpcTransport
  - Public child of MetadataServiceTransport.
  - Implements synchronous gRPC transport.
  - Defined in: grpc.py

  MetadataServiceGrpcAsyncIOTransport
  - Public child of MetadataServiceTransport.
  - Implements asynchronous gRPC transport.
  - Defined in: grpc_asyncio.py

  _BaseMetadataServiceRestTransport
  - Private child of MetadataServiceTransport.
  - Base class for REST transport.
  - Contains inner classes like _BaseMETHOD.
  - Defined in: rest_base.py

  MetadataServiceRestTransport
  - Public child of _BaseMetadataServiceRestTransport.
  - Implements synchronous REST transport.
  - Contains inner classes METHOD derived from _BaseMETHOD.
  - Defined in: rest.py
```

----------------------------------------

TITLE: Model Garden Service Transport Hierarchy
DESCRIPTION: Describes the base abstract class and its concrete public and private child classes for handling synchronous and asynchronous communication with the Model Garden Service.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/model_garden_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ModelGardenServiceTransport Hierarchy:

  ModelGardenServiceTransport
    - Abstract Base Class (ABC) for all transports.

  Public Children:
    - ModelGardenServiceGrpcTransport
      - Implements synchronous gRPC transport.
      - Defined in: grpc.py

    - ModelGardenServiceGrpcAsyncIOTransport
      - Implements asynchronous gRPC transport.
      - Defined in: grpc_asyncio.py

    - ModelGardenServiceRestTransport
      - Implements synchronous REST transport.
      - Inherits from _BaseModelGardenServiceRestTransport.
      - Uses inner classes 'METHOD' derived from parent's '_BaseMETHOD'.
      - Defined in: rest.py

  Private Children:
    - _BaseModelGardenServiceRestTransport
      - Base REST transport with inner classes '_BaseMETHOD'.
      - Defined in: rest_base.py
```

----------------------------------------

TITLE: Upload Vertex AI Model
DESCRIPTION: Demonstrates the process of uploading a custom model to Vertex AI. This involves specifying the model's display name, artifact URI, and serving container image.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_14

LANGUAGE: Python
CODE:
```
import google.cloud.aiplatform as aiplatform

model = aiplatform.Model.upload(
    display_name='my-model',
    artifact_uri="gs://python/to/my/model/dir",
    serving_container_image_uri="us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-2:latest",
)
```

----------------------------------------

TITLE: Multimodal Generation with Images/Videos (Python)
DESCRIPTION: Shows how to use multimodal generation with Gemini models, supporting local files and Cloud Storage URIs for images and videos. It initializes a vision-capable model and sends content including media parts.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/generative_models/README.md#_snippet_3

LANGUAGE: python
CODE:
```
from vertexai.generative_models import GenerativeModel, Image, Part

vision_model = GenerativeModel("gemini-pro-vision")

# Local image
image = Image.load_from_file("image.jpg")
print(vision_model.generate_content(["What is shown in this image?", image]))

# Image from Cloud Storage
image_part = Part.from_uri("gs://download.tensorflow.org/example_images/320px-Felis_catus-cat_on_snow.jpg", mime_type="image/jpeg")
print(vision_model.generate_content([image_part, "Describe this image?"]))

# Text and video
video_part = Part.from_uri("gs://cloud-samples-data/video/animals.mp4", mime_type="video/mp4")
print(vision_model.generate_content(["What is in the video? ", video_part]))
```

----------------------------------------

TITLE: Install mock
DESCRIPTION: Installs the mock library version 4.0.2, commonly used for unit testing to isolate components.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_3

LANGUAGE: python
CODE:
```
mock==4.0.2
```

----------------------------------------

TITLE: Create and Run Vertex AI Pipeline (Synchronous)
DESCRIPTION: Creates and executes a Vertex AI Pipeline synchronously, monitoring its progress until completion. Requires pipeline definition, parameters, and root path.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_27

LANGUAGE: python
CODE:
```
# Instantiate PipelineJob object
pl = PipelineJob(
    display_name="My first pipeline",

    # Whether or not to enable caching
    # True = always cache pipeline step result
    # False = never cache pipeline step result
    # None = defer to cache option for each pipeline component in the pipeline definition
    enable_caching=False,

    # Local or GCS path to a compiled pipeline definition
    template_path="pipeline.json",

    # Dictionary containing input parameters for your pipeline
    parameter_values=parameter_values,

    # GCS path to act as the pipeline root
    pipeline_root=pipeline_root,
)

# Execute pipeline in Vertex AI and monitor until completion
pl.run(
  # Email address of service account to use for the pipeline run
  # You must have iam.serviceAccounts.actAs permission on the service account to use it
  service_account=service_account,

  # Whether this function call should be synchronous (wait for pipeline run to finish before terminating)
  # or asynchronous (return immediately)
  sync=True
)
```

----------------------------------------

TITLE: Clone and Configure Repository
DESCRIPTION: Steps to fork, clone, and set up the python-aiplatform repository for development. This includes configuring remotes to pull changes from the official repository.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_0

LANGUAGE: bash
CODE:
```
$ cd ${HOME}
$ git clone git@github.com:USERNAME/python-aiplatform.git hack-on-python-aiplatform
$ cd hack-on-python-aiplatform
$ git remote add upstream git@github.com:googleapis/python-aiplatform.git
$ git fetch upstream
$ git merge upstream/main
```

----------------------------------------

TITLE: Python AI Platform Dependencies
DESCRIPTION: This snippet lists the Python dependencies and their version constraints for the google-googleapis/python-aiplatform project. It includes libraries like google-api-core, google-auth, proto-plus, and others, with specific versions pinned for compatibility and testing purposes.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.8.txt#_snippet_0

LANGUAGE: python
CODE:
```
# -*- coding: utf-8 -*-
# This constraints file is used to check that lower bounds
# are correct in setup.py
# List *all* library dependencies and extras in this file.
google-api-core==2.17.1 # Increased for gapic owlbot presubmit tests
google-auth==2.14.1 # Tests google-auth without rest async support
proto-plus==1.22.3
protobuf
mock==4.0.2
google-cloud-storage==2.2.1 # Increased for kfp 2.0 compatibility
packaging==24.1 # Increased to unbreak canonicalize_version error (b/377774673)
grpcio-testing==1.34.0
pytest-xdist==3.3.1 # Pinned to unbreak unit tests
ray==2.4.0 # Pinned until 2.9.3 is verified for Ray tests
google-vizier==0.1.21
google-adk==0.0.2
```

----------------------------------------

TITLE: Model Garden Service Transport Hierarchy
DESCRIPTION: Describes the base abstract class and its concrete public and private child classes for handling synchronous and asynchronous communication with the Model Garden Service.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/model_garden_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ModelGardenServiceTransport Hierarchy:

  ModelGardenServiceTransport
    - Abstract Base Class (ABC) for all transports.

  Public Children:
    - ModelGardenServiceGrpcTransport
      - Implements synchronous gRPC transport.
      - Defined in: grpc.py

    - ModelGardenServiceGrpcAsyncIOTransport
      - Implements asynchronous gRPC transport.
      - Defined in: grpc_asyncio.py

    - ModelGardenServiceRestTransport
      - Implements synchronous REST transport.
      - Inherits from _BaseModelGardenServiceRestTransport.
      - Uses inner classes 'METHOD' derived from parent's '_BaseMETHOD'.
      - Defined in: rest.py

  Private Children:
    - _BaseModelGardenServiceRestTransport
      - Base REST transport with inner classes '_BaseMETHOD'.
      - Defined in: rest_base.py
```

----------------------------------------

TITLE: Model Service Transport Hierarchy
DESCRIPTION: Describes the inheritance structure for Model Service transports. It outlines the abstract base class and its public and private children for synchronous/asynchronous gRPC and REST implementations, specifying their respective source files.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/model_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ModelServiceTransport:
  Abstract base class for all transports.

  Public Children:
    ModelServiceGrpcTransport:
      Description: Synchronous gRPC transport.
      Defined in: grpc.py

    ModelServiceGrpcAsyncIOTransport:
      Description: Asynchronous gRPC transport.
      Defined in: grpc_asyncio.py

    ModelServiceRestTransport:
      Description: Synchronous REST transport.
      Inherits from: _BaseModelServiceRestTransport
      Contains inner classes: METHOD (derived from _BaseMETHOD)
      Defined in: rest.py

  Private Children:
    _BaseModelServiceRestTransport:
      Description: Base REST transport with inner classes.
      Contains inner classes: _BaseMETHOD
      Defined in: rest_base.py
```

----------------------------------------

TITLE: Gemini Grounding with Google Search in Python
DESCRIPTION: Shows how to configure a Gemini model to ground its responses using Google Search. This involves creating a tool that utilizes Google Search retrieval and generating content based on a query.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/generative_models/README.md#_snippet_9

LANGUAGE: python
CODE:
```
from vertexai import generative_models
from vertexai.generative_models import GenerativeModel, Tool

model=GenerativeModel(
    "gemini-pro",
    tools=[Tool.from_google_search_retrieval(
        google_search_retrieval=generative_models.grounding.GoogleSearchRetrieval(
            dynamic_retrieval_config=generative_models.grounding.DynamicRetrievalConfig(
                mode=generative_models.grounding.DynamicRetrievalConfig.Mode.MODE_DYNAMIC)))
    ],
)

response = model.generate_content("Who won Euro 2024")

print(response.text)

# Checking grounding metadata. It contains grounding supports and the follow-up search entry widget.
if response.candidates:
    print(response.candidates[0].grounding_metadata)
```

----------------------------------------

TITLE: Function Calling with Generative Models
DESCRIPTION: Explains how to enable function calling for generative models. This involves defining tool functions with JSON schema for parameters, creating a Tool object, and using it with the model to generate function calls and process responses.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_6

LANGUAGE: python
CODE:
```
from vertexai.generative_models import GenerativeModel, Part, Tool, FunctionDeclaration

# Define a function declaration for getting weather
get_current_weather_func = FunctionDeclaration(
    name="get_current_weather",
    description="Get the current weather in a given location",
    parameters={
        "type": "object",
        "properties": {
            "location": {
                "type": "string",
                "description": "The city and state, e.g. San Francisco, CA"
            },
            "unit": {
                "type": "string",
                "enum": [
                    "celsius",
                    "fahrenheit",
                ]
            }
        },
        "required": [
            "location"
        ]
    }
)

# Create a tool with the function declaration
weather_tool = Tool(
    function_declarations=[get_current_weather_func],
)

# Use tools in chat
model = GenerativeModel(
    "gemini-pro",
    tools=[weather_tool],
)
chat = model.start_chat()

# Send a message, model responds with a function call
print(chat.send_message("What is the weather like in Boston?"))

# Send a function response to the model
print(chat.send_message(
    Part.from_function_response(
        name="get_current_weather",
        response={
            "content": {"weather": "super nice"},
        }
    ),
))
```

----------------------------------------

TITLE: Schedule Service Transport Hierarchy
DESCRIPTION: Details the inheritance structure for AI Platform Schedule Service transports. It outlines the abstract base class and its concrete implementations for gRPC and REST, including synchronous and asynchronous variants.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/schedule_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ScheduleServiceTransport:
  Abstract Base Class (ABC) for all transport implementations.

  Public Children:
    - ScheduleServiceGrpcTransport: Implements synchronous gRPC transport. Defined in grpc.py.
    - ScheduleServiceGrpcAsyncIOTransport: Implements asynchronous gRPC transport. Defined in grpc_asyncio.py.
    - ScheduleServiceRestTransport: Implements synchronous REST transport. Defined in rest.py.

  Private Children:
    - _BaseScheduleServiceRestTransport: Base class for REST transport, containing inner classes _BaseMETHOD. Defined in rest_base.py.

  Inner Classes:
    - _BaseMETHOD: Inner classes within _BaseScheduleServiceRestTransport, serving as base definitions for REST methods.
    - METHOD: Inner classes within ScheduleServiceRestTransport, derived from _BaseMETHOD, representing concrete REST method implementations.
```

----------------------------------------

TITLE: Run Custom Training Job
DESCRIPTION: Illustrates how to define and run a custom training job using the Vertex AI SDK. This includes specifying the script, container, requirements, and model serving container.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_11

LANGUAGE: Python
CODE:
```
import google.cloud.aiplatform as aiplatform

# Assuming my_dataset is a pre-created Vertex AI Dataset object
# my_dataset = aiplatform.ImageDataset(...)

job = aiplatform.CustomTrainingJob(
    display_name="my-training-job",
    script_path="training_script.py",
    container_uri="us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-2:latest",
    requirements=["gcsfs==0.7.1"],
    model_serving_container_image_uri="us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-2:latest",
)

model = job.run(
    my_dataset,
    replica_count=1,
    machine_type="n1-standard-4",
    accelerator_type='NVIDIA_TESLA_K80',
    accelerator_count=1
)
```

----------------------------------------

TITLE: Evaluation Service Transport Hierarchy
DESCRIPTION: Describes the inheritance structure for EvaluationService transports, including gRPC and REST implementations. This outlines the base class and its public and private children for different communication protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/evaluation_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
EvaluationServiceTransport:
  - Base class for all transports.

  Public Children:
  - EvaluationServiceGrpcTransport:
    - Type: sync gRPC transport
    - Defined in: grpc.py
  - EvaluationServiceGrpcAsyncIOTransport:
    - Type: async gRPC transport
    - Defined in: grpc_asyncio.py
  - EvaluationServiceRestTransport:
    - Type: sync REST transport
    - Derived from: _BaseEvaluationServiceRestTransport
    - Contains inner classes: METHOD (derived from _BaseMETHOD)
    - Defined in: rest.py

  Private Children:
  - _BaseEvaluationServiceRestTransport:
    - Type: base REST transport
    - Contains inner classes: _BaseMETHOD
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: Import Vertex AI SDK
DESCRIPTION: Imports the Vertex AI SDK namespace, which is required to access its functionalities for interacting with Google Cloud's Vertex AI services.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_5

LANGUAGE: python
CODE:
```
from google.cloud import aiplatform
```

----------------------------------------

TITLE: Retrieve Vertex AI Dataset
DESCRIPTION: Demonstrates how to retrieve a previously created Vertex AI Dataset using its resource name. This is a common first step before using the dataset for training.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_9

LANGUAGE: Python
CODE:
```
import google.cloud.aiplatform as aiplatform

dataset = aiplatform.ImageDataset('projects/my-project/location/us-central1/datasets/{DATASET_ID}')
```

----------------------------------------

TITLE: Install google-auth
DESCRIPTION: Installs google-auth version 2.35.0. This dependency is used for testing with REST async support.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_1

LANGUAGE: python
CODE:
```
google-auth==2.35.0 # Tests google-auth with rest async support
```

----------------------------------------

TITLE: Evaluation Service Transport Hierarchy
DESCRIPTION: Describes the inheritance structure for EvaluationService transports, including gRPC and REST implementations. This outlines the base class and its public and private children for different communication protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/evaluation_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
EvaluationServiceTransport:
  - Base class for all transports.

  Public Children:
  - EvaluationServiceGrpcTransport:
    - Type: sync gRPC transport
    - Defined in: grpc.py
  - EvaluationServiceGrpcAsyncIOTransport:
    - Type: async gRPC transport
    - Defined in: grpc_asyncio.py
  - EvaluationServiceRestTransport:
    - Type: sync REST transport
    - Derived from: _BaseEvaluationServiceRestTransport
    - Contains inner classes: METHOD (derived from _BaseMETHOD)
    - Defined in: rest.py

  Private Children:
  - _BaseEvaluationServiceRestTransport:
    - Type: base REST transport
    - Contains inner classes: _BaseMETHOD
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: Model Service Transport Hierarchy
DESCRIPTION: Describes the inheritance structure for Model Service transports. It outlines the abstract base class and its public and private children for synchronous/asynchronous gRPC and REST implementations, specifying their respective source files.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/model_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ModelServiceTransport:
  Abstract base class for all transports.

  Public Children:
    ModelServiceGrpcTransport:
      Description: Synchronous gRPC transport.
      Defined in: grpc.py

    ModelServiceGrpcAsyncIOTransport:
      Description: Asynchronous gRPC transport.
      Defined in: grpc_asyncio.py

    ModelServiceRestTransport:
      Description: Synchronous REST transport.
      Inherits from: _BaseModelServiceRestTransport
      Contains inner classes: METHOD (derived from _BaseMETHOD)
      Defined in: rest.py

  Private Children:
    _BaseModelServiceRestTransport:
      Description: Base REST transport with inner classes.
      Contains inner classes: _BaseMETHOD
      Defined in: rest_base.py
```

----------------------------------------

TITLE: Create Tabular Dataset
DESCRIPTION: Creates a managed tabular dataset in Vertex AI from data stored in Google Cloud Storage. It requires a display name and the GCS URI of the dataset file.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_7

LANGUAGE: python
CODE:
```
my_dataset = aiplatform.TabularDataset.create(
    display_name="my-dataset", gcs_source=['gs://path/to/my/dataset.csv'])
```

----------------------------------------

TITLE: ReasoningEngineExecutionService Transport Hierarchy
DESCRIPTION: Details the abstract base class and its public and private child transports for synchronous and asynchronous gRPC and REST communication.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/reasoning_engine_execution_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ReasoningEngineExecutionService Transport Hierarchy:

Base Abstract Class:
  ReasoningEngineExecutionServiceTransport
    - Abstract Base Class (ABC) for all transports.

Public Child Transports:
  ReasoningEngineExecutionServiceGrpcTransport
    - Implements synchronous gRPC transport.
    - Defined in: grpc.py

  ReasoningEngineExecutionServiceGrpcAsyncIOTransport
    - Implements asynchronous gRPC transport.
    - Defined in: grpc_asyncio.py

  ReasoningEngineExecutionServiceRestTransport
    - Implements synchronous REST transport.
    - Inherits from _BaseReasoningEngineExecutionServiceRestTransport.
    - Defines inner classes `METHOD` derived from parent's `_BaseMETHOD`.
    - Defined in: rest.py

Private Base REST Transport:
  _BaseReasoningEngineExecutionServiceRestTransport
    - Base class for REST transports.
    - Contains inner classes `_BaseMETHOD`.
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: Install Vertex AI SDK (Windows)
DESCRIPTION: Installs the Vertex AI SDK for Python on Windows systems using pip and virtualenv. It covers creating a virtual environment, activating it, and installing the necessary package.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_4

LANGUAGE: console
CODE:
```
pip install virtualenv
virtualenv <your-env>
<your-env>\Scripts\activate
<your-env>\Scripts\pip.exe install google-cloud-aiplatform
```

----------------------------------------

TITLE: Deployment Resource Pool Service Transport Inheritance
DESCRIPTION: Describes the class hierarchy for the Deployment Resource Pool Service transports. It details the abstract base class and its public and private children for synchronous and asynchronous gRPC, as well as synchronous REST implementations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/deployment_resource_pool_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
DeploymentResourcePoolServiceTransport Inheritance Structure:

`DeploymentResourcePoolServiceTransport` is the abstract base class (ABC) for all transport implementations.

- **Public Child**: `DeploymentResourcePoolServiceGrpcTransport`
  - Description: Provides the synchronous gRPC transport implementation.
  - Location: Defined in `grpc.py`.

- **Public Child**: `DeploymentResourcePoolServiceGrpcAsyncIOTransport`
  - Description: Provides the asynchronous gRPC transport implementation using asyncio.
  - Location: Defined in `grpc_asyncio.py`.

- **Private Child**: `_BaseDeploymentResourcePoolServiceRestTransport`
  - Description: Serves as the base class for REST transport, containing inner classes like `_BaseMETHOD`.
  - Location: Defined in `rest_base.py`.

- **Public Child**: `DeploymentResourcePoolServiceRestTransport`
  - Description: Provides the synchronous REST transport implementation. It includes inner classes `METHOD` which are derived from the parent's corresponding `_BaseMETHOD` classes.
  - Location: Defined in `rest.py`.
```

----------------------------------------

TITLE: Initialize Vertex AI SDK
DESCRIPTION: Initializes the Vertex AI SDK with common configurations such as project ID, location, and staging bucket. This setup is crucial before making any calls to Vertex AI services.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_6

LANGUAGE: python
CODE:
```
aiplatform.init(
    # your Google Cloud Project ID or number
    # environment default used is not set
    project='my-project',

    # the Vertex AI region you will use
    # defaults to us-central1
    location='us-central1',

    # Google Cloud Storage bucket in same region as location
    # used to stage artifacts
    staging_bucket='gs://my_staging_bucket',

    # custom google.auth.credentials.Credentials
    # environment default credentials used if not set
    credentials=my_credentials,

    # customer managed encryption key resource name
    # will be applied to all Vertex AI resources if set
    encryption_spec_key_name=my_encryption_key_name,

    # the name of the experiment to use to track
    # logged metrics and parameters
    experiment='my-experiment',

    # description of the experiment above
    experiment_description='my experiment description'
)
```

----------------------------------------

TITLE: Install Sample Dependencies (Bash)
DESCRIPTION: Installs all required Python packages listed in the 'requirements.txt' file within the activated virtual environment. This step ensures that all necessary libraries are available to run the AI Platform samples.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/scripts/readme-gen/templates/install_deps.tmpl.rst#_snippet_2

LANGUAGE: bash
CODE:
```
pip install -r requirements.txt
```

----------------------------------------

TITLE: Gemini Automatic Function Calling with Python
DESCRIPTION: Demonstrates how to define a Python function, declare it as a tool for a Gemini model, and use automatic function calling in a chat session. The SDK handles function execution and response integration.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/generative_models/README.md#_snippet_8

LANGUAGE: python
CODE:
```
# First, create functions that the model can use to answer your questions.
def get_current_weather(location: str, unit: str = "centigrade"):
    """Gets weather in the specified location.

    Args:
        location: The location for which to get the weather.
        unit: Optional. Temperature unit. Can be Centigrade or Fahrenheit. Defaults to Centigrade.
    """
    return dict(
        location=location,
        unit=unit,
        weather="Super nice, but maybe a bit hot.",
    )

# Infer function schema
get_current_weather_func = FunctionDeclaration.from_func(get_current_weather)
# Tool is a collection of related functions
weather_tool = Tool(
    function_declarations=[get_current_weather_func],
)

# Use tools in chat:
model = GenerativeModel(
    "gemini-pro",
    # You can specify tools when creating a model to avoid having to send them with every request.
    tools=[weather_tool],
)

# Activate automatic function calling:
afc_responder = AutomaticFunctionCallingResponder(
    # Optional:
    max_automatic_function_calls=5,
)
chat = model.start_chat(responder=afc_responder)
# Send a message to the model. The model will respond with a function call.
# The SDK will automatically call the requested function and respond to the model.
# The model will use the function call response to answer the original question.
print(chat.send_message("What is the weather like in Boston?"))
```

----------------------------------------

TITLE: Deployment Resource Pool Service Transport Inheritance
DESCRIPTION: Describes the class hierarchy for the Deployment Resource Pool Service transports. It details the abstract base class and its public and private children for synchronous and asynchronous gRPC, as well as synchronous REST implementations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/deployment_resource_pool_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
DeploymentResourcePoolServiceTransport Inheritance Structure:

`DeploymentResourcePoolServiceTransport` is the abstract base class (ABC) for all transport implementations.

- **Public Child**: `DeploymentResourcePoolServiceGrpcTransport`
  - Description: Provides the synchronous gRPC transport implementation.
  - Location: Defined in `grpc.py`.

- **Public Child**: `DeploymentResourcePoolServiceGrpcAsyncIOTransport`
  - Description: Provides the asynchronous gRPC transport implementation using asyncio.
  - Location: Defined in `grpc_asyncio.py`.

- **Private Child**: `_BaseDeploymentResourcePoolServiceRestTransport`
  - Description: Serves as the base class for REST transport, containing inner classes like `_BaseMETHOD`.
  - Location: Defined in `rest_base.py`.

- **Public Child**: `DeploymentResourcePoolServiceRestTransport`
  - Description: Provides the synchronous REST transport implementation. It includes inner classes `METHOD` which are derived from the parent's corresponding `_BaseMETHOD` classes.
  - Location: Defined in `rest.py`.
```

----------------------------------------

TITLE: Multimodal Generation with Images and Videos
DESCRIPTION: Shows how to use the Gemini-Pro Vision model for multimodal generation, processing local images, images from Cloud Storage, and videos. It covers loading media and passing them as parts of the content.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_3

LANGUAGE: python
CODE:
```
from vertexai.generative_models import GenerativeModel, Image, Part

# Local image
vision_model = GenerativeModel("gemini-pro-vision")
image = Image.load_from_file("image.jpg")
print(vision_model.generate_content(["What is shown in this image?", image]))

# Image from Cloud Storage
image_part = Part.from_uri("gs://download.tensorflow.org/example_images/320px-Felis_catus-cat_on_snow.jpg", mime_type="image/jpeg")
print(vision_model.generate_content([image_part, "Describe this image?"]))

# Text and video
video_part = Part.from_uri("gs://cloud-samples-data/video/animals.mp4", mime_type="video/mp4")
print(vision_model.generate_content(["What is in the video? ", video_part]))
```

----------------------------------------

TITLE: Extension Execution Service Transport Hierarchy
DESCRIPTION: Defines the abstract base class and concrete implementations for the Extension Execution Service transports. This structure facilitates different communication protocols while maintaining a consistent interface.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/extension_execution_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ExtensionExecutionServiceTransport:
  Description: Abstract base class (ABC) for all transports.
  Children:
    - ExtensionExecutionServiceGrpcTransport
    - ExtensionExecutionServiceGrpcAsyncIOTransport
    - _BaseExtensionExecutionServiceRestTransport

ExtensionExecutionServiceGrpcTransport:
  Description: Public child for synchronous gRPC transport.
  Defined in: grpc.py

ExtensionExecutionServiceGrpcAsyncIOTransport:
  Description: Public child for asynchronous gRPC transport.
  Defined in: grpc_asyncio.py

_BaseExtensionExecutionServiceRestTransport:
  Description: Private child for base REST transport.
  Contains inner classes `_BaseMETHOD`.
  Defined in: rest_base.py

ExtensionExecutionServiceRestTransport:
  Description: Public child for synchronous REST transport.
  Contains inner classes `METHOD` derived from `_BaseMETHOD`.
  Defined in: rest.py
```

----------------------------------------

TITLE: Deploy Vertex AI Model
DESCRIPTION: Illustrates how to deploy a Vertex AI Model to an endpoint. This includes configuring the machine type, replica count, and accelerator details for the deployment.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_15

LANGUAGE: Python
CODE:
```
import google.cloud.aiplatform as aiplatform

# Assuming 'model' is a Vertex AI Model object
# model = aiplatform.Model(...)

endpoint = model.deploy(
    machine_type="n1-standard-4",
    min_replica_count=1,
    max_replica_count=5,
    accelerator_type='NVIDIA_TESLA_K80',
    accelerator_count=1
)
```

----------------------------------------

TITLE: Pipeline Service Transport Hierarchy
DESCRIPTION: Describes the abstract base class and concrete implementations for Pipeline Service transports, detailing their relationships and origins.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/pipeline_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
PipelineServiceTransport:
  - Abstract Base Class (ABC) for all transports.

  Public Children:
  - PipelineServiceGrpcTransport:
    - Represents the synchronous gRPC transport.
    - Defined in: grpc.py
  - PipelineServiceGrpcAsyncIOTransport:
    - Represents the asynchronous gRPC transport.
    - Defined in: grpc_asyncio.py
  - PipelineServiceRestTransport:
    - Represents the synchronous REST transport.
    - Derived from _BasePipelineServiceRestTransport.
    - Contains inner classes METHOD, which are derived from the parent's _BaseMETHOD classes.
    - Defined in: rest.py

  Private Children:
  - _BasePipelineServiceRestTransport:
    - Base class for REST transports.
    - Contains inner classes _BaseMETHOD.
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: Custom Training Script Data Contract
DESCRIPTION: Illustrates how a custom training script should read data URIs and format from environment variables provided by the Vertex AI training service.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_7

LANGUAGE: Python
CODE:
```
import os

os.environ['AIP_DATA_FORMAT']  # provides format of data
os.environ['AIP_TRAINING_DATA_URI']  # uri to training split
os.environ['AIP_VALIDATION_DATA_URI']  # uri to validation split
os.environ['AIP_TEST_DATA_URI']  # uri to test split
```

----------------------------------------

TITLE: System Instructions for Models
DESCRIPTION: Demonstrates how to provide system instructions to a generative model to influence its behavior and response style. This allows for custom personas or constraints, like talking like a pirate.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_5

LANGUAGE: python
CODE:
```
from vertexai.generative_models import GenerativeModel

model = GenerativeModel(
    "gemini-1.0-pro",
    system_instruction=[
        "Talk like a pirate.",
        "Don't use rude words.",
    ],
)
print(model.generate_content("Why is sky blue?"))
```

----------------------------------------

TITLE: Run Gen AI Model Inference for Evaluation
DESCRIPTION: Shows how to generate model responses for evaluation purposes. It involves creating a DataFrame of prompts and references, then calling the `run_inference` method with a specified model.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_1

LANGUAGE: Python
CODE:
```
import pandas as pd

prompts_df = pd.DataFrame({
    "prompt": [
        "What is the capital of France?",
        "Write a haiku about a cat.",
        "Write a Python function to calculate the factorial of a number.",
        "Translate 'How are you?' to French.",
    ],

    "reference": [
        "Paris",
        "Sunbeam on the floor,\nA furry puddle sleeping,\nTwitching tail tells tales.",
        "def factorial(n):\n    if n < 0:\n        return 'Factorial does not exist for negative numbers'\n    elif n == 0:\n        return 1\n    else:\n        fact = 1\n        i = 1\n        while i <= n:\n            fact *= i\n            i += 1\n        return fact",
        "Comment ça va ?",
    ]
})

inference_results = client.evals.run_inference(
    model="gemini-2.5-flash-preview-05-20",
    src=prompts_df
)
```

----------------------------------------

TITLE: Reasoning Engine Service Transport Structure
DESCRIPTION: Defines the inheritance hierarchy for the Reasoning Engine Service transports, specifying the base abstract class and its concrete implementations for synchronous and asynchronous gRPC, as well as synchronous REST.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/reasoning_engine_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ReasoningEngineServiceTransport (Abstract Base Class)
  - Base for all transport implementations.

  Public Children:
  - ReasoningEngineServiceGrpcTransport
    - Description: Synchronous gRPC transport implementation.
    - Defined in: grpc.py

  - ReasoningEngineServiceGrpcAsyncIOTransport
    - Description: Asynchronous gRPC transport implementation using asyncio.
    - Defined in: grpc_asyncio.py

  - ReasoningEngineServiceRestTransport
    - Description: Synchronous REST transport implementation.
    - Inherits from: _BaseReasoningEngineServiceRestTransport
    - Contains inner classes: METHOD (derived from _BaseMETHOD)
    - Defined in: rest.py

  Private Children:
  - _BaseReasoningEngineServiceRestTransport
    - Description: Base class for REST transport, providing common functionality.
    - Contains inner classes: _BaseMETHOD
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: Use Explanation Metadata in Model Deployment
DESCRIPTION: Illustrates how to use the generated explanation metadata when deploying a model to an endpoint or uploading a model to Vertex AI. The `explanation_metadata` object is passed as an argument to these deployment methods.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_30

LANGUAGE: Python
CODE:
```
# Assuming 'builder' is an instance of SavedModelMetadataBuilder
explanation_metadata = builder.get_metadata_protobuf()

# To deploy a model to an endpoint with explanation
# model.deploy(..., explanation_metadata=explanation_metadata)

# To deploy a model to a created endpoint with explanation
# endpoint.deploy(..., explanation_metadata=explanation_metadata)

# To upload a model with explanation
# aiplatform.Model.upload(..., explanation_metadata=explanation_metadata)
```

----------------------------------------

TITLE: DatasetService Transport Inheritance
DESCRIPTION: Details the inheritance hierarchy for the DatasetService transports, defining the abstract base class and its public and private children for gRPC and REST communication.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/dataset_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
DatasetServiceTransport:
  - Abstract Base Class (ABC) for all transports.

  Public Children:
  - DatasetServiceGrpcTransport: For synchronous gRPC transport (defined in grpc.py).
  - DatasetServiceGrpcAsyncIOTransport: For asynchronous gRPC transport (defined in grpc_asyncio.py).
  - DatasetServiceRestTransport: For synchronous REST transport (defined in rest.py).

  Private Children:
  - _BaseDatasetServiceRestTransport: Base REST transport with inner classes _BaseMETHOD (defined in rest_base.py).
    - DatasetServiceRestTransport derives from this and defines METHOD classes from _BaseMETHOD.
```

----------------------------------------

TITLE: Reasoning Engine Service Transport Structure
DESCRIPTION: Defines the inheritance hierarchy for the Reasoning Engine Service transports, specifying the base abstract class and its concrete implementations for synchronous and asynchronous gRPC, as well as synchronous REST.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/reasoning_engine_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ReasoningEngineServiceTransport (Abstract Base Class)
  - Base for all transport implementations.

  Public Children:
  - ReasoningEngineServiceGrpcTransport
    - Description: Synchronous gRPC transport implementation.
    - Defined in: grpc.py

  - ReasoningEngineServiceGrpcAsyncIOTransport
    - Description: Asynchronous gRPC transport implementation using asyncio.
    - Defined in: grpc_asyncio.py

  - ReasoningEngineServiceRestTransport
    - Description: Synchronous REST transport implementation.
    - Inherits from: _BaseReasoningEngineServiceRestTransport
    - Contains inner classes: METHOD (derived from _BaseMETHOD)
    - Defined in: rest.py

  Private Children:
  - _BaseReasoningEngineServiceRestTransport
    - Description: Base class for REST transport, providing common functionality.
    - Contains inner classes: _BaseMETHOD
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: SessionService Transport Hierarchy
DESCRIPTION: Outlines the class inheritance structure for SessionService transports. It details the abstract base class and its public and private children for gRPC and REST implementations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/session_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
SessionServiceTransport:
  Abstract Base Class (ABC) for all transports.

  Children:
  - SessionServiceGrpcTransport:
    - Type: Public child
    - Functionality: Synchronous gRPC transport.
    - Location: Defined in `grpc.py`.

  - SessionServiceGrpcAsyncIOTransport:
    - Type: Public child
    - Functionality: Asynchronous gRPC transport.
    - Location: Defined in `grpc_asyncio.py`.

  - _BaseSessionServiceRestTransport:
    - Type: Private child
    - Functionality: Base REST transport with inner classes `_BaseMETHOD`.
    - Location: Defined in `rest_base.py`.

  - SessionServiceRestTransport:
    - Type: Public child
    - Functionality: Synchronous REST transport with inner classes `METHOD` derived from `_BaseMETHOD`.
    - Location: Defined in `rest.py`.
```

----------------------------------------

TITLE: Initialize Cloud Profiler for TensorFlow (Python)
DESCRIPTION: Integrates Cloud Profiler with TensorFlow training scripts on Vertex AI. This allows on-demand profiling of remote training jobs, with results visualized in Vertex AI Tensorboard. Ensure a Vertex AI TensorBoard instance is used when running the job.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_32

LANGUAGE: Python
CODE:
```
from google.cloud.aiplatform.training_utils import cloud_profiler
...
cloud_profiler.init()
```

----------------------------------------

TITLE: DatasetService Transport Inheritance
DESCRIPTION: Details the inheritance hierarchy for the DatasetService transports, defining the abstract base class and its public and private children for gRPC and REST communication.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/dataset_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
DatasetServiceTransport:
  - Abstract Base Class (ABC) for all transports.

  Public Children:
  - DatasetServiceGrpcTransport: For synchronous gRPC transport (defined in grpc.py).
  - DatasetServiceGrpcAsyncIOTransport: For asynchronous gRPC transport (defined in grpc_asyncio.py).
  - DatasetServiceRestTransport: For synchronous REST transport (defined in rest.py).

  Private Children:
  - _BaseDatasetServiceRestTransport: Base REST transport with inner classes _BaseMETHOD (defined in rest_base.py).
    - DatasetServiceRestTransport derives from this and defines METHOD classes from _BaseMETHOD.
```

----------------------------------------

TITLE: Pipeline Service Transport Hierarchy
DESCRIPTION: Describes the abstract base class and concrete implementations for Pipeline Service transports, detailing their relationships and origins.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/pipeline_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
PipelineServiceTransport:
  - Abstract Base Class (ABC) for all transports.

  Public Children:
  - PipelineServiceGrpcTransport:
    - Represents the synchronous gRPC transport.
    - Defined in: grpc.py
  - PipelineServiceGrpcAsyncIOTransport:
    - Represents the asynchronous gRPC transport.
    - Defined in: grpc_asyncio.py
  - PipelineServiceRestTransport:
    - Represents the synchronous REST transport.
    - Derived from _BasePipelineServiceRestTransport.
    - Contains inner classes METHOD, which are derived from the parent's _BaseMETHOD classes.
    - Defined in: rest.py

  Private Children:
  - _BasePipelineServiceRestTransport:
    - Base class for REST transports.
    - Contains inner classes _BaseMETHOD.
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: AI Platform V1 Prediction Instance Types Schema
DESCRIPTION: This section details the schema types available for prediction instances in Google Cloud AI Platform V1. It outlines the structure and expected data formats for instances used in prediction requests.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/instance_v1/types_.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Google Cloud AI Platform V1 Prediction Instance Types Schema:

This schema defines the structure for prediction instances used with Google Cloud AI Platform's V1 API. It specifies the data types and fields required for submitting prediction requests.

Key components typically include:
- Instance structure: Defines the input data format for a single prediction.
- Data types: Specifies expected formats for numerical, categorical, and text data.
- Schema versioning: Indicates compatibility with the V1 API.

Example (Conceptual):

{
  "instance": {
    "numeric_feature_1": 123.45,
    "categorical_feature_1": "category_a",
    "text_feature_1": "This is a sample text."
  }
}

This documentation serves as a reference for developers integrating with the AI Platform V1 prediction service, ensuring correct data formatting for optimal performance and accuracy.
```

----------------------------------------

TITLE: Migration Service Pagers Module
DESCRIPTION: Documents the pagers associated with the Migration Service. Pagers are used for handling large result sets, typically returned by list operations, enabling efficient iteration over data.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/migration_service.rst#_snippet_1

LANGUAGE: APIDOC
CODE:
```
.. automodule:: google.cloud.aiplatform_v1beta1.services.migration_service.pagers
    :members:
    :inherited-members:
```

----------------------------------------

TITLE: Create Vertex AI Pipeline Run
DESCRIPTION: Initiates a Vertex AI Pipeline run. Requires a display name, whether to enable caching, and the path to the compiled pipeline definition (e.g., 'pipeline.json'). Input parameters can also be provided.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_25

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform
from google.cloud.aiplatform.pipeline_jobs import PipelineJob

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

# Instantiate PipelineJob object
pl = PipelineJob(
    display_name="My first pipeline",

    # Whether or not to enable caching
    # True = always cache pipeline step result
    # False = never cache pipeline step result
    # None = defer to cache option for each pipeline component in the pipeline definition
    enable_caching=False,

    # Local or GCS path to a compiled pipeline definition
    template_path="pipeline.json",

    # Dictionary containing input parameters for your pipeline
    # pipeline_root='gs://my-bucket/pipeline_root',
    # parameter_values={'input_param1': 'value1', 'input_param2': 123}
)
```

----------------------------------------

TITLE: Install Vertex AI SDK (Windows)
DESCRIPTION: Provides step-by-step instructions for installing the Vertex AI SDK for Python on Windows environments. It details the process of creating and activating a virtual environment before installing the package using pip.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_1

LANGUAGE: console
CODE:
```
pip install virtualenv
virtualenv <your-env>
<your-env>\Scripts\activate
<your-env>\Scripts\pip.exe install google-cloud-aiplatform
```

----------------------------------------

TITLE: Extension Registry Service Transport Hierarchy
DESCRIPTION: Outlines the class hierarchy for the Extension Registry Service transport layer, detailing the abstract base class and its public and private concrete implementations for different transport protocols (gRPC and REST).
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/extension_registry_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ExtensionRegistryServiceTransport:
  Abstract Base Class (ABC) for all transports.

  Public Children:
    - ExtensionRegistryServiceGrpcTransport: For synchronous gRPC transport (defined in grpc.py).
    - ExtensionRegistryServiceGrpcAsyncIOTransport: For asynchronous gRPC transport (defined in grpc_asyncio.py).
    - ExtensionRegistryServiceRestTransport: For synchronous REST transport (defined in rest.py).

  Private Children:
    - _BaseExtensionRegistryServiceRestTransport: Base REST transport with inner classes _BaseMETHOD (defined in rest_base.py).
```

----------------------------------------

TITLE: TensorboardService Transport Hierarchy
DESCRIPTION: Details the abstract base class and its public and private children, outlining the different transport implementations available for the TensorboardService. This includes synchronous and asynchronous gRPC, and synchronous REST transports.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/tensorboard_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
TensorboardServiceTransport (Abstract Base Class)
  - Base class for all TensorboardService transport implementations.

  Public Children:
  - TensorboardServiceGrpcTransport (sync gRPC)
    - Implements synchronous gRPC communication.
    - Defined in: grpc.py

  - TensorboardServiceGrpcAsyncIOTransport (async gRPC)
    - Implements asynchronous gRPC communication using asyncio.
    - Defined in: grpc_asyncio.py

  - TensorboardServiceRestTransport (sync REST)
    - Implements synchronous RESTful communication.
    - Inherits from _BaseTensorboardServiceRestTransport.
    - Contains inner classes 'METHOD' derived from parent's '_BaseMETHOD'.
    - Defined in: rest.py

  Private Children:
  - _BaseTensorboardServiceRestTransport (base REST)
    - Base class for REST transport implementations.
    - Contains inner classes '_BaseMETHOD'.
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: PredictionService Transport Hierarchy
DESCRIPTION: Describes the inheritance structure of the PredictionService transport layer. It outlines the abstract base class and its concrete implementations for different communication protocols (gRPC, REST) and execution models (synchronous, asynchronous).
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/prediction_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
PredictionServiceTransport:
  - Abstract Base Class (ABC) for all transports.

  Public Children:
  - PredictionServiceGrpcTransport:
    - Represents the synchronous gRPC transport.
    - Defined in `grpc.py`.
  - PredictionServiceGrpcAsyncIOTransport:
    - Represents the asynchronous gRPC transport.
    - Defined in `grpc_asyncio.py`.
  - PredictionServiceRestTransport:
    - Represents the synchronous REST transport.
    - Derived from `_BasePredictionServiceRestTransport`.
    - Uses inner classes `METHOD` which are derived from the parent's `_BaseMETHOD` classes.
    - Defined in `rest.py`.

  Private Children:
  - _BasePredictionServiceRestTransport:
    - Base class for REST transport.
    - Contains inner classes `_BaseMETHOD`.
    - Defined in `rest_base.py`.
```

----------------------------------------

TITLE: TensorboardService Transport Hierarchy
DESCRIPTION: Details the abstract base class and its public and private children, outlining the different transport implementations available for the TensorboardService. This includes synchronous and asynchronous gRPC, and synchronous REST transports.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/tensorboard_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
TensorboardServiceTransport (Abstract Base Class)
  - Base class for all TensorboardService transport implementations.

  Public Children:
  - TensorboardServiceGrpcTransport (sync gRPC)
    - Implements synchronous gRPC communication.
    - Defined in: grpc.py

  - TensorboardServiceGrpcAsyncIOTransport (async gRPC)
    - Implements asynchronous gRPC communication using asyncio.
    - Defined in: grpc_asyncio.py

  - TensorboardServiceRestTransport (sync REST)
    - Implements synchronous RESTful communication.
    - Inherits from _BaseTensorboardServiceRestTransport.
    - Contains inner classes 'METHOD' derived from parent's '_BaseMETHOD'.
    - Defined in: rest.py

  Private Children:
  - _BaseTensorboardServiceRestTransport (base REST)
    - Base class for REST transport implementations.
    - Contains inner classes '_BaseMETHOD'.
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: PredictionService Transport Hierarchy
DESCRIPTION: Describes the inheritance structure of the PredictionService transport layer. It outlines the abstract base class and its concrete implementations for different communication protocols (gRPC, REST) and execution models (synchronous, asynchronous).
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/prediction_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
PredictionServiceTransport:
  - Abstract Base Class (ABC) for all transports.

  Public Children:
  - PredictionServiceGrpcTransport:
    - Represents the synchronous gRPC transport.
    - Defined in `grpc.py`.
  - PredictionServiceGrpcAsyncIOTransport:
    - Represents the asynchronous gRPC transport.
    - Defined in `grpc_asyncio.py`.
  - PredictionServiceRestTransport:
    - Represents the synchronous REST transport.
    - Derived from `_BasePredictionServiceRestTransport`.
    - Uses inner classes `METHOD` which are derived from the parent's `_BaseMETHOD` classes.
    - Defined in `rest.py`.

  Private Children:
  - _BasePredictionServiceRestTransport:
    - Base class for REST transport.
    - Contains inner classes `_BaseMETHOD`.
    - Defined in `rest_base.py`.
```

----------------------------------------

TITLE: AI Platform V1 Prediction Instance Types Schema
DESCRIPTION: This section details the schema types available for prediction instances in Google Cloud AI Platform V1. It outlines the structure and expected data formats for instances used in prediction requests.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/instance_v1/types.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Google Cloud AI Platform V1 Prediction Instance Types Schema:

This schema defines the structure for prediction instances used with Google Cloud AI Platform's V1 API. It specifies the data types and fields required for submitting prediction requests.

Key components typically include:
- Instance structure: Defines the input data format for a single prediction.
- Data types: Specifies expected formats for numerical, categorical, and text data.
- Schema versioning: Indicates compatibility with the V1 API.

Example (Conceptual):

{
  "instance": {
    "numeric_feature_1": 123.45,
    "categorical_feature_1": "category_a",
    "text_feature_1": "This is a sample text."
  }
}

This documentation serves as a reference for developers integrating with the AI Platform V1 prediction service, ensuring correct data formatting for optimal performance and accuracy.
```

----------------------------------------

TITLE: Run Python Sample using Bash
DESCRIPTION: This snippet shows the command to execute a Python sample file from the command line. It requires Python to be installed and configured in your environment. The command assumes the sample file is executable.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/scripts/readme-gen/templates/README.tmpl.rst#_snippet_0

LANGUAGE: bash
CODE:
```
python {{sample.file}}
```

----------------------------------------

TITLE: Function Calling with Gemini (Python)
DESCRIPTION: Enables Gemini models to call external functions by defining function declarations and tools. The model can respond with a function call, which can then be executed and its response sent back to the model.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/generative_models/README.md#_snippet_6

LANGUAGE: python
CODE:
```
# First, create tools that the model is can use to answer your questions.
# Describe a function by specifying it's schema (JsonSchema format)
from vertexai.generative_models import GenerativeModel, Part

get_current_weather_func = GenerativeModel.FunctionDeclaration(
    name="get_current_weather",
    description="Get the current weather in a given location",
    parameters={
        "type": "object",
        "properties": {
            "location": {
                "type": "string",
                "description": "The city and state, e.g. San Francisco, CA"
            },
            "unit": {
                "type": "string",
                "enum": [
                    "celsius",
                    "fahrenheit",
                ]
            }
        },
        "required": [
            "location"
        ]
    },
)
# Tool is a collection of related functions
weather_tool = GenerativeModel.Tool(
    function_declarations=[get_current_weather_func],
)

# Use tools in chat:
model = GenerativeModel(
    "gemini-pro",
    # You can specify tools when creating a model to avoid having to send them with every request.
    tools=[weather_tool],
)
chat = model.start_chat()
# Send a message to the model. The model will respond with a function call.
print(chat.send_message("What is the weather like in Boston?"))
# Then send a function response to the model. The model will use it to answer.
print(chat.send_message(
    Part.from_function_response(
        name="get_current_weather",
        response={
            "content": {"weather": "super nice"},
        }
    ),
))
```

----------------------------------------

TITLE: Install ray
DESCRIPTION: Installs the ray library version 2.5.0. This version is pinned until 2.9.3 is verified for Ray tests.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_7

LANGUAGE: python
CODE:
```
ray==2.5.0 # Pinned until 2.9.3 is verified for Ray tests
```

----------------------------------------

TITLE: Run Linter with Nox
DESCRIPTION: Checks the codebase for PEP8 compliance and other linting errors using the nox session. This verifies adherence to the project's coding style guidelines.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_5

LANGUAGE: bash
CODE:
```
$ nox -s lint
```

----------------------------------------

TITLE: ReasoningEngineExecutionService Transport Hierarchy
DESCRIPTION: Details the abstract base class and its public and private child transports for synchronous and asynchronous gRPC and REST communication.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/reasoning_engine_execution_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
ReasoningEngineExecutionService Transport Hierarchy:

Base Abstract Class:
  ReasoningEngineExecutionServiceTransport
    - Abstract Base Class (ABC) for all transports.

Public Child Transports:
  ReasoningEngineExecutionServiceGrpcTransport
    - Implements synchronous gRPC transport.
    - Defined in: grpc.py

  ReasoningEngineExecutionServiceGrpcAsyncIOTransport
    - Implements asynchronous gRPC transport.
    - Defined in: grpc_asyncio.py

  ReasoningEngineExecutionServiceRestTransport
    - Implements synchronous REST transport.
    - Inherits from _BaseReasoningEngineExecutionServiceRestTransport.
    - Defines inner classes `METHOD` derived from parent's `_BaseMETHOD`.
    - Defined in: rest.py

Private Base REST Transport:
  _BaseReasoningEngineExecutionServiceRestTransport
    - Base class for REST transports.
    - Contains inner classes `_BaseMETHOD`.
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: Install google-vizier
DESCRIPTION: Installs the google-vizier library version 0.1.21.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_11

LANGUAGE: python
CODE:
```
google-vizier==0.1.21
```

----------------------------------------

TITLE: Install Vertex AI SDK (Shell)
DESCRIPTION: Installs the google-cloud-aiplatform Python package using pip. It ensures the latest version or a specified minimum version is installed for use.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/generative_models/README.md#_snippet_0

LANGUAGE: shell
CODE:
```
pip3 install --upgrade --user "google-cloud-aiplatform>=1.38"
```

----------------------------------------

TITLE: Create and Submit Vertex AI Pipeline (Asynchronous)
DESCRIPTION: Submits a Vertex AI Pipeline for execution asynchronously, returning immediately without waiting for completion. The pipeline can be monitored separately.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_28

LANGUAGE: python
CODE:
```
# Instantiate PipelineJob object
pl = PipelineJob(
    display_name="My first pipeline",

    # Whether or not to enable caching
    # True = always cache pipeline step result
    # False = never cache pipeline step result
    # None = defer to cache option for each pipeline component in the pipeline definition
    enable_caching=False,

    # Local or GCS path to a compiled pipeline definition
    template_path="pipeline.json",

    # Dictionary containing input parameters for your pipeline
    parameter_values=parameter_values,

    # GCS path to act as the pipeline root
    pipeline_root=pipeline_root,
)

# Submit the Pipeline to Vertex AI
pl.submit(
  # Email address of service account to use for the pipeline run
  # You must have iam.serviceAccounts.actAs permission on the service account to use it
  service_account=service_account,
)
```

----------------------------------------

TITLE: Install Vertex AI SDK (Mac/Linux)
DESCRIPTION: Installs the Vertex AI SDK for Python on macOS and Linux systems using pip and virtualenv. It covers creating a virtual environment, activating it, and installing the necessary package.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_3

LANGUAGE: console
CODE:
```
pip install virtualenv
virtualenv <your-env>
source <your-env>/bin/activate
<your-env>/bin/pip install google-cloud-aiplatform
```

----------------------------------------

TITLE: Install google-genai
DESCRIPTION: Installs the google-genai library, requiring version 1.10.0 or higher.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_10

LANGUAGE: python
CODE:
```
google-genai>=1.10.0
```

----------------------------------------

TITLE: GenAiCacheService Pagers
DESCRIPTION: Details the pager objects used for iterating through lists of CachedContents returned by the GenAiCacheService. These pagers handle the logic for fetching subsequent pages of results.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/gen_ai_cache_service.rst#_snippet_1

LANGUAGE: APIDOC
CODE:
```
google.cloud.aiplatform_v1.services.gen_ai_cache_service.pagers.ListCachedContentsPager:
  __init__(method, request, response, *, retry=GAPIC_RETRY_DEFAULT, timeout=None, metadata=None):
    Initializes the ListCachedContentsPager.
    Parameters:
      method: The API method to call for fetching pages.
      request: The initial request object.
      response: The initial response object.
      retry (google.api_core.retry.Retry): An optional retry object.
      timeout (float): An optional timeout value.
      metadata (Sequence[tuple[str, str]]): Optional metadata.

  __iter__():
    Returns an iterator over the CachedContent objects.

  __next__():
    Fetches the next CachedContent object.

  pages:
    An iterator over the pages of results.

  cached_contents:
    An iterator over the CachedContent objects in the current page.

```

----------------------------------------

TITLE: FeaturestoreOnlineServingService Transport Inheritance
DESCRIPTION: Details the inheritance hierarchy for FeaturestoreOnlineServingService transports. It outlines the abstract base class (ABC) and its public and private child classes, specifying their purpose and the files where they are defined.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/featurestore_online_serving_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
FeaturestoreOnlineServingServiceTransport Inheritance Structure:

  FeaturestoreOnlineServingServiceTransport (ABC)
    - Base class for all transports.

  Public Children:
    - FeaturestoreOnlineServingServiceGrpcTransport
      - Purpose: Synchronous gRPC transport.
      - Defined in: grpc.py

    - FeaturestoreOnlineServingServiceGrpcAsyncIOTransport
      - Purpose: Asynchronous gRPC transport.
      - Defined in: grpc_asyncio.py

    - FeaturestoreOnlineServingServiceRestTransport
      - Purpose: Synchronous REST transport.
      - Derived from: _BaseFeaturestoreOnlineServingServiceRestTransport.
      - Contains inner classes: METHOD (derived from _BaseMETHOD).
      - Defined in: rest.py

  Private Children:
    - _BaseFeaturestoreOnlineServingServiceRestTransport
      - Purpose: Base REST transport.
      - Contains inner classes: _BaseMETHOD.
      - Defined in: rest_base.py
```

----------------------------------------

TITLE: Gemini Function Calling with Python SDK
DESCRIPTION: Demonstrates how to enable automatic function calling with Gemini models in the Google AI Platform Python SDK. It includes defining a Python function, creating a tool with function declarations, and initiating a chat session with an automatic function calling responder.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_8

LANGUAGE: python
CODE:
```
# First, create functions that the model can use to answer your questions.
def get_current_weather(location: str, unit: str = "centigrade"):
    """Gets weather in the specified location.

    Args:
        location: The location for which to get the weather.
        unit: Optional. Temperature unit. Can be Centigrade or Fahrenheit. Defaults to Centigrade.
    """
    return dict(
        location=location,
        unit=unit,
        weather="Super nice, but maybe a bit hot.",
    )

# Infer function schema
get_current_weather_func = FunctionDeclaration.from_func(get_current_weather)
# Tool is a collection of related functions
weather_tool = Tool(
    function_declarations=[get_current_weather_func],
)

# Use tools in chat:
model = GenerativeModel(
    "gemini-pro",
    # You can specify tools when creating a model to avoid having to send them with every request.
    tools=[weather_tool],
)

# Activate automatic function calling:
af c_responder = AutomaticFunctionCallingResponder(
    # Optional:
    max_automatic_function_calls=5,
)
chat = model.start_chat(responder=afc_responder)
# Send a message to the model. The model will respond with a function call.
# The SDK will automatically call the requested function and respond to the model.
# The model will use the function call response to answer the original question.
print(chat.send_message("What is the weather like in Boston?"))
```

----------------------------------------

TITLE: Install Vertex AI Python Package
DESCRIPTION: Installs or upgrades the google-cloud-aiplatform Python package to the latest version, ensuring access to the Vertex Model Garden SDK features.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/model_garden/README.md#_snippet_0

LANGUAGE: shell
CODE:
```
pip3 install --upgrade --user "google-cloud-aiplatform>=1.84"
```

----------------------------------------

TITLE: Install Vertex AI SDK (Mac/Linux)
DESCRIPTION: Provides step-by-step instructions for installing the Vertex AI SDK for Python on macOS and Linux environments. It details the process of creating and activating a virtual environment before installing the package using pip.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_0

LANGUAGE: console
CODE:
```
pip install virtualenv
virtualenv <your-env>
source <your-env>/bin/activate
<your-env>/bin/pip install google-cloud-aiplatform
```

----------------------------------------

TITLE: LlmUtilityService Transport Hierarchy
DESCRIPTION: Details the abstract base class (ABC) and its public and private child classes for synchronous and asynchronous gRPC and REST transports.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/llm_utility_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
LlmUtilityServiceTransport:
  Abstract Base Class (ABC) for all transports.

  - LlmUtilityServiceGrpcTransport:
    Public child for synchronous gRPC transport.
    Defined in `grpc.py`.

  - LlmUtilityServiceGrpcAsyncIOTransport:
    Public child for asynchronous gRPC transport.
    Defined in `grpc_asyncio.py`.

  - _BaseLlmUtilityServiceRestTransport:
    Private child for base REST transport.
    Contains inner classes `_BaseMETHOD`.
    Defined in `rest_base.py`.

  - LlmUtilityServiceRestTransport:
    Public child for synchronous REST transport.
    Contains inner classes `METHOD` derived from `_BaseMETHOD`.
    Defined in `rest.py`.
```

----------------------------------------

TITLE: SpecialistPoolService Transport Hierarchy
DESCRIPTION: Describes the inheritance structure for `SpecialistPoolService` transports. It outlines the abstract base class and its public and private children for different communication protocols like gRPC and REST, specifying their implementation files.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/specialist_pool_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
SpecialistPoolServiceTransport:
  Abstract Base Class (ABC) for all transports.

  Children:
    - SpecialistPoolServiceGrpcTransport:
        Type: public
        Protocol: synchronous gRPC
        Implementation: grpc.py

    - SpecialistPoolServiceGrpcAsyncIOTransport:
        Type: public
        Protocol: asynchronous gRPC
        Implementation: grpc_asyncio.py

    - _BaseSpecialistPoolServiceRestTransport:
        Type: private
        Protocol: base REST transport
        Details: Contains inner classes `_BaseMETHOD`.
        Implementation: rest_base.py

    - SpecialistPoolServiceRestTransport:
        Type: public
        Protocol: synchronous REST
        Details: Inherits from `_BaseSpecialistPoolServiceRestTransport` and uses `METHOD` inner classes derived from parent's `_BaseMETHOD`.
        Implementation: rest.py
```

----------------------------------------

TITLE: FeaturestoreOnlineServingService Transport Inheritance
DESCRIPTION: Details the inheritance hierarchy for FeaturestoreOnlineServingService transports. It outlines the abstract base class (ABC) and its public and private child classes, specifying their purpose and the files where they are defined.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/featurestore_online_serving_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
FeaturestoreOnlineServingServiceTransport Inheritance Structure:

  FeaturestoreOnlineServingServiceTransport (ABC)
    - Base class for all transports.

  Public Children:
    - FeaturestoreOnlineServingServiceGrpcTransport
      - Purpose: Synchronous gRPC transport.
      - Defined in: grpc.py

    - FeaturestoreOnlineServingServiceGrpcAsyncIOTransport
      - Purpose: Asynchronous gRPC transport.
      - Defined in: grpc_asyncio.py

    - FeaturestoreOnlineServingServiceRestTransport
      - Purpose: Synchronous REST transport.
      - Derived from: _BaseFeaturestoreOnlineServingServiceRestTransport.
      - Contains inner classes: METHOD (derived from _BaseMETHOD).
      - Defined in: rest.py

  Private Children:
    - _BaseFeaturestoreOnlineServingServiceRestTransport
      - Purpose: Base REST transport.
      - Contains inner classes: _BaseMETHOD.
      - Defined in: rest_base.py
```

----------------------------------------

TITLE: Import Vertex AI SDK Components (Python)
DESCRIPTION: Imports essential classes from the vertexai.generative_models module. These classes are used for interacting with generative AI models, handling content, and defining tools.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/generative_models/README.md#_snippet_1

LANGUAGE: python
CODE:
```
from vertexai.generative_models import GenerativeModel, Image, Content, Part, Tool, FunctionDeclaration, GenerationConfig
```

----------------------------------------

TITLE: List Model Evaluations
DESCRIPTION: Shows how to list all model evaluation metrics associated with a Vertex AI Model. This is typically used for AutoML models to inspect performance.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_16

LANGUAGE: Python
CODE:
```
import google.cloud.aiplatform as aiplatform

# Assuming model is a Vertex AI Model object
# model = aiplatform.Model('projects/my-project/locations/us-central1/models/{MODEL_ID}')

evaluations = model.list_model_evaluations()
```

----------------------------------------

TITLE: FeatureOnlineStoreService Transport Inheritance
DESCRIPTION: Details the inheritance hierarchy for FeatureOnlineStoreService transports, including the base abstract class, synchronous/asynchronous gRPC transports, and synchronous REST transports with their respective base classes.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/feature_online_store_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
FeatureOnlineStoreService Transports:

Abstract Base Class:
  FeatureOnlineStoreServiceTransport
    - The abstract base class for all transport implementations.

Concrete Transports:
  - FeatureOnlineStoreServiceGrpcTransport (sync gRPC)
    - Public child of FeatureOnlineStoreServiceTransport.
    - Implements synchronous gRPC transport.
    - Defined in: grpc.py

  - FeatureOnlineStoreServiceGrpcAsyncIOTransport (async gRPC)
    - Public child of FeatureOnlineStoreServiceTransport.
    - Implements asynchronous gRPC transport.
    - Defined in: grpc_asyncio.py

  - _BaseFeatureOnlineStoreServiceRestTransport (base REST)
    - Private child of FeatureOnlineStoreServiceTransport.
    - Base class for REST transport, containing inner classes like _BaseMETHOD.
    - Defined in: rest_base.py

  - FeatureOnlineStoreServiceRestTransport (sync REST)
    - Public child of _BaseFeatureOnlineStoreServiceRestTransport.
    - Implements synchronous REST transport.
    - Contains METHOD classes derived from _BaseMETHOD.
    - Defined in: rest.py
```

----------------------------------------

TITLE: Run Single Sample Test
DESCRIPTION: Executes a specific test case within the samples/snippets directory using a specified Python version. The `-k` flag allows filtering tests by name, enabling targeted testing of individual samples.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_13

LANGUAGE: bash
CODE:
```
cd samples/snippets
nox -s py-3.9 -- -k <name of test>
```

----------------------------------------

TITLE: Create Vertex AI Endpoint
DESCRIPTION: Creates a new Vertex AI Endpoint resource. Endpoints are used to host deployed models for online predictions. Requires a display name.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_20

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

endpoint = aiplatform.Endpoint.create(display_name='my-endpoint')
```

----------------------------------------

TITLE: Evaluate with Prompt Templates using EvalTask
DESCRIPTION: Explains how to use prompt templates for evaluation when the 'prompt' column is not explicitly provided. Prompts are assembled from other dataset columns, which must match the template's variable names.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_11

LANGUAGE: python
CODE:
```
import pandas as pd
from vertexai.evaluation import EvalTask, MetricPromptTemplateExamples
from vertexai.generative_models import GenerativeModel

eval_dataset = pd.DataFrame({
    "context"    : [...],
    "instruction": [...],
})
result = EvalTask(
    dataset=eval_dataset,
    metrics=[MetricPromptTemplateExamples.Pointwise.SUMMARIZATION_QUALITY],
).evaluate(
    model=GenerativeModel("gemini-1.5-pro"),
    prompt_template="{instruction}. Article: {context}. Summary:",
)
```

----------------------------------------

TITLE: GenAiCacheService Module
DESCRIPTION: This snippet documents the main GenAiCacheService module. It includes all public members and inherited members, providing access to the service's functionalities for managing AI cache data.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1beta1/gen_ai_cache_service.rst#_snippet_0

LANGUAGE: python
CODE:
```
.. automodule:: google.cloud.aiplatform_v1beta1.services.gen_ai_cache_service
    :members:
    :inherited-members:
```

----------------------------------------

TITLE: Create Tabular Dataset
DESCRIPTION: Creates a new Vertex AI Tabular Dataset from a Google Cloud Storage source. This involves specifying a display name and the GCS path to the dataset file.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_4

LANGUAGE: Python
CODE:
```
my_dataset = aiplatform.TabularDataset.create(
    display_name="my-dataset", gcs_source=['gs://path/to/my/dataset.csv']
)
```

----------------------------------------

TITLE: LlmUtilityService Transport Hierarchy
DESCRIPTION: Details the abstract base class (ABC) and its public and private child classes for synchronous and asynchronous gRPC and REST transports.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/llm_utility_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
LlmUtilityServiceTransport:
  Abstract Base Class (ABC) for all transports.

  - LlmUtilityServiceGrpcTransport:
    Public child for synchronous gRPC transport.
    Defined in `grpc.py`.

  - LlmUtilityServiceGrpcAsyncIOTransport:
    Public child for asynchronous gRPC transport.
    Defined in `grpc_asyncio.py`.

  - _BaseLlmUtilityServiceRestTransport:
    Private child for base REST transport.
    Contains inner classes `_BaseMETHOD`.
    Defined in `rest_base.py`.

  - LlmUtilityServiceRestTransport:
    Public child for synchronous REST transport.
    Contains inner classes `METHOD` derived from `_BaseMETHOD`.
    Defined in `rest.py`.
```

----------------------------------------

TITLE: Import Vertex AI SDK
DESCRIPTION: Imports the necessary Vertex AI namespace for using the SDK's functionalities. This is the first step before initializing or using any Vertex AI services.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_2

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform
```

----------------------------------------

TITLE: Automatic Function Calling Setup (Python)
DESCRIPTION: Provides setup for automatic function calling, noting a limitation regarding nested types for parameters in the `FunctionDeclaration.from_func` converter. It suggests providing full `FunctionDeclaration` objects instead.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/generative_models/README.md#_snippet_7

LANGUAGE: python
CODE:
```
from vertexai.preview.generative_models import GenerativeModel, Tool, FunctionDeclaration, AutomaticFunctionCallingResponder
```

----------------------------------------

TITLE: Deploy Model to Endpoint
DESCRIPTION: Deploys a specified model to an existing Vertex AI endpoint. Configuration includes replica counts, machine types, and accelerator details for serving.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_23

LANGUAGE: python
CODE:
```
model = aiplatform.Model('/projects/my-project/locations/us-central1/models/{MODEL_ID}')

endpoint.deploy(model,
                  min_replica_count=1,
                  max_replica_count=5,
                  machine_type='n1-standard-4',
                  accelerator_type='NVIDIA_TESLA_K80',
                  accelerator_count=1)
```

----------------------------------------

TITLE: FeatureOnlineStoreService Transport Inheritance
DESCRIPTION: Details the inheritance hierarchy for FeatureOnlineStoreService transports, including the base abstract class, synchronous/asynchronous gRPC transports, and synchronous REST transports with their respective base classes.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/feature_online_store_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
FeatureOnlineStoreService Transports:

Abstract Base Class:
  FeatureOnlineStoreServiceTransport
    - The abstract base class for all transport implementations.

Concrete Transports:
  - FeatureOnlineStoreServiceGrpcTransport (sync gRPC)
    - Public child of FeatureOnlineStoreServiceTransport.
    - Implements synchronous gRPC transport.
    - Defined in: grpc.py

  - FeatureOnlineStoreServiceGrpcAsyncIOTransport (async gRPC)
    - Public child of FeatureOnlineStoreServiceTransport.
    - Implements asynchronous gRPC transport.
    - Defined in: grpc_asyncio.py

  - _BaseFeatureOnlineStoreServiceRestTransport (base REST)
    - Private child of FeatureOnlineStoreServiceTransport.
    - Base class for REST transport, containing inner classes like _BaseMETHOD.
    - Defined in: rest_base.py

  - FeatureOnlineStoreServiceRestTransport (sync REST)
    - Public child of _BaseFeatureOnlineStoreServiceRestTransport.
    - Implements synchronous REST transport.
    - Contains METHOD classes derived from _BaseMETHOD.
    - Defined in: rest.py
```

----------------------------------------

TITLE: Evaluate with Gemini Model Inference using EvalTask
DESCRIPTION: Shows how to perform evaluation by directly using a Vertex AI GenerativeModel instance for inference. The model is specified via the `model` parameter in the `evaluate` method, and the dataset must contain a 'prompt' column.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_10

LANGUAGE: python
CODE:
```
from vertexai.evaluation import EvalTask
from vertexai.generative_models import GenerativeModel

eval_dataset = pd.DataFrame({
    "reference": [...],
    "prompt"  : [...],
})
result = EvalTask(
    dataset=eval_dataset,
    metrics=["exact_match", "bleu", "rouge_1", "rouge_l_sum"],
    experiment="my-experiment",
).evaluate(
    model=GenerativeModel("gemini-1.5-pro"),
    experiment_run_name="gemini-eval-run"
)
```

----------------------------------------

TITLE: MigrationService Transport Inheritance
DESCRIPTION: Details the inheritance hierarchy for MigrationService transports, including synchronous and asynchronous gRPC, and REST transports. This structure allows for flexible integration with different communication protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/migration_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
MigrationServiceTransport (ABC)
  - Base class for all transport implementations.

  Public Children:
  - MigrationServiceGrpcTransport:
    - Implements synchronous gRPC transport.
    - Defined in: grpc.py

  - MigrationServiceGrpcAsyncIOTransport:
    - Implements asynchronous gRPC transport.
    - Defined in: grpc_asyncio.py

  - MigrationServiceRestTransport:
    - Implements synchronous REST transport.
    - Inherits from _BaseMigrationServiceRestTransport.
    - Contains inner classes METHOD derived from _BaseMETHOD.
    - Defined in: rest.py

  Private Children:
  - _BaseMigrationServiceRestTransport:
    - Base class for REST transport implementations.
    - Contains inner classes _BaseMETHOD.
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: Vizier Service Transport Hierarchy
DESCRIPTION: Describes the inheritance structure for VizierService transports, including base classes and concrete implementations for gRPC and REST. This structure defines how the service communicates via different protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/vizier_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
VizierServiceTransport:
  Abstract Base Class (ABC) for all Vizier Service transports.

  Children:
    VizierServiceGrpcTransport:
      Description: Public child for synchronous gRPC transport.
      Defined in: grpc.py

    VizierServiceGrpcAsyncIOTransport:
      Description: Public child for asynchronous gRPC transport.
      Defined in: grpc_asyncio.py

    _BaseVizierServiceRestTransport:
      Description: Private child for base REST transport.
      Contains inner classes like _BaseMETHOD.
      Defined in: rest_base.py

    VizierServiceRestTransport:
      Description: Public child for synchronous REST transport.
      Inherits from _BaseVizierServiceRestTransport.
      Contains inner classes METHOD derived from the parent's _BaseMETHOD classes.
      Defined in: rest.py
```

----------------------------------------

TITLE: Install google-cloud-storage
DESCRIPTION: Installs google-cloud-storage version 2.2.1. This version is increased for compatibility with kfp 2.0.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_4

LANGUAGE: python
CODE:
```
google-cloud-storage==2.2.1 # Increased for kfp 2.0 compatibility
```

----------------------------------------

TITLE: Initialize Cloud Profiler for Vertex AI Training
DESCRIPTION: Provides the code snippet to initialize the Cloud Profiler within a TensorFlow training script for Vertex AI jobs. This integration allows for on-demand profiling of remote training jobs, with results visualized in Vertex AI Tensorboard.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_31

LANGUAGE: Python
CODE:
```
from google.cloud.aiplatform.training_utils import cloud_profiler

# ... your training code ...
cloud_profiler.init()
```

----------------------------------------

TITLE: Install packaging
DESCRIPTION: Installs the packaging library version 24.1. This version is increased to resolve a canonicalize_version error (b/377774673).
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_5

LANGUAGE: python
CODE:
```
packaging==24.1 # Increased to unbreak canonicalize_version error (b/377774673)
```

----------------------------------------

TITLE: Install Vertex AI SDK
DESCRIPTION: Installs or upgrades the google-cloud-aiplatform Python package to the specified version. This is the first step to using the Vertex Generative AI SDK.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_0

LANGUAGE: shell
CODE:
```
pip3 install --upgrade --user "google-cloud-aiplatform>=1.38"
```

----------------------------------------

TITLE: Run Vertex AI Training Job
DESCRIPTION: Initiates a Vertex AI training job with specified dataset, target column, split fractions, budget, and model display name. It returns the trained model object.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_11

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

# Assume dataset and job are already initialized
# dataset = aiplatform.TabularDataset('projects/my-project/locations/us-central1/datasets/my-dataset-id')
# job = aiplatform.AutoMlTabularTrainingJob(
#     display_name='automl_tabular_job',
#     optimization_prediction_type='regression',
#     optimization_objective='minimize-rmse',
# )

# model = job.run(
#     dataset=dataset,
#     target_column="target_column_name",
#     training_fraction_split=0.6,
#     validation_fraction_split=0.2,
#     test_fraction_split=0.2,
#     budget_milli_node_hours=1000,
#     model_display_name="my-automl-model",
#     disable_early_stopping=False,
# )
```

----------------------------------------

TITLE: Create Model Evaluation Reference (by IDs)
DESCRIPTION: Creates a reference to a model evaluation by providing the model ID and evaluation ID. This simplifies referencing evaluations when the full resource name is not readily available.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_19

LANGUAGE: python
CODE:
```
evaluation = aiplatform.ModelEvaluation(
  evaluation_name={EVALUATION_ID},
  model_id={MODEL_ID})
```

----------------------------------------

TITLE: PersistentResourceServiceGrpcTransport (Sync gRPC)
DESCRIPTION: A public child class inheriting from PersistentResourceServiceTransport, providing the concrete implementation for synchronous gRPC transport. This class is defined in the grpc.py file.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/persistent_resource_service/transports/README.rst#_snippet_1

LANGUAGE: APIDOC
CODE:
```
class PersistentResourceServiceGrpcTransport(PersistentResourceServiceTransport):
    """Sync gRPC transport for PersistentResourceService."""
    pass

# Defined in: grpc.py
```

----------------------------------------

TITLE: SpecialistPoolService Transport Hierarchy
DESCRIPTION: Details the abstract base class and its public and private children for different transport mechanisms (gRPC, REST) and execution models (synchronous, asynchronous).
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/specialist_pool_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
SpecialistPoolServiceTransport:
  Abstract Base Class (ABC) for all transports.

  - SpecialistPoolServiceGrpcTransport:
    Public child for synchronous gRPC transport.
    Defined in: grpc.py

  - SpecialistPoolServiceGrpcAsyncIOTransport:
    Public child for asynchronous gRPC transport.
    Defined in: grpc_asyncio.py

  - _BaseSpecialistPoolServiceRestTransport:
    Private child for base REST transport.
    Contains inner classes `_BaseMETHOD`.
    Defined in: rest_base.py

  - SpecialistPoolServiceRestTransport:
    Public child for synchronous REST transport.
    Contains inner classes `METHOD` derived from the parent's `_BaseMETHOD` classes.
    Defined in: rest.py
```

----------------------------------------

TITLE: Define ADK Agent
DESCRIPTION: Creates an ADK Agent instance using Vertex AI's AdkApp. It specifies the model, agent name, and integrates the custom tool defined previously.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_16

LANGUAGE: python
CODE:
```
from google.adk.agents import Agent
from vertexai.preview.reasoning_engines import AdkApp

app = AdkApp(agent=Agent(
    model="gemini-2.0-flash",        # Required.
    name='currency_exchange_agent',  # Required.
    tools=[get_exchange_rate],       # Optional.
))
```

----------------------------------------

TITLE: Perform BYOR Evaluation with Vertex AI EvalTask
DESCRIPTION: Demonstrates how to conduct Bring-Your-Own-Response (BYOR) evaluation using the EvalTask. This involves providing model responses directly in the dataset, with optional baseline responses for pairwise metrics.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_9

LANGUAGE: python
CODE:
```
import pandas as pd
from vertexai.evaluation import EvalTask, MetricPromptTemplateExamples

eval_dataset = pd.DataFrame({
        "prompt"  : [...],
        "reference": [...],
        "response" : [...],
        "baseline_model_response": [...],
})
eval_task = EvalTask(
    dataset=eval_dataset,
    metrics=[
            "bleu",
            "rouge_l_sum",
            MetricPromptTemplateExamples.Pointwise.FLUENCY,
            MetricPromptTemplateExamples.Pairwise.SAFETY
    ],
    experiment="my-experiment",
)
eval_result = eval_task.evaluate(experiment_run_name="eval-experiment-run")
```

----------------------------------------

TITLE: Submit Vertex AI Pipeline Asynchronously
DESCRIPTION: Demonstrates submitting a Vertex AI Pipeline job asynchronously using the `submit` method. This allows the script to return immediately without waiting for the pipeline to finish execution, useful for non-blocking operations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_27

LANGUAGE: Python
CODE:
```
from google.cloud.aiplatform import PipelineJob

# Instantiate PipelineJob object
pl = PipelineJob(
    display_name="My first pipeline",
    enable_caching=False,
    template_path="pipeline.json",
    parameter_values=parameter_values,
    pipeline_root=pipeline_root,
)

# Submit the Pipeline to Vertex AI
pl.submit(
    service_account=service_account,
)
```

----------------------------------------

TITLE: PersistentResourceServiceGrpcTransport (Sync gRPC)
DESCRIPTION: A public child class inheriting from PersistentResourceServiceTransport, providing the concrete implementation for synchronous gRPC transport. This class is defined in the grpc.py file.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/persistent_resource_service/transports/README.rst#_snippet_1

LANGUAGE: APIDOC
CODE:
```
class PersistentResourceServiceGrpcTransport(PersistentResourceServiceTransport):
    """Sync gRPC transport for PersistentResourceService."""
    pass

# Defined in: grpc.py
```

----------------------------------------

TITLE: Vizier Service Transport Hierarchy
DESCRIPTION: Describes the inheritance structure for VizierService transports, including base classes and concrete implementations for gRPC and REST. This structure defines how the service communicates via different protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/vizier_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
VizierServiceTransport:
  Abstract Base Class (ABC) for all Vizier Service transports.

  Children:
    VizierServiceGrpcTransport:
      Description: Public child for synchronous gRPC transport.
      Defined in: grpc.py

    VizierServiceGrpcAsyncIOTransport:
      Description: Public child for asynchronous gRPC transport.
      Defined in: grpc_asyncio.py

    _BaseVizierServiceRestTransport:
      Description: Private child for base REST transport.
      Contains inner classes like _BaseMETHOD.
      Defined in: rest_base.py

    VizierServiceRestTransport:
      Description: Public child for synchronous REST transport.
      Inherits from _BaseVizierServiceRestTransport.
      Contains inner classes METHOD derived from the parent's _BaseMETHOD classes.
      Defined in: rest.py
```

----------------------------------------

TITLE: Set Environment Variables for Faster Linting
DESCRIPTION: Configures environment variables to point to the official repository's main branch, potentially speeding up linting checks by using cached or up-to-date code references.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_6

LANGUAGE: bash
CODE:
```
export GOOGLE_CLOUD_TESTING_REMOTE="upstream"
export GOOGLE_CLOUD_TESTING_BRANCH="main"
```

----------------------------------------

TITLE: Upload Vertex AI Model
DESCRIPTION: Uploads a model to Vertex AI. Requires a display name, the GCS URI of the model artifacts, and the serving container image URI. Returns the uploaded Model object.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_13

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

model = aiplatform.Model.upload(
    display_name='my-model',
    artifact_uri="gs://python/to/my/model/dir",
    serving_container_image_uri="us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-2:latest",
)
```

----------------------------------------

TITLE: Pairwise Metric Evaluation with Model Inference using EvalTask
DESCRIPTION: Illustrates performing pairwise metric evaluation where both a candidate and a baseline model are used. The `PairwiseMetric` is configured with a `baseline_model`, and the `EvalTask.evaluate` method takes the candidate `model`.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_13

LANGUAGE: python
CODE:
```
import pandas as pd
from vertexai.evaluation import EvalTask, MetricPromptTemplateExamples, PairwiseMetric
from vertexai.generative_models import GenerativeModel

baseline_model = GenerativeModel("gemini-1.0-pro")
candidate_model = GenerativeModel("gemini-1.5-pro")

pairwise_groundedness = PairwiseMetric(
    metric_prompt_template=MetricPromptTemplateExamples.get_prompt_template(
        "pairwise_groundedness"
    ),
    baseline_model=baseline_model,
)
eval_dataset = pd.DataFrame({
    "prompt"  : [...],
})
result = EvalTask(
    dataset=eval_dataset,
    metrics=[pairwise_groundedness],
    experiment="my-pairwise-experiment",
).evaluate(
    model=candidate_model,
    experiment_run_name="gemini-pairwise-eval-run",
)
```

----------------------------------------

TITLE: Create Model Evaluation Reference (by name)
DESCRIPTION: Creates a reference to a model evaluation by providing its full resource name. This is useful for accessing existing evaluations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_18

LANGUAGE: python
CODE:
```
evaluation = aiplatform.ModelEvaluation(
  evaluation_name='projects/my-project/locations/us-central1/models/{MODEL_ID}/evaluations/{EVALUATION_ID}')
```

----------------------------------------

TITLE: MigrationService Transport Inheritance
DESCRIPTION: Details the inheritance hierarchy for MigrationService transports, including synchronous and asynchronous gRPC, and REST transports. This structure allows for flexible integration with different communication protocols.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/migration_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
MigrationServiceTransport (ABC)
  - Base class for all transport implementations.

  Public Children:
  - MigrationServiceGrpcTransport:
    - Implements synchronous gRPC transport.
    - Defined in: grpc.py

  - MigrationServiceGrpcAsyncIOTransport:
    - Implements asynchronous gRPC transport.
    - Defined in: grpc_asyncio.py

  - MigrationServiceRestTransport:
    - Implements synchronous REST transport.
    - Inherits from _BaseMigrationServiceRestTransport.
    - Contains inner classes METHOD derived from _BaseMETHOD.
    - Defined in: rest.py

  Private Children:
  - _BaseMigrationServiceRestTransport:
    - Base class for REST transport implementations.
    - Contains inner classes _BaseMETHOD.
    - Defined in: rest_base.py
```

----------------------------------------

TITLE: Vertex AI Platform Transport Hierarchy
DESCRIPTION: Details the inheritance hierarchy for Vertex AI Platform transports. It outlines the abstract base class `VertexRagServiceTransport` and its public and private child classes for gRPC and REST communication, specifying their respective implementation files.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/vertex_rag_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
VertexRagServiceTransport (Abstract Base Class):
  - Base class for all transport implementations.

  Public Children:
  - VertexRagServiceGrpcTransport:
    - For synchronous gRPC transport.
    - Defined in: `grpc.py`
  - VertexRagServiceGrpcAsyncIOTransport:
    - For asynchronous gRPC transport.
    - Defined in: `grpc_asyncio.py`
  - VertexRagServiceRestTransport:
    - For synchronous REST transport.
    - Inherits from `_BaseVertexRagServiceRestTransport`.
    - Uses inner classes `METHOD` derived from parent's `_BaseMETHOD`.
    - Defined in: `rest.py`

  Private Children:
  - _BaseVertexRagServiceRestTransport:
    - Base REST transport with inner classes `_BaseMETHOD`.
    - Defined in: `rest_base.py`
```

----------------------------------------

TITLE: PersistentResourceServiceRestTransport (Sync REST)
DESCRIPTION: A public child class inheriting from _BasePersistentResourceServiceRestTransport, providing the concrete implementation for synchronous REST transport. It defines public METHOD classes derived from the parent's _BaseMETHOD classes. This class is defined in the rest.py file.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/persistent_resource_service/transports/README.rst#_snippet_4

LANGUAGE: APIDOC
CODE:
```
class PersistentResourceServiceRestTransport(_BasePersistentResourceServiceRestTransport):
    """Sync REST transport for PersistentResourceService."""
    class METHOD(_BaseMETHOD):
        """Concrete class for REST method definitions."""
        pass

# Defined in: rest.py
```

----------------------------------------

TITLE: Evaluate Gen AI Model Responses
DESCRIPTION: Details how to evaluate the generated model responses against ground truth or quality standards. This involves using the `evaluate` method with the inference results and specifying desired metrics.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_2

LANGUAGE: Python
CODE:
```
eval_result = client.evals.evaluate(
    dataset=inference_results,
    metrics=[
        types.Metric(name='exact_match'),
        types.Metric(name='rouge_l_sum'),
        types.PrebuiltMetric.TEXT_QUALITY,
    ]
)
```

----------------------------------------

TITLE: Install google-adk
DESCRIPTION: Installs the google-adk library version 0.0.2.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_9

LANGUAGE: python
CODE:
```
google-adk==0.0.2
```

----------------------------------------

TITLE: Create and Activate Virtual Environment (Bash)
DESCRIPTION: Creates a Python virtual environment named 'env' and activates it. This isolates project dependencies, ensuring compatibility and preventing conflicts with other Python projects. Samples are compatible with Python 3.7+.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/scripts/readme-gen/templates/install_deps.tmpl.rst#_snippet_1

LANGUAGE: bash
CODE:
```
virtualenv env
source env/bin/activate
```

----------------------------------------

TITLE: Deploy Model with Advanced Container Configuration
DESCRIPTION: Demonstrates deploying a Vertex AI model using a custom container image with advanced configuration. This includes setting container commands, arguments, ports, environment variables, predict/health routes, shared memory, gRPC ports, and custom startup/health probes for production-grade deployments.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/model_garden/README.md#_snippet_6

LANGUAGE: python
CODE:
```
endpoint = model.deploy(
    serving_container_image_uri="us-docker.pkg.dev/vertex-ai/custom-container:latest",
    container_command=["python3"],
    container_args=["serve.py"],
    container_ports=[8888],
    container_env_vars={"ENV": "prod"},
    container_predict_route="/predict",
    container_health_route="/health",
    serving_container_shared_memory_size_mb=512,
    serving_container_grpc_ports=[9000],
    serving_container_startup_probe_exec=["/bin/check-start.sh"],
    serving_container_health_probe_exec=["/bin/health-check.sh"]
)
```

----------------------------------------

TITLE: Install ipython
DESCRIPTION: Installs ipython version 8.22.2. This version is pinned to resolve a TypeAliasType import error.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_8

LANGUAGE: python
CODE:
```
ipython==8.22.2 # Pinned to unbreak TypeAliasType import error
```

----------------------------------------

TITLE: Query Deployed Agent
DESCRIPTION: Sends a query to the deployed Agent Engine application and streams the response events. This verifies the agent's functionality in the cloud environment.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_19

LANGUAGE: python
CODE:
```
for event in remote_app.stream_query(
    user_id="user-id",
    message="What is the exchange rate from US dollars to SEK today?",
):
    print(event)
```

----------------------------------------

TITLE: Chat with Gemini Models (Python)
DESCRIPTION: Enables stateful multi-turn conversations with Gemini models. It initializes a chat session and sends messages, allowing for context to be maintained across turns.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/generative_models/README.md#_snippet_4

LANGUAGE: python
CODE:
```
from vertexai.generative_models import GenerativeModel, Image

vision_model = GenerativeModel("gemini-ultra-vision")
vision_chat = vision_model.start_chat()
image = Image.load_from_file("image.jpg")
print(vision_chat.send_message(["I like this image.", image]))
print(vision_chat.send_message("What things do I like?."))
```

----------------------------------------

TITLE: Vertex AI Platform Transport Hierarchy
DESCRIPTION: Details the inheritance hierarchy for Vertex AI Platform transports. It outlines the abstract base class `VertexRagServiceTransport` and its public and private child classes for gRPC and REST communication, specifying their respective implementation files.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/vertex_rag_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
VertexRagServiceTransport (Abstract Base Class):
  - Base class for all transport implementations.

  Public Children:
  - VertexRagServiceGrpcTransport:
    - For synchronous gRPC transport.
    - Defined in: `grpc.py`
  - VertexRagServiceGrpcAsyncIOTransport:
    - For asynchronous gRPC transport.
    - Defined in: `grpc_asyncio.py`
  - VertexRagServiceRestTransport:
    - For synchronous REST transport.
    - Inherits from `_BaseVertexRagServiceRestTransport`.
    - Uses inner classes `METHOD` derived from parent's `_BaseMETHOD`.
    - Defined in: `rest.py`

  Private Children:
  - _BaseVertexRagServiceRestTransport:
    - Base REST transport with inner classes `_BaseMETHOD`.
    - Defined in: `rest_base.py`
```

----------------------------------------

TITLE: Create Vertex AI Model Evaluation Reference
DESCRIPTION: Creates a reference to an existing Vertex AI Model Evaluation using its full resource name or by providing model and evaluation IDs. This allows direct access to the evaluation object.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_17

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

# Using full resource name
evaluation_by_name = aiplatform.ModelEvaluation(
  evaluation_name='projects/my-project/locations/us-central1/models/{MODEL_ID}/evaluations/{EVALUATION_ID}')

# Using model and evaluation IDs
evaluation_by_ids = aiplatform.ModelEvaluation(
  evaluation_name='{EVALUATION_ID}',
  model_id='{MODEL_ID}')
```

----------------------------------------

TITLE: Retrieve Vertex AI Model
DESCRIPTION: Shows how to retrieve an existing Vertex AI Model resource using its resource name. This is useful for deploying or exporting a previously trained model.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_13

LANGUAGE: Python
CODE:
```
import google.cloud.aiplatform as aiplatform

model = aiplatform.Model('/projects/my-project/locations/us-central1/models/{MODEL_ID}')
```

----------------------------------------

TITLE: Initialize Vertex AI SDK
DESCRIPTION: Initializes the Vertex AI SDK with common configurations such as project ID, region, and staging bucket. This setup is crucial for all subsequent SDK operations.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_3

LANGUAGE: Python
CODE:
```
aiplatform.init(
    # your Google Cloud Project ID or number
    # environment default used is not set
    project='my-project',

    # the Vertex AI region you will use
    # defaults to us-central1
    location='us-central1',

    # Google Cloud Storage bucket in same region as location
    # used to stage artifacts
    staging_bucket='gs://my_staging_bucket',

    # custom google.auth.credentials.Credentials
    # environment default credentials used if not set
    credentials=my_credentials,

    # customer managed encryption key resource name
    # will be applied to all Vertex AI resources if set
    encryption_spec_key_name=my_encryption_key_name,

    # the name of the experiment to use to track
    # logged metrics and parameters
    experiment='my-experiment',

    # description of the experiment above
    experiment_description='my experiment description'
)
```

----------------------------------------

TITLE: VizierService Pagers
DESCRIPTION: Details the pagers used for handling large result sets when querying the VizierService. Pagers simplify iteration over lists of resources, such as studies or trials.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/aiplatform_v1/vizier_service.rst#_snippet_1

LANGUAGE: python
CODE:
```
from google.cloud.aiplatform.v1.services import vizier_service

# Initialize the client
client = vizier_service.VizierServiceClient()

# Example usage (conceptual):
# request = vizier_service.ListStudiesRequest(parent='projects/PROJECT_ID/locations/LOCATION_ID')
# page_result = client.list_studies(request=request)
# 
# # Iterate through results using the pager
# for study in page_result.studies:
#     print(study.display_name)
```

----------------------------------------

TITLE: Vertex AI Custom Training Environment Variables
DESCRIPTION: Shows the environment variables that Vertex AI populates for custom training jobs. Your training script must read these to access data and write model artifacts.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_10

LANGUAGE: Python
CODE:
```
import os

# Accessing data URIs and format
data_format = os.environ['AIP_DATA_FORMAT']
training_data_uri = os.environ['AIP_TRAINING_DATA_URI']
validation_data_uri = os.environ['AIP_VALIDATION_DATA_URI']
test_data_uri = os.environ['AIP_TEST_DATA_URI']

# Writing model artifacts
model_output_dir = os.environ['AIP_MODEL_DIR']
```

----------------------------------------

TITLE: Custom Training Script Model Output
DESCRIPTION: Shows how a custom training script must write its model artifacts to the directory specified by the 'AIP_MODEL_DIR' environment variable.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_8

LANGUAGE: Python
CODE:
```
import os

os.environ['AIP_MODEL_DIR']
```

----------------------------------------

TITLE: Create Asynchronous Batch Prediction Job
DESCRIPTION: Submits a batch prediction job asynchronously, allowing the program to continue execution without waiting for the job to complete. Includes methods to monitor job status.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_21

LANGUAGE: python
CODE:
```
batch_prediction_job = model.batch_predict(..., sync=False)

# wait for resource to be created
batch_prediction_job.wait_for_resource_creation()

# get the state
print(batch_prediction_job.state)

# block until job is complete
batch_prediction_job.wait()
```

----------------------------------------

TITLE: PersistentResourceServiceRestTransport (Sync REST)
DESCRIPTION: A public child class inheriting from _BasePersistentResourceServiceRestTransport, providing the concrete implementation for synchronous REST transport. It defines public METHOD classes derived from the parent's _BaseMETHOD classes. This class is defined in the rest.py file.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/persistent_resource_service/transports/README.rst#_snippet_4

LANGUAGE: APIDOC
CODE:
```
class PersistentResourceServiceRestTransport(_BasePersistentResourceServiceRestTransport):
    """Sync REST transport for PersistentResourceService."""
    class METHOD(_BaseMETHOD):
        """Concrete class for REST method definitions."""
        pass

# Defined in: rest.py
```

----------------------------------------

TITLE: Create Batch Prediction Job
DESCRIPTION: Initiates a batch prediction job using a specified model. It requires defining job parameters like display name, input/output formats, machine type, and data sources.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_20

LANGUAGE: python
CODE:
```
model = aiplatform.Model('/projects/my-project/locations/us-central1/models/{MODEL_ID}')

batch_prediction_job = model.batch_predict(
  job_display_name='my-batch-prediction-job',
  instances_format='csv',
  machine_type='n1-standard-4',
  gcs_source=['gs://path/to/my/file.csv'],
  gcs_destination_prefix='gs://path/to/my/batch_prediction/results/',
  service_account='my-sa@my-project.iam.gserviceaccount.com'
)
```

----------------------------------------

TITLE: Install Pre-commit Hooks
DESCRIPTION: Installs the pre-commit framework's git hooks to automate code checks before committing. This helps enforce coding style and quality standards.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_3

LANGUAGE: bash
CODE:
```
$ pre-commit install
pre-commit installed at .git/hooks/pre-commit
```

----------------------------------------

TITLE: Initialize Vertex AI SDK
DESCRIPTION: Initializes the Vertex AI SDK with your Google Cloud project ID and location. This setup is required before making any calls to Vertex AI services.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_1

LANGUAGE: python
CODE:
```
import vertexai

vertexai.init(project='my-project', location='us-central1')
```

----------------------------------------

TITLE: Automatic Function Calling Responder
DESCRIPTION: Introduces the AutomaticFunctionCallingResponder for handling function calls. Note that the `FunctionDeclaration.from_func` converter has limitations with nested types; provide full `FunctionDeclaration` objects instead.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_7

LANGUAGE: python
CODE:
```
from vertexai.preview.generative_models import GenerativeModel, Tool, FunctionDeclaration, AutomaticFunctionCallingResponder
```

----------------------------------------

TITLE: Run Unit Tests with Nox
DESCRIPTION: Execute unit tests for the python-aiplatform library using the nox automation tool. This command runs all configured unit tests.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_1

LANGUAGE: bash
CODE:
```
$ nox -s unit
```

----------------------------------------

TITLE: Deploy Hugging Face Model
DESCRIPTION: Deploys a model directly from Hugging Face using its model ID. Supports gated models by providing an access token.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/model_garden/README.md#_snippet_3

LANGUAGE: python
CODE:
```
from vertexai import model_garden

# Deploy a public Hugging Face model
model = model_garden.OpenModel("Qwen/Qwen2-1.5B-Instruct")
endpoint = model.deploy()

# Deploy a gated Hugging Face model
endpoint = model.deploy(hugging_face_access_token="your_hf_token")
```

----------------------------------------

TITLE: Install pytest-xdist
DESCRIPTION: Installs pytest-xdist version 3.3.1. This version is pinned to resolve issues in unit tests.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.12.txt#_snippet_6

LANGUAGE: python
CODE:
```
pytest-xdist==3.3.1 # Pinned to unbreak unit tests
```

----------------------------------------

TITLE: Install Python Package: pytest
DESCRIPTION: pytest is a powerful Python testing framework that makes it easy to write small, readable tests. It supports fixtures, parametrization, and a rich plugin ecosystem for enhanced testing capabilities.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/samples/snippets/requirements-test.txt#_snippet_0

LANGUAGE: python
CODE:
```
pytest==7.2.0
```

----------------------------------------

TITLE: Evaluate with Custom Model Inference using EvalTask
DESCRIPTION: Details how to integrate custom inference functions for evaluation. The custom function is passed to the `model` parameter, and it must accept a string input (typically from the 'prompt' column) and return a string response.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_12

LANGUAGE: python
CODE:
```
from openai import OpenAI
from vertexai.evaluation import EvalTask, MetricPromptTemplateExamples


client = OpenAI()
def custom_model_fn(input: str) -> str:
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
        {"role": "user", "content": input}
        ]
    )
    return response.choices[0].message.content

eval_dataset = pd.DataFrame({
    "prompt"  : [...],
    "reference": [...],
})
result = EvalTask(
    dataset=eval_dataset,
    metrics=[MetricPromptTemplateExamples.Pointwise.SAFETY],
    experiment="my-experiment",
).evaluate(
    model=custom_model_fn,
    experiment_run_name="gpt-eval-run"
)
```

----------------------------------------

TITLE: _BasePersistentResourceServiceRestTransport (Base REST)
DESCRIPTION: A private child class inheriting from PersistentResourceServiceTransport, serving as the base for REST transport implementations. It contains inner classes named _BaseMETHOD for defining method-specific logic. This class is defined in the rest_base.py file.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/persistent_resource_service/transports/README.rst#_snippet_3

LANGUAGE: APIDOC
CODE:
```
class _BasePersistentResourceServiceRestTransport(PersistentResourceServiceTransport):
    """Base REST transport for PersistentResourceService."""
    class _BaseMETHOD:
        """Base class for REST method definitions."""
        pass

# Defined in: rest_base.py
```

----------------------------------------

TITLE: List Model Deployment Options
DESCRIPTION: Inspects the available deployment configurations, such as compatible machine types and container images, for a given model.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/model_garden/README.md#_snippet_4

LANGUAGE: python
CODE:
```
from vertexai import model_garden

model = model_garden.OpenModel("google/paligemma@paligemma-224-float32")
deploy_options = model.list_deploy_options()
```

----------------------------------------

TITLE: _BasePersistentResourceServiceRestTransport (Base REST)
DESCRIPTION: A private child class inheriting from PersistentResourceServiceTransport, serving as the base for REST transport implementations. It contains inner classes named _BaseMETHOD for defining method-specific logic. This class is defined in the rest_base.py file.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/persistent_resource_service/transports/README.rst#_snippet_3

LANGUAGE: APIDOC
CODE:
```
class _BasePersistentResourceServiceRestTransport(PersistentResourceServiceTransport):
    """Base REST transport for PersistentResourceService."""
    class _BaseMETHOD:
        """Base class for REST method definitions."""
        pass

# Defined in: rest_base.py
```

----------------------------------------

TITLE: Initialize Cloud Profiler
DESCRIPTION: Integrates Cloud Profiler into a TensorFlow training script for Vertex AI. This involves importing the necessary utility and calling the init function. The profiler data can then be visualized in Vertex Tensorboard.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/training_utils/cloud_profiler/README.rst#_snippet_0

LANGUAGE: Python
CODE:
```
from google.cloud.aiplatform.training_utils import cloud_profiler
...
cloud_profiler.init()
```

----------------------------------------

TITLE: PersistentResourceServiceTransport ABC
DESCRIPTION: The abstract base class (ABC) that defines the common interface for all transport implementations of the PersistentResourceService. It serves as the foundation for concrete transport classes.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/persistent_resource_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
class PersistentResourceServiceTransport:
    """Abstract base class for PersistentResourceService transports."""
    pass
```

----------------------------------------

TITLE: Run System Tests with Nox
DESCRIPTION: Executes system tests for the python-aiplatform library using the nox automation tool. System tests are typically configured for specific Python versions.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_7

LANGUAGE: bash
CODE:
```
# Run all system tests
$ nox -s system
```

----------------------------------------

TITLE: Python Project Dependencies
DESCRIPTION: Lists the Python package dependencies and version constraints required for the project. This file is essential for setting up the correct development environment and ensuring compatibility.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/testing/constraints-3.10.txt#_snippet_0

LANGUAGE: Constraints
CODE:
```
# -*- coding: utf-8 -*-
# This constraints file is required for unit tests.
# List all library dependencies and extras in this file.
google-api-core==2.21.0 # Tests google-api-core with rest async support
google-auth==2.35.0 # Tests google-auth with rest async support
proto-plus==1.22.3
protobuf
mock==4.0.2
google-cloud-storage==2.2.1 # Increased for kfp 2.0 compatibility
packaging==24.1 # Increased to unbreak canonicalize_version error (b/377774673)
grpcio-testing==1.34.0
mlflow==2.16.0 # Pinned to speed up installation
pytest-xdist==3.3.1 # Pinned to unbreak unit tests
ray==2.4.0 # Pinned until 2.9.3 is verified for Ray tests
ipython==8.22.2 # Pinned to unbreak TypeAliasType import error
scikit-learn!=1.4.1.post1 # Pin to unbreak test_sklearn (b/332610038)
requests==2.31.0 # Pinned to unbreak http+docker error (b/342669351)
google-vizier==0.1.21
google-adk==0.0.2
```

----------------------------------------

TITLE: Install Agent Engine SDK
DESCRIPTION: Installs the necessary Google Cloud AI Platform packages with agent engine and ADK support. Ensure you have Python 3 installed.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_14

LANGUAGE: shell
CODE:
```
pip3 install --upgrade --user "google-cloud-aiplatform[agent_engines,adk]>=1.95.1"
```

----------------------------------------

TITLE: Train AutoML Tabular Model
DESCRIPTION: Initiates an AutoML training job for tabular data. This involves selecting a pre-created dataset and defining the job's display name.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_10

LANGUAGE: Python
CODE:
```
dataset = aiplatform.TabularDataset('projects/my-project/location/us-central1/datasets/{DATASET_ID}')

job = aiplatform.AutoMLTabularTrainingJob(
  display_name="train-automl",
)
```

----------------------------------------

TITLE: Format Code with Black
DESCRIPTION: Applies the 'black' code formatter to the project to ensure consistent styling. This session automatically formats Python code according to project standards.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_4

LANGUAGE: bash
CODE:
```
$ nox -s blacken
```

----------------------------------------

TITLE: List and Filter Deployable Models
DESCRIPTION: Retrieves a list of all models available for deployment through Model Garden. Supports filtering by Hugging Face models or keywords.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/model_garden/README.md#_snippet_2

LANGUAGE: python
CODE:
```
from vertexai import model_garden

# List all deployable models
models = model_garden.list_deployable_models()

# Filter for Hugging Face models and by keyword
models = model_garden.list_deployable_models(list_hf_models=True, model_filter="stable-diffusion")
```

----------------------------------------

TITLE: Install Python Development Headers
DESCRIPTION: Installs the necessary Python development headers on Debian/Ubuntu systems. This is required if the build process encounters errors related to missing Python.h files.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_9

LANGUAGE: bash
CODE:
```
$ sudo apt-get install python-dev
```

----------------------------------------

TITLE: PersistentResourceServiceTransport ABC
DESCRIPTION: The abstract base class (ABC) that defines the common interface for all transport implementations of the PersistentResourceService. It serves as the foundation for concrete transport classes.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/persistent_resource_service/transports/README.rst#_snippet_0

LANGUAGE: APIDOC
CODE:
```
class PersistentResourceServiceTransport:
    """Abstract base class for PersistentResourceService transports."""
    pass
```

----------------------------------------

TITLE: Asynchronous Vertex AI Batch Prediction
DESCRIPTION: Creates a batch prediction job asynchronously. Includes methods to wait for resource creation, check job state, and block until the job is complete.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_19

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

# Assume model is already initialized
# model = aiplatform.Model('/projects/my-project/locations/us-central1/models/{MODEL_ID}')

# Create job asynchronously
batch_prediction_job = model.batch_predict(..., sync=False)

# Wait for resource to be created
batch_prediction_job.wait_for_resource_creation()

# Get the state
print(f"Job state: {batch_prediction_job.state}")

# Block until job is complete
batch_prediction_job.wait()
```

----------------------------------------

TITLE: Test Agent Locally
DESCRIPTION: Tests the defined ADK Agent locally by sending a query and streaming the response events. This allows for quick iteration and debugging before deployment.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_17

LANGUAGE: python
CODE:
```
for event in app.stream_query(
    user_id="user-id",
    message="What is the exchange rate from US dollars to SEK today?",
):
    print(event)
```

----------------------------------------

TITLE: PersistentResourceServiceGrpcAsyncIOTransport (Async gRPC)
DESCRIPTION: A public child class inheriting from PersistentResourceServiceTransport, providing the concrete implementation for asynchronous gRPC transport using asyncio. This class is defined in the grpc_asyncio.py file.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1/services/persistent_resource_service/transports/README.rst#_snippet_2

LANGUAGE: APIDOC
CODE:
```
class PersistentResourceServiceGrpcAsyncIOTransport(PersistentResourceServiceTransport):
    """Async gRPC transport for PersistentResourceService."""
    pass

# Defined in: grpc_asyncio.py
```

----------------------------------------

TITLE: PersistentResourceServiceGrpcAsyncIOTransport (Async gRPC)
DESCRIPTION: A public child class inheriting from PersistentResourceServiceTransport, providing the concrete implementation for asynchronous gRPC transport using asyncio. This class is defined in the grpc_asyncio.py file.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform_v1beta1/services/persistent_resource_service/transports/README.rst#_snippet_2

LANGUAGE: APIDOC
CODE:
```
class PersistentResourceServiceGrpcAsyncIOTransport(PersistentResourceServiceTransport):
    """Async gRPC transport for PersistentResourceService."""
    pass

# Defined in: grpc_asyncio.py
```

----------------------------------------

TITLE: List Vertex AI Model Evaluations
DESCRIPTION: Retrieves a list of all model evaluations associated with a given Vertex AI Model. This is useful for inspecting the performance metrics of different training runs.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_15

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

model = aiplatform.Model('projects/my-project/locations/us-central1/models/{MODEL_ID}')

evaluations = model.list_model_evaluations()
```

----------------------------------------

TITLE: Deploy Model to Vertex AI Endpoint
DESCRIPTION: Deploys a Vertex AI Model to an existing Endpoint. Configures machine type, replica counts, and accelerator details for online serving. This is a prerequisite for making predictions.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_21

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

# Assume model and endpoint are already initialized
# model = aiplatform.Model('/projects/my-project/locations/us-central1/models/{MODEL_ID}')
# endpoint = aiplatform.Endpoint('projects/my-project/locations/us-central1/endpoints/{ENDPOINT_ID}')

endpoint.deploy(
    model,
    min_replica_count=1,
    max_replica_count=5,
    machine_type='n1-standard-4',
    accelerator_type='NVIDIA_TESLA_K80',
    accelerator_count=1
)
```

----------------------------------------

TITLE: Deploy Model with Custom Configurations
DESCRIPTION: Customizes the deployment of a model by specifying machine types, accelerators, replica counts, endpoint/model names, and other advanced settings.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/vertexai/model_garden/README.md#_snippet_5

LANGUAGE: python
CODE:
```
from vertexai import model_garden

model = model_garden.OpenModel("google/paligemma@paligemma-224-float32")

# Customize machine and resource configuration
endpoint = model.deploy(
    machine_type="g2-standard-4",
    accelerator_type="NVIDIA_L4",
    accelerator_count=1,
    min_replica_count=1,
    max_replica_count=1,
    endpoint_display_name="paligemma-endpoint",
    model_display_name="paligemma-model"
)

# Deploy with EULA acceptance
endpoint = model.deploy(eula=True)

# Deploy on Spot VMs for cost savings
endpoint = model.deploy(spot=True)

# Enable experimental fast-tryout path
endpoint = model.deploy(fast_tryout_enabled=True)

# Create a dedicated, DNS-isolated endpoint
endpoint = model.deploy(use_dedicated_endpoint=True)

# Use reservation affinity for pre-reserved capacity
endpoint = model.deploy(
    reservation_affinity_type="SPECIFIC_RESERVATION",
    reservation_affinity_key="compute.googleapis.com/reservation-name",
    reservation_affinity_values="projects/YOUR_PROJECT/zones/YOUR_ZONE/reservations/YOUR_RESERVATION"
)

# Override with a custom container image
endpoint = model.deploy(
    serving_container_image_uri="us-docker.pkg.dev/vertex-ai/custom-container:latest"
)
```

----------------------------------------

TITLE: Deploy Agent to Agent Engine
DESCRIPTION: Deploys the locally defined ADK Agent to Vertex AI's Agent Engine. This involves initializing Vertex AI with project and location details and creating the remote application.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/gemini_docs/README.md#_snippet_18

LANGUAGE: python
CODE:
```
import vertexai

vertexai.init(
    project='my-project',
    location='us-central1',
    staging_bucket="gs://my-staging-bucket",
)

remote_app = vertexai.agent_engines.create(
    app,
    requirements=["google-cloud-aiplatform[agent_engines,adk]"],
)
```

----------------------------------------

TITLE: Create Vertex AI Batch Prediction Job
DESCRIPTION: Initiates a batch prediction job for a Vertex AI Model. Configures job display name, input/output formats, machine type, GCS source data, GCS destination prefix, and service account.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_18

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

# Assume model is already initialized
# model = aiplatform.Model('/projects/my-project/locations/us-central1/models/{MODEL_ID}')

batch_prediction_job = model.batch_predict(
  job_display_name='my-batch-prediction-job',
  instances_format='csv',
  machine_type='n1-standard-4',
  gcs_source=['gs://path/to/my/file.csv'],
  gcs_destination_prefix='gs://path/to/my/batch_prediction/results/',
  service_account='my-sa@my-project.iam.gserviceaccount.com'
)
```

----------------------------------------

TITLE: Deploy Vertex AI Model
DESCRIPTION: Deploys a trained or uploaded model to a Vertex AI Endpoint. Specifies machine type, replica counts, and optionally accelerator details. Returns the deployed Endpoint object.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_14

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

# Assume model is already initialized
# model = aiplatform.Model('/projects/my-project/locations/us-central1/models/{MODEL_ID}')

endpoint = model.deploy(
    machine_type="n1-standard-4",
    min_replica_count=1,
    max_replica_count=5,
    accelerator_type='NVIDIA_TESLA_K80',
    accelerator_count=1
)
```

----------------------------------------

TITLE: Run Custom Training Job
DESCRIPTION: Configures and runs a custom training job on Vertex AI. This includes specifying the training script, container image, requirements, and hardware accelerators.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_9

LANGUAGE: Python
CODE:
```
job = aiplatform.CustomTrainingJob(
    display_name="my-training-job",
    script_path="training_script.py",
    container_uri="us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-2:latest",
    requirements=["gcsfs==0.7.1"],
    model_serving_container_image_uri="us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-2:latest",
)

model = job.run(
    my_dataset,
    replica_count=1,
    machine_type="n1-standard-4",
    accelerator_type='NVIDIA_TESLA_K80',
    accelerator_count=1
)
```

----------------------------------------

TITLE: Install Python Package: pytest-xdist
DESCRIPTION: pytest-xdist is a plugin for pytest that allows distributing tests across multiple CPUs or machines. This significantly speeds up test execution for large test suites.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/samples/snippets/requirements-test.txt#_snippet_1

LANGUAGE: python
CODE:
```
pytest-xdist
```

----------------------------------------

TITLE: Run Specific Unit Test with Nox
DESCRIPTION: Execute a single unit test by specifying its name using the nox tool. This is useful for debugging specific test failures.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_2

LANGUAGE: bash
CODE:
```
$ nox -s unit-3.12 -- -k <name of test>
```

----------------------------------------

TITLE: Run Vertex AI Pipeline Synchronously
DESCRIPTION: Instantiates and executes a Vertex AI Pipeline job synchronously, waiting for its completion. This method requires specifying pipeline configuration such as the display name, template path, parameter values, pipeline root, and optionally a service account.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_26

LANGUAGE: Python
CODE:
```
from google.cloud.aiplatform import PipelineJob

# Instantiate PipelineJob object
pl = PipelineJob(
    display_name="My first pipeline",
    enable_caching=False,
    template_path="pipeline.json",
    parameter_values=parameter_values,
    pipeline_root=pipeline_root,
)

# Execute pipeline in Vertex AI and monitor until completion
pl.run(
    service_account=service_account,
    sync=True
)
```

----------------------------------------

TITLE: Run Test Coverage
DESCRIPTION: Executes the test suite to ensure 100% statement coverage for the codebase. This command should be run after each commit to maintain code quality.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_10

LANGUAGE: bash
CODE:
```
nox -s cover
```

----------------------------------------

TITLE: Delete Vertex AI Endpoint
DESCRIPTION: Deletes a Vertex AI endpoint resource. This action is irreversible and removes the endpoint and any associated deployments.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_26

LANGUAGE: python
CODE:
```
endpoint.delete()
```

----------------------------------------

TITLE: Run Specific System Test with Nox
DESCRIPTION: Executes a single system test by specifying its name and Python version using the nox tool. Note that system tests are primarily configured for Python 3.9.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/CONTRIBUTING.rst#_snippet_8

LANGUAGE: bash
CODE:
```
# Run a single system test
$ nox -s system-3.9 -- -k <name of test>
```

----------------------------------------

TITLE: Install PortAudio on Mac OS X
DESCRIPTION: Installs PortAudio using Homebrew on macOS. This is a prerequisite for the PyAudio library.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/scripts/readme-gen/templates/install_portaudio.tmpl.rst#_snippet_0

LANGUAGE: bash
CODE:
```
brew install portaudio
```

----------------------------------------

TITLE: Install PortAudio on Debian/Ubuntu Linux
DESCRIPTION: Installs PortAudio development files and Python headers on Debian-based Linux distributions like Ubuntu. These are necessary for compiling PyAudio.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/scripts/readme-gen/templates/install_portaudio.tmpl.rst#_snippet_2

LANGUAGE: bash
CODE:
```
apt-get install portaudio19-dev python-all-dev
```

----------------------------------------

TITLE: Undeploy All Models from Vertex AI Endpoint
DESCRIPTION: Removes all deployed models from a Vertex AI Endpoint. This action stops online serving for all models hosted on that endpoint.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_23

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

# Assume endpoint is already initialized
# endpoint = aiplatform.Endpoint('projects/my-project/locations/us-central1/endpoints/{ENDPOINT_ID}')

endpoint.undeploy_all()
```

----------------------------------------

TITLE: Undeploy All Models from Endpoint
DESCRIPTION: Removes all deployed models from a Vertex AI endpoint. This action makes the endpoint inactive for predictions.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/README.rst#_snippet_25

LANGUAGE: python
CODE:
```
endpoint.undeploy_all()
```

----------------------------------------

TITLE: Install PyAudio with PortAudio Flags on Mac OS X
DESCRIPTION: Installs PyAudio with specific build flags to help locate PortAudio headers and libraries when encountering installation errors on macOS. This is a workaround for missing portaudio.h.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/scripts/readme-gen/templates/install_portaudio.tmpl.rst#_snippet_1

LANGUAGE: bash
CODE:
```
pip install --global-option='build_ext' \
    --global-option='-I/usr/local/include' \
    --global-option='-L/usr/local/lib' \
    pyaudio
```

----------------------------------------

TITLE: Delete Vertex AI Endpoint
DESCRIPTION: Deletes a Vertex AI Endpoint and all associated deployed models. This is a permanent action and cannot be undone.
SOURCE: https://github.com/googleapis/python-aiplatform/blob/main/docs/README.rst#_snippet_24

LANGUAGE: Python
CODE:
```
from google.cloud import aiplatform

# Initialize Vertex AI SDK
aiplatform.init(project='my-project', location='us-central1')

# Assume endpoint is already initialized
# endpoint = aiplatform.Endpoint('projects/my-project/locations/us-central1/endpoints/{ENDPOINT_ID}')

endpoint.delete()
```